{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VP64XWyvNkZl"
   },
   "source": [
    "Main Leaderboard\n",
    "\n",
    "Forecaster  | Peer score against Pros | % Beat Pros on same Qs (Bootstrap) | % Beat Pros on same Qs (Resample)\n",
    "\n",
    "Resample: Linear interpolation of two forecasters to determine \"ground truth\" for resampling. \"Ground truth\" = weighted combination of percent forecasts on each question that yields the most accurate score. Weights are 0 to 1.\n",
    "\n",
    "Correlation: Deal with by assigning weights to questions. Weights for independent questions are 1. \"Approximately correct rather than precisely wrong.\" Would be good to have a rule of thumb. These weights can be used for leaderboard above.\n",
    "\n",
    "Likely want % beat Pros to be beyond 95% for significance - but obviously a sliding scale.\n",
    "\n",
    "Can use this method for Metaculus Track Record! Have separate line for each platform - so can see significance against each platform. Then combine all competeing platforms and treat as the same forecaster going head-to-head against Metaculus!\n",
    "\n",
    "Heroku:\n",
    "\n",
    "Bots: https://data.heroku.com/dataclips/bmlboxtaewpwemfvqwktqxernfeq\n",
    "\n",
    "Pros: https://data.heroku.com/dataclips/rozqhydlvqrzsllgmioruallozjx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "ISzIoto4hnoG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# @title Import libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from functions import *\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_head_and_tail(df: pd.DataFrame):\n",
    "  display(df.head())\n",
    "  display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1932996/3462343738.py:25: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_bot_forecasts = pd.read_csv('https://data.heroku.com/dataclips/tfwiopapwgyjkawcpjmpibjlsars.csv')\n"
     ]
    }
   ],
   "source": [
    "# @title Create df_bot_resolved_questions, df_pro_resolved_questions, df_pro_bot_resolved_questions, df_bot_question_weights\n",
    "\n",
    "\"\"\"\n",
    "Input question data for both bots and pros.\n",
    "\n",
    "Only look at questions that have resolved Yes or No.\n",
    "\n",
    "df_pro_resolved_questions: Has pro_question_id, title, resolution, scheduled_close_time\n",
    "df_bot_resolved_questions: Has bot_question_id, title, resolution, scheduled_close_time\n",
    "\n",
    "All pro questions are asked to bots, but not all bot questions are asked to pros (correction:\n",
    "not true in 2024 Q4, there were some that got launched to pros first? and were bad so they\n",
    "didn't get asked of bots?)\n",
    "\n",
    "To compare pros to bots, we need to match the pro_question_id with the bot_question_id.\n",
    "This is done by matching the title and scheduled_close_time.\n",
    "\n",
    "We remove early closers from the analysis. I do this by comparing actual close time to scheduled\n",
    "close time in a later cell!\n",
    "\n",
    "df_pro_bot_resolved_questions: Has pro_question_id, bot_question_id, title, resolution, scheduled_close_time, question_weight\n",
    "\"\"\"\n",
    "\n",
    "df_bot_scores = pd.read_csv(f'https://data.heroku.com/dataclips/nqghgczhvwahbmupzypyzaanabzv.csv')\n",
    "df_bot_forecasts = pd.read_csv('https://data.heroku.com/dataclips/tfwiopapwgyjkawcpjmpibjlsars.csv')\n",
    "df_bot_questions = df_bot_forecasts.rename(columns={'question_id': 'bot_question_id', 'question_title': 'title'})\n",
    "\n",
    "df_pro_scores = pd.read_csv(f'https://data.heroku.com/dataclips/pcyecxbmoxppkxxaebikcwukhpqk.csv')\n",
    "df_pro_forecasts = pd.read_csv('https://data.heroku.com/dataclips/roxytxphqvznkgbygmfgzymjtfxx.csv')\n",
    "df_pro_questions = df_pro_forecasts.rename(columns={'question_id': 'pro_question_id', 'question_title': 'title'})\n",
    "\n",
    "if False: # Temporary - Only keep Binary\n",
    "    df_bot_questions = df_bot_questions[df_bot_questions['resolution'].isin(['yes', 'no'])]\n",
    "    df_bot_forecasts = df_bot_forecasts[df_bot_forecasts['resolution'].isin(['yes', 'no'])]\n",
    "    df_bot_scores = df_bot_scores[df_bot_scores['resolution'].isin(['yes', 'no'])]\n",
    "    df_pro_questions = df_pro_questions[df_pro_questions['resolution'].isin(['yes', 'no'])]\n",
    "    df_pro_forecasts = df_pro_forecasts[df_pro_forecasts['resolution'].isin(['yes', 'no'])]\n",
    "    df_pro_scores = df_pro_scores[df_pro_scores['resolution'].isin(['yes', 'no'])]\n",
    "\n",
    "df_pro_resolved_questions = df_pro_questions[['pro_question_id', 'title', 'resolution', 'scheduled_close_time', 'actual_close_time', 'question_weight', 'type', 'options', 'range_min', 'range_max', 'open_upper_bound', 'open_lower_bound']]\n",
    "df_bot_resolved_questions = df_bot_questions[['bot_question_id', 'title', 'resolution', 'scheduled_close_time', 'actual_close_time', 'question_weight', 'type', 'options', 'range_min', 'range_max', 'open_upper_bound', 'open_lower_bound']]\n",
    "\n",
    "df_pro_bot_resolved_questions = pd.merge(\n",
    "    df_bot_resolved_questions,\n",
    "    df_pro_resolved_questions[['pro_question_id', 'title', 'scheduled_close_time', 'question_weight']],\n",
    "    on=['title', 'scheduled_close_time'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_pro_bot_resolved_questions['question_weight'] = df_pro_bot_resolved_questions['question_weight_x'].combine_first(df_pro_bot_resolved_questions['question_weight_y'])\n",
    "df_pro_bot_resolved_questions.drop(['question_weight_x', 'question_weight_y'], axis=1, inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "df_pro_bot_resolved_questions = df_pro_bot_resolved_questions.drop_duplicates()\n",
    "\n",
    "# Cast both question ids to int64\n",
    "df_pro_bot_resolved_questions['pro_question_id'] = df_pro_bot_resolved_questions['pro_question_id'].astype('Int64')\n",
    "df_pro_bot_resolved_questions['bot_question_id'] = df_pro_bot_resolved_questions['bot_question_id'].astype('Int64')\n",
    "\n",
    "# Remove df_bot_resolved_questions and df_pro_resolved_questions to make sure you only ever use df_pro_bot_resolved_questions\n",
    "del df_bot_resolved_questions\n",
    "del df_pro_resolved_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "# Are any of the weights NOT 1 -- for Q3 we need to assign weights \"manually\" but for Q4 they are there\n",
    "print(df_pro_bot_resolved_questions[df_pro_bot_resolved_questions['question_weight'] != 1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number bot questions: 424\n",
      "Bot questions that don't have pro counterpart: 325\n",
      "Overlap between bot and pro questions: 99\n"
     ]
    }
   ],
   "source": [
    "b = df_pro_bot_resolved_questions.shape\n",
    "\n",
    "# How many are NA for pro_question_id?\n",
    "a = df_pro_bot_resolved_questions['pro_question_id'].isna().sum()\n",
    "\n",
    "print(f'Total number bot questions: {b[0]}')\n",
    "print(f'Bot questions that don\\'t have pro counterpart: {a}')\n",
    "print(f'Overlap between bot and pro questions: {b[0]-a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted count: 99\n",
      "Weighted count: 95.0\n"
     ]
    }
   ],
   "source": [
    "# Weighted vs unweighted breakdown for those overlapping questions?\n",
    "df_pro_bot_overlap = df_pro_bot_resolved_questions[~df_pro_bot_resolved_questions['pro_question_id'].isna()]\n",
    "print(f'Unweighted count: {df_pro_bot_overlap.shape[0]}')\n",
    "print(f'Weighted count: {df_pro_bot_overlap[\"question_weight\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "# Test: Are there any non-1 weights (there should be)\n",
    "print(df_pro_bot_resolved_questions[df_pro_bot_resolved_questions['question_weight'] != 1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bot_question_id', 'title', 'resolution', 'scheduled_close_time',\n",
       "       'actual_close_time', 'type', 'options', 'range_min', 'range_max',\n",
       "       'open_upper_bound', 'open_lower_bound', 'pro_question_id',\n",
       "       'question_weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro_bot_resolved_questions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IntegerArray>\n",
      "[31268, 31269, 31270, 31280, 31281, 31282, 31292, 31293, 31294, 31322,  <NA>,\n",
      " 31337, 31338, 31368, 31321, 33874, 33875, 33876, 33877, 33878, 33879, 33880,\n",
      " 33881, 33882, 33883, 33884, 33885, 33886, 33887, 34245, 34246, 34247, 34248,\n",
      " 34249, 34250, 34252, 34251, 34253, 34254, 34255, 34256, 34257, 34258, 34259,\n",
      " 34487, 34488, 34489, 34490, 34491, 34493, 34494, 34495, 34496, 34497, 34498,\n",
      " 34499, 34500, 34501, 34721, 34722, 34723, 34724, 34725, 34726, 34727, 34728,\n",
      " 34729, 34730, 34733, 34734, 34961, 34959, 34960, 34962, 34963, 34964, 34965,\n",
      " 34966, 34967, 34968, 34971, 34972, 35169, 35170, 35171, 35172, 35173, 35174,\n",
      " 35175, 35176, 35177, 35178, 35377, 35378, 35379, 35380, 35381, 35385, 35386,\n",
      " 35387]\n",
      "Length: 100, dtype: Int64 <IntegerArray>\n",
      "[31262, 31263, 31264, 31274, 31275, 31276, 31286, 31287, 31288, 31317,\n",
      " ...\n",
      " 35614, 35615, 35616, 35617, 35618, 35619, 35620, 35621, 35622, 35705]\n",
      "Length: 424, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# Unique pro questions, bot questions\n",
    "pro_questions = df_pro_bot_resolved_questions['pro_question_id'].unique()\n",
    "bot_questions = df_pro_bot_resolved_questions['bot_question_id'].unique()\n",
    "print(pro_questions, bot_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bot_question_id           Int64\n",
       "title                    object\n",
       "resolution               object\n",
       "scheduled_close_time     object\n",
       "actual_close_time        object\n",
       "type                     object\n",
       "options                  object\n",
       "range_min               float64\n",
       "range_max               float64\n",
       "open_upper_bound         object\n",
       "open_lower_bound         object\n",
       "pro_question_id           Int64\n",
       "question_weight         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro_bot_resolved_questions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove early closers IF right now is before scheduled close time\n",
    "df_pro_bot_resolved_questions['scheduled_close_time'] = pd.to_datetime(df_pro_bot_resolved_questions['scheduled_close_time']).dt.tz_localize(None)\n",
    "df_pro_bot_resolved_questions['actual_close_time'] = pd.to_datetime(df_pro_bot_resolved_questions['actual_close_time']).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique questions in df_pro_bot_resolved_questions: 424\n"
     ]
    }
   ],
   "source": [
    "remove_early_closers = False # SET TO FALSE WHEN ALL Q'S ARE RESOLVED\n",
    "if remove_early_closers:\n",
    "  df_pro_bot_resolved_questions = df_pro_bot_resolved_questions[(df_pro_bot_resolved_questions['actual_close_time'] <= df_pro_bot_resolved_questions['scheduled_close_time'])]\n",
    "\n",
    "print('Number of unique questions in df_pro_bot_resolved_questions:', len(df_pro_bot_resolved_questions['bot_question_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read in the scores dataclips from heroku, take last (spot) score for each question_id, forecaster pair; make it into what Tom's code expects\n",
    "\n",
    "## BOTS\n",
    "\n",
    "# BASELINE\n",
    "df_bot_baseline = df_bot_scores[df_bot_scores['score_type'] == 'spot_baseline']\n",
    "\n",
    "# Take the LAST score for each (forecaster, question_id) pair\n",
    "df_bot_baseline = df_bot_baseline.groupby(['question_id', 'forecaster']).last().reset_index()\n",
    "\n",
    "# PEER\n",
    "df_bot_peer = df_bot_scores[df_bot_scores['score_type'] == 'spot_peer']\n",
    "\n",
    "# Take the LAST score for each (forecaster, question_id) pair\n",
    "df_bot_peer = df_bot_peer.groupby(['question_id', 'forecaster']).last().reset_index()\n",
    "\n",
    "## PROS\n",
    "\n",
    "# BASELINE\n",
    "df_pro_baseline = df_pro_scores[df_pro_scores['score_type'] == 'spot_baseline']\n",
    "\n",
    "# Take the LAST score for each (forecaster, question_id) pair\n",
    "df_pro_baseline = df_pro_baseline.groupby(['question_id', 'forecaster']).last().reset_index()\n",
    "df_pro_baseline_long = df_pro_baseline.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process forecasts (consolidate forecast columns; take the last forecast from each forecaster for each question)\n",
    "df_bot_forecasts = process_forecasts(df_bot_forecasts)\n",
    "df_pro_forecasts = process_forecasts(df_pro_forecasts)\n",
    "\n",
    "# Add median rows\n",
    "df_bot_forecasts = add_median_rows(add_is_median(df_bot_forecasts), 'bot')\n",
    "df_pro_forecasts = add_median_rows(add_is_median(df_pro_forecasts), 'pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>forecaster</th>\n",
       "      <th>question_title</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>scheduled_close_time</th>\n",
       "      <th>actual_close_time</th>\n",
       "      <th>question_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>range_min</th>\n",
       "      <th>range_max</th>\n",
       "      <th>open_lower_bound</th>\n",
       "      <th>open_upper_bound</th>\n",
       "      <th>post_id</th>\n",
       "      <th>forecast</th>\n",
       "      <th>is_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31268</td>\n",
       "      <td>Jgalt</td>\n",
       "      <td>For Q1 2025, how many banks will be listed on ...</td>\n",
       "      <td>2025-01-17 19:06:22.013528+00</td>\n",
       "      <td>101465</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31736</td>\n",
       "      <td>[0.001,0.568,0.366,0.041,0.024]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31268</td>\n",
       "      <td>MaciekK</td>\n",
       "      <td>For Q1 2025, how many banks will be listed on ...</td>\n",
       "      <td>2025-01-17 19:06:22.013528+00</td>\n",
       "      <td>117580</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31736</td>\n",
       "      <td>[0.001,0.62,0.35,0.019,0.01]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31268</td>\n",
       "      <td>OpenSystem</td>\n",
       "      <td>For Q1 2025, how many banks will be listed on ...</td>\n",
       "      <td>2025-01-17 19:06:22.013528+00</td>\n",
       "      <td>120160</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31736</td>\n",
       "      <td>[0.005,0.7,0.25,0.04,0.005]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31268</td>\n",
       "      <td>darkives</td>\n",
       "      <td>For Q1 2025, how many banks will be listed on ...</td>\n",
       "      <td>2025-01-17 19:06:22.013528+00</td>\n",
       "      <td>103907</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31736</td>\n",
       "      <td>[0.001,0.49,0.365,0.1,0.044]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31268</td>\n",
       "      <td>datscilly</td>\n",
       "      <td>For Q1 2025, how many banks will be listed on ...</td>\n",
       "      <td>2025-01-17 19:06:22.013528+00</td>\n",
       "      <td>103777</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31736</td>\n",
       "      <td>[0.001,0.56,0.36,0.059,0.02]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  forecaster                                     question_title  \\\n",
       "0        31268       Jgalt  For Q1 2025, how many banks will be listed on ...   \n",
       "1        31268     MaciekK  For Q1 2025, how many banks will be listed on ...   \n",
       "2        31268  OpenSystem  For Q1 2025, how many banks will be listed on ...   \n",
       "5        31268    darkives  For Q1 2025, how many banks will be listed on ...   \n",
       "6        31268   datscilly  For Q1 2025, how many banks will be listed on ...   \n",
       "\n",
       "                      created_at  author_id resolution  \\\n",
       "0  2025-01-17 19:06:22.013528+00     101465          1   \n",
       "1  2025-01-17 19:06:22.013528+00     117580          1   \n",
       "2  2025-01-17 19:06:22.013528+00     120160          1   \n",
       "5  2025-01-17 19:06:22.013528+00     103907          1   \n",
       "6  2025-01-17 19:06:22.013528+00     103777          1   \n",
       "\n",
       "     scheduled_close_time       actual_close_time  question_weight  \\\n",
       "0  2025-01-20 03:27:00+00  2025-01-20 03:27:00+00              1.0   \n",
       "1  2025-01-20 03:27:00+00  2025-01-20 03:27:00+00              1.0   \n",
       "2  2025-01-20 03:27:00+00  2025-01-20 03:27:00+00              1.0   \n",
       "5  2025-01-20 03:27:00+00  2025-01-20 03:27:00+00              1.0   \n",
       "6  2025-01-20 03:27:00+00  2025-01-20 03:27:00+00              1.0   \n",
       "\n",
       "              type                     options  range_min  range_max  \\\n",
       "0  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "1  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "2  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "5  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "6  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "\n",
       "  open_lower_bound open_upper_bound  post_id                         forecast  \\\n",
       "0            False            False    31736  [0.001,0.568,0.366,0.041,0.024]   \n",
       "1            False            False    31736     [0.001,0.62,0.35,0.019,0.01]   \n",
       "2            False            False    31736      [0.005,0.7,0.25,0.04,0.005]   \n",
       "5            False            False    31736     [0.001,0.49,0.365,0.1,0.044]   \n",
       "6            False            False    31736     [0.001,0.56,0.36,0.059,0.02]   \n",
       "\n",
       "   is_median  \n",
       "0      False  \n",
       "1       True  \n",
       "2      False  \n",
       "5      False  \n",
       "6      False  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro_forecasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD THE BOT MEDIAN SPOT SCORES & REMOVE UNNECESSARY COLUMNS\n",
    "df_bot_baseline = df_bot_baseline[['question_id', 'question_title', 'question_weight', 'forecaster', 'score', 'resolution']]\n",
    "\n",
    "# Add bot_median rows\n",
    "df_bot_baseline = df_bot_baseline.merge(df_bot_forecasts[['question_id', 'forecaster', 'is_median']], on=['question_id', 'forecaster'], how='left')\n",
    "df_bot_baseline = add_median_rows(df_bot_baseline, 'bot')\n",
    "\n",
    "df_bot_baseline_long = df_bot_baseline.copy()\n",
    "\n",
    "# DO THE SAME FOR DF_BOT_PEER\n",
    "df_bot_peer = df_bot_peer[['question_id', 'question_title', 'question_weight', 'forecaster', 'score', 'resolution']]\n",
    "\n",
    "# Add bot_median rows\n",
    "df_bot_peer = df_bot_peer.merge(df_bot_forecasts[['question_id', 'forecaster', 'is_median']], on=['question_id', 'forecaster'], how='left')\n",
    "df_bot_peer = add_median_rows(df_bot_peer, 'bot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['metac-Llama-3.1', 'metac-Gemini-Exp-1206', 'acm_bot',\n",
       "       'NextWorldLab', 'metac-o1-preview', 'metac-perplexity', 'mmBot',\n",
       "       'metac-claude-3-5-sonnet-latest', 'Grizeu_Bot', 'GreeneiBot2',\n",
       "       'InstitutPelFutur', 'metac-claude-3-5-sonnet-20240620', 'metac-o1',\n",
       "       'metac-grok-2-1212', 'metac-gpt-4o', 'bot_median', 'pgodzinai',\n",
       "       'metac-exa', 'jkraybill_bot', 'VeritasAI', 'MWG', 'twsummerbot',\n",
       "       'CatrachoCaster', 'X_bot', 'manticAI', 'annabot', 'minefrac1',\n",
       "       'metac-deepseek-r1', 'Bot_Pepa', 'laylaps', 'ajf-bot',\n",
       "       'SynapseSeer', 'RPM_bot', 'cookics_bot_TEST', 'ProfessorSP',\n",
       "       'wunderplumb', 'CumulativeBot', 'pianobot', 'krm-bot',\n",
       "       'KevinTestBot', '4Shadower', 'swingswish', 'jonahsingerbot',\n",
       "       'bean_bot', 'andrewsiah', 'cobyj-bot'], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bots = df_bot_peer['forecaster'].unique()\n",
    "all_bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecaster</th>\n",
       "      <th>weighted_mean</th>\n",
       "      <th>weighted_sum</th>\n",
       "      <th>n_questions</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>weighted_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>metac-o1</td>\n",
       "      <td>9.674740</td>\n",
       "      <td>3631.123492</td>\n",
       "      <td>406</td>\n",
       "      <td>6.257418</td>\n",
       "      <td>1.738353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>metac-o1-preview</td>\n",
       "      <td>8.465638</td>\n",
       "      <td>3121.449998</td>\n",
       "      <td>399</td>\n",
       "      <td>3.947903</td>\n",
       "      <td>2.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bot_median</td>\n",
       "      <td>6.860987</td>\n",
       "      <td>2593.590381</td>\n",
       "      <td>409</td>\n",
       "      <td>3.788648</td>\n",
       "      <td>1.562899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>manticAI</td>\n",
       "      <td>6.510835</td>\n",
       "      <td>2055.210309</td>\n",
       "      <td>337</td>\n",
       "      <td>0.552564</td>\n",
       "      <td>3.029040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metac-Gemini-Exp-1206</td>\n",
       "      <td>5.417367</td>\n",
       "      <td>1880.476418</td>\n",
       "      <td>377</td>\n",
       "      <td>0.876988</td>\n",
       "      <td>2.309106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               forecaster  weighted_mean  weighted_sum  n_questions  ci_lower  \\\n",
       "12               metac-o1       9.674740   3631.123492          406  6.257418   \n",
       "4        metac-o1-preview       8.465638   3121.449998          399  3.947903   \n",
       "15             bot_median       6.860987   2593.590381          409  3.788648   \n",
       "24               manticAI       6.510835   2055.210309          337  0.552564   \n",
       "1   metac-Gemini-Exp-1206       5.417367   1880.476418          377  0.876988   \n",
       "\n",
       "    weighted_se  \n",
       "12     1.738353  \n",
       "4      2.298000  \n",
       "15     1.562899  \n",
       "24     3.029040  \n",
       "1      2.309106  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecaster</th>\n",
       "      <th>weighted_mean</th>\n",
       "      <th>weighted_sum</th>\n",
       "      <th>n_questions</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>weighted_se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VeritasAI</td>\n",
       "      <td>-4.854808</td>\n",
       "      <td>-1602.183635</td>\n",
       "      <td>361</td>\n",
       "      <td>-8.860367</td>\n",
       "      <td>2.036820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>minefrac1</td>\n",
       "      <td>-9.333648</td>\n",
       "      <td>-1757.059251</td>\n",
       "      <td>202</td>\n",
       "      <td>-15.440064</td>\n",
       "      <td>3.096816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Grizeu_Bot</td>\n",
       "      <td>-9.743831</td>\n",
       "      <td>-1882.605577</td>\n",
       "      <td>207</td>\n",
       "      <td>-17.494967</td>\n",
       "      <td>3.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>metac-gpt-4o</td>\n",
       "      <td>-5.987786</td>\n",
       "      <td>-2235.360274</td>\n",
       "      <td>404</td>\n",
       "      <td>-10.422687</td>\n",
       "      <td>2.255950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ajf-bot</td>\n",
       "      <td>-14.000701</td>\n",
       "      <td>-3208.260547</td>\n",
       "      <td>244</td>\n",
       "      <td>-24.482548</td>\n",
       "      <td>5.321344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      forecaster  weighted_mean  weighted_sum  n_questions   ci_lower  \\\n",
       "19     VeritasAI      -4.854808  -1602.183635          361  -8.860367   \n",
       "26     minefrac1      -9.333648  -1757.059251          202 -15.440064   \n",
       "8     Grizeu_Bot      -9.743831  -1882.605577          207 -17.494967   \n",
       "14  metac-gpt-4o      -5.987786  -2235.360274          404 -10.422687   \n",
       "30       ajf-bot     -14.000701  -3208.260547          244 -24.482548   \n",
       "\n",
       "    weighted_se  \n",
       "19     2.036820  \n",
       "26     3.096816  \n",
       "8      3.931500  \n",
       "14     2.255950  \n",
       "30     5.321344  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate and show results\n",
    "ranked_forecasters = calculate_weighted_stats(df_bot_peer)\n",
    "\n",
    "display_head_and_tail(ranked_forecasters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "BmAFBHIhK77X"
   },
   "outputs": [],
   "source": [
    "# @title Create df_bot_baseline, df_bot_peer, df_bot_forecasts, bots\n",
    "\n",
    "\"\"\"\n",
    "df_bot_baseline: Spot Baseline scores for all bots & bot_median\n",
    "\n",
    "df_bot_peer: Spot Peer scores for all bots & bot_median. Can be used to recreate\n",
    "the tournament leaderboard on the site.\n",
    "\n",
    "df_bot_forecasts: Spot forecasts for all bots & bot_median, ie only counts the\n",
    "final forecast\n",
    "\n",
    "bots: a list of all bots\n",
    "\"\"\"\n",
    "\n",
    "# Pivot df_bot_baseline\n",
    "df_bot_baseline = df_bot_baseline.rename(columns={'question_id': 'bot_question_id'})\n",
    "#df_bot_baseline['score'] = pd.to_numeric(df_bot_baseline['score'], errors='coerce')\n",
    "df_pivoted = df_bot_baseline.pivot(index='bot_question_id', columns='forecaster', values='score')\n",
    "df_pivoted = df_pivoted.reset_index()\n",
    "df_pivoted = df_pivoted.reindex(sorted(df_pivoted.columns), axis=1)\n",
    "\n",
    "# Move 'question_id' to be the first column\n",
    "cols = df_pivoted.columns.tolist()\n",
    "cols = ['bot_question_id'] + [col for col in cols if col != 'bot_question_id']\n",
    "df_pivoted = df_pivoted[cols]\n",
    "\n",
    "all_columns = df_pivoted.columns.tolist()\n",
    "# Remove 'question_id' and 'bot_median' from the list if they exist\n",
    "all_columns = [col for col in all_columns if col not in ['bot_question_id', 'bot_median']]\n",
    "new_column_order = ['bot_question_id', 'bot_median'] + all_columns\n",
    "df_pivoted = df_pivoted[new_column_order]\n",
    "df_bot_baseline_wide = df_pivoted\n",
    "df_bot_baseline_wide['bot_question_id'] = pd.to_numeric(df_bot_baseline_wide['bot_question_id'], errors='coerce')\n",
    "\n",
    "# Create df_bot_peer\n",
    "df_bot_peer = df_bot_peer.rename(columns={'question_id': 'bot_question_id'})\n",
    "df_bot_peer['score'] = pd.to_numeric(df_bot_peer['score'], errors='coerce')\n",
    "\n",
    "df_bot_peer_wide = make_wide(df_bot_peer, df_pro_bot_resolved_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 47)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{np.int64(31262),\n",
       " np.int64(31263),\n",
       " np.int64(31264),\n",
       " np.int64(31274),\n",
       " np.int64(31275),\n",
       " np.int64(31276),\n",
       " np.int64(31286),\n",
       " np.int64(31287),\n",
       " np.int64(31288),\n",
       " np.int64(31317),\n",
       " np.int64(31318),\n",
       " np.int64(31332),\n",
       " np.int64(31333),\n",
       " np.int64(31334),\n",
       " np.int64(31366),\n",
       " np.int64(31370),\n",
       " np.int64(33735),\n",
       " np.int64(33736),\n",
       " np.int64(33737),\n",
       " np.int64(33738),\n",
       " np.int64(33739),\n",
       " np.int64(33740),\n",
       " np.int64(33741),\n",
       " np.int64(33742),\n",
       " np.int64(33743),\n",
       " np.int64(33744),\n",
       " np.int64(33745),\n",
       " np.int64(33746),\n",
       " np.int64(33747),\n",
       " np.int64(33748),\n",
       " np.int64(33749),\n",
       " np.int64(33750),\n",
       " np.int64(33751),\n",
       " np.int64(33752),\n",
       " np.int64(33753),\n",
       " np.int64(33754),\n",
       " np.int64(33755),\n",
       " np.int64(33756),\n",
       " np.int64(33757),\n",
       " np.int64(33758),\n",
       " np.int64(33759),\n",
       " np.int64(33760),\n",
       " np.int64(33761),\n",
       " np.int64(33762),\n",
       " np.int64(33763),\n",
       " np.int64(33764),\n",
       " np.int64(33765),\n",
       " np.int64(33766),\n",
       " np.int64(33767),\n",
       " np.int64(33768),\n",
       " np.int64(33769),\n",
       " np.int64(33770),\n",
       " np.int64(33771),\n",
       " np.int64(33772),\n",
       " np.int64(33773),\n",
       " np.int64(33774),\n",
       " np.int64(33775),\n",
       " np.int64(33776),\n",
       " np.int64(33777),\n",
       " np.int64(33778),\n",
       " np.int64(33779),\n",
       " np.int64(33780),\n",
       " np.int64(33781),\n",
       " np.int64(33782),\n",
       " np.int64(33783),\n",
       " np.int64(34180),\n",
       " np.int64(34181),\n",
       " np.int64(34182),\n",
       " np.int64(34183),\n",
       " np.int64(34184),\n",
       " np.int64(34185),\n",
       " np.int64(34186),\n",
       " np.int64(34187),\n",
       " np.int64(34188),\n",
       " np.int64(34189),\n",
       " np.int64(34190),\n",
       " np.int64(34191),\n",
       " np.int64(34192),\n",
       " np.int64(34193),\n",
       " np.int64(34194),\n",
       " np.int64(34195),\n",
       " np.int64(34196),\n",
       " np.int64(34197),\n",
       " np.int64(34198),\n",
       " np.int64(34199),\n",
       " np.int64(34200),\n",
       " np.int64(34201),\n",
       " np.int64(34202),\n",
       " np.int64(34203),\n",
       " np.int64(34204),\n",
       " np.int64(34205),\n",
       " np.int64(34206),\n",
       " np.int64(34207),\n",
       " np.int64(34208),\n",
       " np.int64(34209),\n",
       " np.int64(34210),\n",
       " np.int64(34211),\n",
       " np.int64(34212),\n",
       " np.int64(34214),\n",
       " np.int64(34215),\n",
       " np.int64(34216),\n",
       " np.int64(34217),\n",
       " np.int64(34218),\n",
       " np.int64(34219),\n",
       " np.int64(34220),\n",
       " np.int64(34221),\n",
       " np.int64(34222),\n",
       " np.int64(34224),\n",
       " np.int64(34225),\n",
       " np.int64(34226),\n",
       " np.int64(34227),\n",
       " np.int64(34228),\n",
       " np.int64(34229),\n",
       " np.int64(34323),\n",
       " np.int64(34324),\n",
       " np.int64(34325),\n",
       " np.int64(34326),\n",
       " np.int64(34422),\n",
       " np.int64(34423),\n",
       " np.int64(34424),\n",
       " np.int64(34425),\n",
       " np.int64(34426),\n",
       " np.int64(34427),\n",
       " np.int64(34428),\n",
       " np.int64(34429),\n",
       " np.int64(34430),\n",
       " np.int64(34431),\n",
       " np.int64(34432),\n",
       " np.int64(34433),\n",
       " np.int64(34434),\n",
       " np.int64(34435),\n",
       " np.int64(34436),\n",
       " np.int64(34437),\n",
       " np.int64(34438),\n",
       " np.int64(34439),\n",
       " np.int64(34440),\n",
       " np.int64(34441),\n",
       " np.int64(34442),\n",
       " np.int64(34443),\n",
       " np.int64(34444),\n",
       " np.int64(34445),\n",
       " np.int64(34446),\n",
       " np.int64(34447),\n",
       " np.int64(34448),\n",
       " np.int64(34449),\n",
       " np.int64(34450),\n",
       " np.int64(34451),\n",
       " np.int64(34452),\n",
       " np.int64(34453),\n",
       " np.int64(34454),\n",
       " np.int64(34455),\n",
       " np.int64(34456),\n",
       " np.int64(34457),\n",
       " np.int64(34458),\n",
       " np.int64(34459),\n",
       " np.int64(34461),\n",
       " np.int64(34462),\n",
       " np.int64(34463),\n",
       " np.int64(34464),\n",
       " np.int64(34465),\n",
       " np.int64(34466),\n",
       " np.int64(34467),\n",
       " np.int64(34468),\n",
       " np.int64(34469),\n",
       " np.int64(34470),\n",
       " np.int64(34471),\n",
       " np.int64(34649),\n",
       " np.int64(34650),\n",
       " np.int64(34651),\n",
       " np.int64(34652),\n",
       " np.int64(34653),\n",
       " np.int64(34654),\n",
       " np.int64(34655),\n",
       " np.int64(34656),\n",
       " np.int64(34657),\n",
       " np.int64(34658),\n",
       " np.int64(34659),\n",
       " np.int64(34660),\n",
       " np.int64(34661),\n",
       " np.int64(34662),\n",
       " np.int64(34663),\n",
       " np.int64(34664),\n",
       " np.int64(34665),\n",
       " np.int64(34666),\n",
       " np.int64(34667),\n",
       " np.int64(34668),\n",
       " np.int64(34669),\n",
       " np.int64(34670),\n",
       " np.int64(34671),\n",
       " np.int64(34672),\n",
       " np.int64(34673),\n",
       " np.int64(34674),\n",
       " np.int64(34675),\n",
       " np.int64(34676),\n",
       " np.int64(34677),\n",
       " np.int64(34678),\n",
       " np.int64(34679),\n",
       " np.int64(34680),\n",
       " np.int64(34681),\n",
       " np.int64(34682),\n",
       " np.int64(34683),\n",
       " np.int64(34684),\n",
       " np.int64(34685),\n",
       " np.int64(34686),\n",
       " np.int64(34687),\n",
       " np.int64(34688),\n",
       " np.int64(34689),\n",
       " np.int64(34690),\n",
       " np.int64(34692),\n",
       " np.int64(34693),\n",
       " np.int64(34695),\n",
       " np.int64(34696),\n",
       " np.int64(34697),\n",
       " np.int64(34698),\n",
       " np.int64(34898),\n",
       " np.int64(34899),\n",
       " np.int64(34900),\n",
       " np.int64(34901),\n",
       " np.int64(34902),\n",
       " np.int64(34903),\n",
       " np.int64(34904),\n",
       " np.int64(34905),\n",
       " np.int64(34906),\n",
       " np.int64(34907),\n",
       " np.int64(34908),\n",
       " np.int64(34909),\n",
       " np.int64(34910),\n",
       " np.int64(34911),\n",
       " np.int64(34912),\n",
       " np.int64(34913),\n",
       " np.int64(34914),\n",
       " np.int64(34915),\n",
       " np.int64(34916),\n",
       " np.int64(34917),\n",
       " np.int64(34918),\n",
       " np.int64(34919),\n",
       " np.int64(34920),\n",
       " np.int64(34921),\n",
       " np.int64(34922),\n",
       " np.int64(34923),\n",
       " np.int64(34924),\n",
       " np.int64(34925),\n",
       " np.int64(34926),\n",
       " np.int64(34927),\n",
       " np.int64(34928),\n",
       " np.int64(34929),\n",
       " np.int64(34930),\n",
       " np.int64(34931),\n",
       " np.int64(34932),\n",
       " np.int64(34933),\n",
       " np.int64(34934),\n",
       " np.int64(34935),\n",
       " np.int64(34936),\n",
       " np.int64(34937),\n",
       " np.int64(34938),\n",
       " np.int64(34939),\n",
       " np.int64(34940),\n",
       " np.int64(34941),\n",
       " np.int64(34942),\n",
       " np.int64(34943),\n",
       " np.int64(34944),\n",
       " np.int64(34945),\n",
       " np.int64(34946),\n",
       " np.int64(34947),\n",
       " np.int64(35110),\n",
       " np.int64(35111),\n",
       " np.int64(35112),\n",
       " np.int64(35113),\n",
       " np.int64(35114),\n",
       " np.int64(35115),\n",
       " np.int64(35116),\n",
       " np.int64(35117),\n",
       " np.int64(35118),\n",
       " np.int64(35119),\n",
       " np.int64(35120),\n",
       " np.int64(35121),\n",
       " np.int64(35122),\n",
       " np.int64(35123),\n",
       " np.int64(35124),\n",
       " np.int64(35126),\n",
       " np.int64(35127),\n",
       " np.int64(35128),\n",
       " np.int64(35129),\n",
       " np.int64(35130),\n",
       " np.int64(35131),\n",
       " np.int64(35132),\n",
       " np.int64(35133),\n",
       " np.int64(35134),\n",
       " np.int64(35135),\n",
       " np.int64(35136),\n",
       " np.int64(35137),\n",
       " np.int64(35138),\n",
       " np.int64(35139),\n",
       " np.int64(35140),\n",
       " np.int64(35141),\n",
       " np.int64(35142),\n",
       " np.int64(35143),\n",
       " np.int64(35144),\n",
       " np.int64(35145),\n",
       " np.int64(35146),\n",
       " np.int64(35147),\n",
       " np.int64(35148),\n",
       " np.int64(35149),\n",
       " np.int64(35150),\n",
       " np.int64(35151),\n",
       " np.int64(35152),\n",
       " np.int64(35153),\n",
       " np.int64(35154),\n",
       " np.int64(35155),\n",
       " np.int64(35156),\n",
       " np.int64(35157),\n",
       " np.int64(35158),\n",
       " np.int64(35322),\n",
       " np.int64(35323),\n",
       " np.int64(35324),\n",
       " np.int64(35325),\n",
       " np.int64(35327),\n",
       " np.int64(35328),\n",
       " np.int64(35329),\n",
       " np.int64(35330),\n",
       " np.int64(35331),\n",
       " np.int64(35332),\n",
       " np.int64(35333),\n",
       " np.int64(35334),\n",
       " np.int64(35335),\n",
       " np.int64(35336),\n",
       " np.int64(35337),\n",
       " np.int64(35338),\n",
       " np.int64(35339),\n",
       " np.int64(35340),\n",
       " np.int64(35341),\n",
       " np.int64(35342),\n",
       " np.int64(35343),\n",
       " np.int64(35344),\n",
       " np.int64(35345),\n",
       " np.int64(35346),\n",
       " np.int64(35347),\n",
       " np.int64(35348),\n",
       " np.int64(35349),\n",
       " np.int64(35350),\n",
       " np.int64(35351),\n",
       " np.int64(35352),\n",
       " np.int64(35353),\n",
       " np.int64(35354),\n",
       " np.int64(35355),\n",
       " np.int64(35356),\n",
       " np.int64(35357),\n",
       " np.int64(35358),\n",
       " np.int64(35359),\n",
       " np.int64(35360),\n",
       " np.int64(35361),\n",
       " np.int64(35362),\n",
       " np.int64(35363),\n",
       " np.int64(35364),\n",
       " np.int64(35365),\n",
       " np.int64(35366),\n",
       " np.int64(35367),\n",
       " np.int64(35368),\n",
       " np.int64(35369),\n",
       " np.int64(35370),\n",
       " np.int64(35371),\n",
       " np.int64(35397),\n",
       " np.int64(35398),\n",
       " np.int64(35399),\n",
       " np.int64(35426),\n",
       " np.int64(35573),\n",
       " np.int64(35579),\n",
       " np.int64(35580),\n",
       " np.int64(35581),\n",
       " np.int64(35582),\n",
       " np.int64(35583),\n",
       " np.int64(35585),\n",
       " np.int64(35586),\n",
       " np.int64(35587),\n",
       " np.int64(35588),\n",
       " np.int64(35589),\n",
       " np.int64(35590),\n",
       " np.int64(35591),\n",
       " np.int64(35592),\n",
       " np.int64(35593),\n",
       " np.int64(35594),\n",
       " np.int64(35595),\n",
       " np.int64(35596),\n",
       " np.int64(35597),\n",
       " np.int64(35599),\n",
       " np.int64(35600),\n",
       " np.int64(35601),\n",
       " np.int64(35602),\n",
       " np.int64(35603),\n",
       " np.int64(35604),\n",
       " np.int64(35605),\n",
       " np.int64(35606),\n",
       " np.int64(35607),\n",
       " np.int64(35608),\n",
       " np.int64(35609),\n",
       " np.int64(35610),\n",
       " np.int64(35611),\n",
       " np.int64(35612),\n",
       " np.int64(35613),\n",
       " np.int64(35614),\n",
       " np.int64(35615),\n",
       " np.int64(35616),\n",
       " np.int64(35617),\n",
       " np.int64(35618),\n",
       " np.int64(35619),\n",
       " np.int64(35620),\n",
       " np.int64(35621),\n",
       " np.int64(35622),\n",
       " np.int64(35705)}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_bot_baseline_wide.shape)\n",
    "\n",
    "array_fewer = np.array([28922, 28923, 28924, 28932, 28933, 28934, 28935, 28936, 28937, 28938, 28958, 28959, 28960, 28985, 28986, 28987, 28988, 28989, 28990, 28991, 28992, 28993, 28994, 28995, 29021, 29022, 29023, 29024, 29025, 29026, 29027, 29028, 29029, 29030, 29031, 29032, 29033, 29034, 29035, 29036, 29037, 29066, 29067, 29068, 29069, 29070, 29071, 29072, 29074, 29075, 29077, 29108, 29109, 29110, 29111, 29112, 29113, 29114, 29115, 29116, 29117, 29119, 29162, 29163, 29164, 29165, 29166, 29168, 29169, 29170, 29171, 29172, 29173, 29174, 29175, 29176, 29177, 29200, 29201, 29202, 29203, 29204, 29205, 29206, 29207, 29208, 29209, 29210, 29211, 29248, 29249, 29250, 29251, 29252, 29253, 29254, 29255, 29256, 29257, 29258, 29296, 29297, 29298, 29299, 29300, 29301, 29302, 29303, 29304, 29305, 29306, 29347, 29348, 29349, 29350, 29351, 29353, 29354, 29355, 29356, 29358, 29359, 29360, 29361, 29362, 29414, 29415, 29417, 29418, 29419, 29420, 29421, 29422, 29423, 29460, 29461, 29462, 29463, 29464, 29465, 29466, 29467, 29471, 29472, 29503, 29504, 29505, 29506, 29507, 29508, 29510, 29511, 29512, 29513, 29556, 29557, 29558, 29559, 29560, 29561, 29562, 29563, 29564, 29565, 29566, 29567, 29568, 29569, 29635, 29636, 29637, 29638, 29639, 29640, 29641, 29642, 29643, 29644, 29645, 29646, 29647, 29648, 29649, 29650, 29714, 29715, 29716, 29717, 29718, 29719, 29720, 29721, 29722, 29723, 29724, 29725, 29726, 29727, 29728, 29729, 29771, 29773, 29774, 29775, 29776, 29777, 29778, 29779, 29780, 29781, 29828, 29829, 29830, 29831, 29832, 29833, 29834, 29835, 29836, 29837, 29838, 29839, 29840, 29908, 29909, 29910, 29911, 29912, 29913, 29914, 29915, 29916, 29917, 29940, 29941, 29942, 29943, 29944, 29945, 29946, 29947, 29948, 29949, 29950, 29951, 29952, 29953, 29954, 29985, 29987, 29988, 29989, 29990, 29991, 29992, 29993, 29994, 29995, 29996, 29997, 29998, 30079, 30080, 30081, 30082, 30083, 30084, 30085, 30086, 30087, 30088, 30089, 30090, 30091, 30120, 30121, 30122, 30123, 30124, 30125, 30126, 30127, 30154, 30155, 30156, 30157, 30158, 30159, 30160, 30161, 30162, 30193, 30194, 30196, 30197, 30198, 30199, 30200, 30248, 30250, 30251, 30252, 30253, 30254, 30255, 30256, 30257, 30281, 30282, 30283, 30284, 30285, 30286, 30287, 30288, 30289, 30290, 30317, 30318, 30320, 30321, 30322, 30323, 30324, 30348, 30349, 30350, 30351, 30352, 30353, 30385, 30386, 30387, 30388, 30389, 30392, 30393, 30394, 30395, 30435, 30437, 30438, 30439, 30440, 30441, 30442, 30443, 30444, 30445, 30446, 30447, 30496, 30497, 30498, 30499, 30500, 30501, 30502, 30503, 30504, 30505, 30532, 30533, 30534, 30535, 30536, 30537, 30576, 30577, 30578, 30579, 30580, 30581, 30582, 30583, 30584, 30585, 30586, 30587, 30613, 30614, 30615, 30617, 30637, 30638, 30639, 30640, 30641, 30723, 30724, 30725, 30726, 30740, 30741, 30787, 30791, 30792, 30793, 30794, 30795, 30796, 30797])\n",
    "\n",
    "# List all questions in df_bot_baseline_wide\n",
    "array_new = df_bot_baseline_wide['bot_question_id'].unique()\n",
    "\n",
    "# What's the difference? between questions pre-median fix and questions now (more now):\n",
    "diff = set(array_new) - set(array_fewer)\n",
    "\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "cellView": "form",
    "id": "XceLWcgCPNw-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bot</th>\n",
       "      <th>Baseline_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metac-o1</td>\n",
       "      <td>8861.959039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metac-o1-preview</td>\n",
       "      <td>8849.559824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bot_median</td>\n",
       "      <td>8567.705563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acm_bot</td>\n",
       "      <td>7605.922314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>manticAI</td>\n",
       "      <td>7061.660958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Bot  Baseline_Score\n",
       "Rank                                  \n",
       "1             metac-o1     8861.959039\n",
       "2     metac-o1-preview     8849.559824\n",
       "3           bot_median     8567.705563\n",
       "4              acm_bot     7605.922314\n",
       "5             manticAI     7061.660958"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bot</th>\n",
       "      <th>Baseline_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bot_Pepa</td>\n",
       "      <td>-510.750607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Grizeu_Bot</td>\n",
       "      <td>-714.098920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ajf-bot</td>\n",
       "      <td>-776.386700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>minefrac1</td>\n",
       "      <td>-905.116263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RPM_bot</td>\n",
       "      <td>-911.357676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bot  Baseline_Score\n",
       "Rank                            \n",
       "42      Bot_Pepa     -510.750607\n",
       "43    Grizeu_Bot     -714.098920\n",
       "44       ajf-bot     -776.386700\n",
       "45     minefrac1     -905.116263\n",
       "46       RPM_bot     -911.357676"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Bot Baseline Leaderboard\n",
    "\n",
    "# Calculate the total score for each bot\n",
    "total_scores = df_bot_baseline_wide.iloc[:, 1:].fillna(0).sum()\n",
    "\n",
    "# Create a new dataframe with the total scores\n",
    "df_total_scores = pd.DataFrame({'Bot': total_scores.index, 'Baseline_Score': total_scores.values})\n",
    "\n",
    "# Sort the dataframe by Total_Score in descending order\n",
    "df_total_scores_sorted = df_total_scores.sort_values('Baseline_Score', ascending=False)\n",
    "\n",
    "# Add a Rank column\n",
    "df_total_scores_sorted['Rank'] = range(1, len(df_total_scores_sorted) + 1)\n",
    "\n",
    "# Set Rank as the index\n",
    "df_total_scores_ranked = df_total_scores_sorted.set_index('Rank')\n",
    "\n",
    "# Display the result\n",
    "display_head_and_tail(df_total_scores_ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Make sure df_bot_baseline_wide has ONE forecast per (forecaster, question_id) pair\n",
    "# Check for duplicates\n",
    "print(df_bot_baseline_wide.duplicated(subset=['bot_question_id', 'bot_median']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "cellView": "form",
    "id": "iRDMoH7hTBEq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bot</th>\n",
       "      <th>Peer Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metac-o1</td>\n",
       "      <td>3864.168122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metac-o1-preview</td>\n",
       "      <td>3162.155445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bot_median</td>\n",
       "      <td>2974.983652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manticAI</td>\n",
       "      <td>2142.538438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>metac-Gemini-Exp-1206</td>\n",
       "      <td>2072.216227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acm_bot</td>\n",
       "      <td>1876.466009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>twsummerbot</td>\n",
       "      <td>1763.532046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>metac-perplexity</td>\n",
       "      <td>1697.555196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GreeneiBot2</td>\n",
       "      <td>1603.998618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cookics_bot_TEST</td>\n",
       "      <td>1140.390796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>metac-claude-3-5-sonnet-latest</td>\n",
       "      <td>1134.209821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SynapseSeer</td>\n",
       "      <td>1066.533051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CumulativeBot</td>\n",
       "      <td>1030.716475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pgodzinai</td>\n",
       "      <td>926.081448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jkraybill_bot</td>\n",
       "      <td>627.932509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>metac-deepseek-r1</td>\n",
       "      <td>614.572462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>question_weight</td>\n",
       "      <td>378.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>metac-exa</td>\n",
       "      <td>265.384263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MWG</td>\n",
       "      <td>215.551323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>annabot</td>\n",
       "      <td>21.125670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>andrewsiah</td>\n",
       "      <td>-4.170684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cobyj-bot</td>\n",
       "      <td>-15.593332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>X_bot</td>\n",
       "      <td>-16.052813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pianobot</td>\n",
       "      <td>-20.745921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CatrachoCaster</td>\n",
       "      <td>-214.389722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KevinTestBot</td>\n",
       "      <td>-244.046973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>jonahsingerbot</td>\n",
       "      <td>-318.088290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>krm-bot</td>\n",
       "      <td>-387.131345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ProfessorSP</td>\n",
       "      <td>-406.072162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mmBot</td>\n",
       "      <td>-453.312468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>metac-grok-2-1212</td>\n",
       "      <td>-492.938695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bean_bot</td>\n",
       "      <td>-494.373003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4Shadower</td>\n",
       "      <td>-586.017986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>metac-claude-3-5-sonnet-20240620</td>\n",
       "      <td>-647.579684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>swingswish</td>\n",
       "      <td>-763.021897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RPM_bot</td>\n",
       "      <td>-905.938514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>metac-Llama-3.1</td>\n",
       "      <td>-1029.014161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>InstitutPelFutur</td>\n",
       "      <td>-1087.748963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>wunderplumb</td>\n",
       "      <td>-1189.786803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>VeritasAI</td>\n",
       "      <td>-1521.091541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NextWorldLab</td>\n",
       "      <td>-1565.096041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bot_Pepa</td>\n",
       "      <td>-1589.575284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>laylaps</td>\n",
       "      <td>-1665.296188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>minefrac1</td>\n",
       "      <td>-1850.747385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Grizeu_Bot</td>\n",
       "      <td>-1898.666894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>metac-gpt-4o</td>\n",
       "      <td>-2618.918368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ajf-bot</td>\n",
       "      <td>-3239.712801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bot   Peer Score\n",
       "Rank                                               \n",
       "1                             metac-o1  3864.168122\n",
       "2                     metac-o1-preview  3162.155445\n",
       "3                           bot_median  2974.983652\n",
       "4                             manticAI  2142.538438\n",
       "5                metac-Gemini-Exp-1206  2072.216227\n",
       "6                              acm_bot  1876.466009\n",
       "7                          twsummerbot  1763.532046\n",
       "8                     metac-perplexity  1697.555196\n",
       "9                          GreeneiBot2  1603.998618\n",
       "10                    cookics_bot_TEST  1140.390796\n",
       "11      metac-claude-3-5-sonnet-latest  1134.209821\n",
       "12                         SynapseSeer  1066.533051\n",
       "13                       CumulativeBot  1030.716475\n",
       "14                           pgodzinai   926.081448\n",
       "15                       jkraybill_bot   627.932509\n",
       "16                   metac-deepseek-r1   614.572462\n",
       "17                     question_weight   378.020000\n",
       "18                           metac-exa   265.384263\n",
       "19                                 MWG   215.551323\n",
       "20                             annabot    21.125670\n",
       "21                          andrewsiah    -4.170684\n",
       "22                           cobyj-bot   -15.593332\n",
       "23                               X_bot   -16.052813\n",
       "24                            pianobot   -20.745921\n",
       "25                      CatrachoCaster  -214.389722\n",
       "26                        KevinTestBot  -244.046973\n",
       "27                      jonahsingerbot  -318.088290\n",
       "28                             krm-bot  -387.131345\n",
       "29                         ProfessorSP  -406.072162\n",
       "30                               mmBot  -453.312468\n",
       "31                   metac-grok-2-1212  -492.938695\n",
       "32                            bean_bot  -494.373003\n",
       "33                           4Shadower  -586.017986\n",
       "34    metac-claude-3-5-sonnet-20240620  -647.579684\n",
       "35                          swingswish  -763.021897\n",
       "36                             RPM_bot  -905.938514\n",
       "37                     metac-Llama-3.1 -1029.014161\n",
       "38                    InstitutPelFutur -1087.748963\n",
       "39                         wunderplumb -1189.786803\n",
       "40                           VeritasAI -1521.091541\n",
       "41                        NextWorldLab -1565.096041\n",
       "42                            Bot_Pepa -1589.575284\n",
       "43                             laylaps -1665.296188\n",
       "44                           minefrac1 -1850.747385\n",
       "45                          Grizeu_Bot -1898.666894\n",
       "46                        metac-gpt-4o -2618.918368\n",
       "47                             ajf-bot -3239.712801"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Bot Peer Leaderboard\n",
    "\n",
    "\"\"\"\n",
    "NOTE: This can be different from the leaderboad on the site IF early closers\n",
    "are excluded (check remove_early_closers bool).\n",
    "\"\"\"\n",
    "\n",
    "df_filled = df_bot_peer_wide.fillna(0)\n",
    "#df_filled = df_filled.drop(['bot_question_id', 'question_weight'], axis=1)\n",
    "\n",
    "# Calculate the total score for each player\n",
    "total_scores = df_filled.sum()\n",
    "\n",
    "# Create a new DataFrame for the leaderboard\n",
    "leaderboard = pd.DataFrame({\n",
    "    'bot': total_scores.index,\n",
    "    'Peer Score': total_scores.values\n",
    "})\n",
    "\n",
    "# Remove bot_question_id from the leaderboard\n",
    "leaderboard = leaderboard[leaderboard['bot'] != 'bot_question_id']\n",
    "\n",
    "# Sort the leaderboard by Total Score in descending order\n",
    "leaderboard = leaderboard.sort_values('Peer Score', ascending=False)\n",
    "\n",
    "# Reset the index and add a 'Rank' column\n",
    "leaderboard = leaderboard.reset_index(drop=True)\n",
    "leaderboard.index += 1\n",
    "leaderboard.index.name = 'Rank'\n",
    "\n",
    "# Display the leaderboard\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD PRO_MEDIAN ROWS\n",
    "\n",
    "# ADD THE PRO MEDIAN SPOT SCORES & REMOVE UNNECESSARY COLUMNS\n",
    "df_pro_scores = df_pro_baseline\n",
    "df_pro_baseline = df_pro_baseline[['question_id', 'question_title', 'question_weight', 'forecaster', 'score', 'resolution']]\n",
    "\n",
    "# Add pro_median rows\n",
    "df_pro_baseline = df_pro_baseline.merge(df_pro_forecasts[['question_id', 'forecaster', 'is_median']], on=['question_id', 'forecaster'], how='left')\n",
    "df_pro_baseline = add_median_rows(df_pro_baseline, 'pro')\n",
    "\n",
    "df_pro_baseline_long = df_pro_baseline.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot_scores = df_bot_scores[df_bot_scores['score_type'] == 'spot_baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO MEDIAN\n",
      "Average baseline: 44.964801909223056\n"
     ]
    }
   ],
   "source": [
    "# Print WEIGHTED average for pro_median\n",
    "print(\"PRO MEDIAN\")\n",
    "pro_median_baseline = df_pro_baseline_long[df_pro_baseline_long['forecaster'] == 'pro_median']\n",
    "print(f'Average baseline: {(pro_median_baseline[\"score\"] * pro_median_baseline[\"question_weight\"]).sum() / pro_median_baseline[\"question_weight\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>forecaster</th>\n",
       "      <th>question_title</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>scheduled_close_time</th>\n",
       "      <th>actual_close_time</th>\n",
       "      <th>question_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>range_min</th>\n",
       "      <th>range_max</th>\n",
       "      <th>open_lower_bound</th>\n",
       "      <th>open_upper_bound</th>\n",
       "      <th>post_id</th>\n",
       "      <th>forecast</th>\n",
       "      <th>is_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31268</td>\n",
       "      <td>Jgalt</td>\n",
       "      <td>For Q1 2025, how many banks will be listed on ...</td>\n",
       "      <td>2025-01-17 19:06:22.013528+00</td>\n",
       "      <td>101465</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31736</td>\n",
       "      <td>[0.001,0.568,0.366,0.041,0.024]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31268</td>\n",
       "      <td>MaciekK</td>\n",
       "      <td>For Q1 2025, how many banks will be listed on ...</td>\n",
       "      <td>2025-01-17 19:06:22.013528+00</td>\n",
       "      <td>117580</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31736</td>\n",
       "      <td>[0.001,0.62,0.35,0.019,0.01]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31268</td>\n",
       "      <td>OpenSystem</td>\n",
       "      <td>For Q1 2025, how many banks will be listed on ...</td>\n",
       "      <td>2025-01-17 19:06:22.013528+00</td>\n",
       "      <td>120160</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31736</td>\n",
       "      <td>[0.005,0.7,0.25,0.04,0.005]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31268</td>\n",
       "      <td>darkives</td>\n",
       "      <td>For Q1 2025, how many banks will be listed on ...</td>\n",
       "      <td>2025-01-17 19:06:22.013528+00</td>\n",
       "      <td>103907</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31736</td>\n",
       "      <td>[0.001,0.49,0.365,0.1,0.044]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31268</td>\n",
       "      <td>datscilly</td>\n",
       "      <td>For Q1 2025, how many banks will be listed on ...</td>\n",
       "      <td>2025-01-17 19:06:22.013528+00</td>\n",
       "      <td>103777</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>2025-01-20 03:27:00+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31736</td>\n",
       "      <td>[0.001,0.56,0.36,0.059,0.02]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  forecaster                                     question_title  \\\n",
       "0        31268       Jgalt  For Q1 2025, how many banks will be listed on ...   \n",
       "1        31268     MaciekK  For Q1 2025, how many banks will be listed on ...   \n",
       "2        31268  OpenSystem  For Q1 2025, how many banks will be listed on ...   \n",
       "5        31268    darkives  For Q1 2025, how many banks will be listed on ...   \n",
       "6        31268   datscilly  For Q1 2025, how many banks will be listed on ...   \n",
       "\n",
       "                      created_at  author_id resolution  \\\n",
       "0  2025-01-17 19:06:22.013528+00     101465          1   \n",
       "1  2025-01-17 19:06:22.013528+00     117580          1   \n",
       "2  2025-01-17 19:06:22.013528+00     120160          1   \n",
       "5  2025-01-17 19:06:22.013528+00     103907          1   \n",
       "6  2025-01-17 19:06:22.013528+00     103777          1   \n",
       "\n",
       "     scheduled_close_time       actual_close_time  question_weight  \\\n",
       "0  2025-01-20 03:27:00+00  2025-01-20 03:27:00+00              1.0   \n",
       "1  2025-01-20 03:27:00+00  2025-01-20 03:27:00+00              1.0   \n",
       "2  2025-01-20 03:27:00+00  2025-01-20 03:27:00+00              1.0   \n",
       "5  2025-01-20 03:27:00+00  2025-01-20 03:27:00+00              1.0   \n",
       "6  2025-01-20 03:27:00+00  2025-01-20 03:27:00+00              1.0   \n",
       "\n",
       "              type                     options  range_min  range_max  \\\n",
       "0  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "1  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "2  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "5  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "6  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "\n",
       "  open_lower_bound open_upper_bound  post_id                         forecast  \\\n",
       "0            False            False    31736  [0.001,0.568,0.366,0.041,0.024]   \n",
       "1            False            False    31736     [0.001,0.62,0.35,0.019,0.01]   \n",
       "2            False            False    31736      [0.005,0.7,0.25,0.04,0.005]   \n",
       "5            False            False    31736     [0.001,0.49,0.365,0.1,0.044]   \n",
       "6            False            False    31736     [0.001,0.56,0.36,0.059,0.02]   \n",
       "\n",
       "   is_median  \n",
       "0      False  \n",
       "1       True  \n",
       "2      False  \n",
       "5      False  \n",
       "6      False  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro_forecasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "cellView": "form",
    "id": "Yfq0_lDKAMl7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_question_id</th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>question_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>range_min</th>\n",
       "      <th>range_max</th>\n",
       "      <th>open_upper_bound</th>\n",
       "      <th>open_lower_bound</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31268</td>\n",
       "      <td>31262</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0\",\"1\",\"2-3\",\"4-6\",\"&gt;6\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.25,0.3,0.3,0.1,0.05]</td>\n",
       "      <td>[0.014083333333333333,0.6016666666666668,0.178...</td>\n",
       "      <td>[0.30000000000000004,0.31,0.25,0.1060000000000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.009900990099009901,0.39603960396039606,0.44...</td>\n",
       "      <td>[0.014925742574257425,0.5137871287128712,0.334...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31269</td>\n",
       "      <td>31263</td>\n",
       "      <td>86.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td>None</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.05,0.0506666667,0.0513333333,0.052,0.052666...</td>\n",
       "      <td>[0.05,0.0506666667,0.0513333333,0.052,0.052666...</td>\n",
       "      <td>[0.05,0.0508333333,0.0516666667,0.0525,0.05333...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0215944348,0.0218024136,0.0220262706,0.0222...</td>\n",
       "      <td>[0.001,0.001060875,0.0011396,0.0012863125,0.00...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31270</td>\n",
       "      <td>31264</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31280</td>\n",
       "      <td>31274</td>\n",
       "      <td>5-9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[\"0-4\",\"5-9\",\"&gt;9\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.25,0.6,0.15]</td>\n",
       "      <td>[0.7,0.25,0.05]</td>\n",
       "      <td>[0.15000000000000002,0.54,0.31000000000000005]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.25,0.5,0.25]</td>\n",
       "      <td>[0.27499999999999997,0.5125,0.21249999999999997]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.116,0.42,0.464]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31281</td>\n",
       "      <td>31275</td>\n",
       "      <td>119.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0,0.0028571429,0.0057142857,0.0085714286,0....</td>\n",
       "      <td>[0.0,0.004,0.008,0.012,0.016,0.02,0.024,0.028,...</td>\n",
       "      <td>[0.0,0.0025,0.005,0.0075,0.01,0.0125,0.015,0.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0,0.0006552097,0.0013605064,0.0021151815,0....</td>\n",
       "      <td>[0.0,0.0001141583,0.0002446967,0.0003862688,0....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0,0.001311947,0.0026238939,0.0039358409,0.0...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pro_question_id  bot_question_id resolution  question_weight  \\\n",
       "0            31268            31262          0              1.0   \n",
       "1            31269            31263      86.82              1.0   \n",
       "2            31270            31264         no              1.0   \n",
       "3            31280            31274        5-9              1.0   \n",
       "4            31281            31275      119.2              1.0   \n",
       "\n",
       "              type                     options  range_min  range_max  \\\n",
       "0  multiple_choice  [\"0\",\"1\",\"2-3\",\"4-6\",\">6\"]        NaN        NaN   \n",
       "1          numeric                        None       60.0      100.0   \n",
       "2           binary                        None        NaN        NaN   \n",
       "3  multiple_choice          [\"0-4\",\"5-9\",\">9\"]        NaN        NaN   \n",
       "4          numeric                        None        0.0      400.0   \n",
       "\n",
       "  open_upper_bound open_lower_bound  ...  \\\n",
       "0            False            False  ...   \n",
       "1             True             True  ...   \n",
       "2            False            False  ...   \n",
       "3             None             None  ...   \n",
       "4            False            False  ...   \n",
       "\n",
       "                                            metac-o1  \\\n",
       "0                            [0.25,0.3,0.3,0.1,0.05]   \n",
       "1  [0.05,0.0506666667,0.0513333333,0.052,0.052666...   \n",
       "2                                                0.1   \n",
       "3                                    [0.25,0.6,0.15]   \n",
       "4  [0.0,0.0028571429,0.0057142857,0.0085714286,0....   \n",
       "\n",
       "                                    metac-o1-preview  \\\n",
       "0  [0.014083333333333333,0.6016666666666668,0.178...   \n",
       "1  [0.05,0.0506666667,0.0513333333,0.052,0.052666...   \n",
       "2                                                0.1   \n",
       "3                                    [0.7,0.25,0.05]   \n",
       "4  [0.0,0.004,0.008,0.012,0.016,0.02,0.024,0.028,...   \n",
       "\n",
       "                                    metac-perplexity minefrac1  \\\n",
       "0  [0.30000000000000004,0.31,0.25,0.1060000000000...       NaN   \n",
       "1  [0.05,0.0508333333,0.0516666667,0.0525,0.05333...       NaN   \n",
       "2                                                0.1       NaN   \n",
       "3     [0.15000000000000002,0.54,0.31000000000000005]       NaN   \n",
       "4  [0.0,0.0025,0.005,0.0075,0.01,0.0125,0.015,0.0...       NaN   \n",
       "\n",
       "                                               mmBot  \\\n",
       "0  [0.009900990099009901,0.39603960396039606,0.44...   \n",
       "1  [0.0215944348,0.0218024136,0.0220262706,0.0222...   \n",
       "2                                                0.2   \n",
       "3                                    [0.25,0.5,0.25]   \n",
       "4  [0.0,0.0006552097,0.0013605064,0.0021151815,0....   \n",
       "\n",
       "                                           pgodzinai pianobot swingswish  \\\n",
       "0  [0.014925742574257425,0.5137871287128712,0.334...      NaN        NaN   \n",
       "1  [0.001,0.001060875,0.0011396,0.0012863125,0.00...      NaN        NaN   \n",
       "2                                               0.07      NaN        NaN   \n",
       "3   [0.27499999999999997,0.5125,0.21249999999999997]      NaN        NaN   \n",
       "4  [0.0,0.0001141583,0.0002446967,0.0003862688,0....      NaN        NaN   \n",
       "\n",
       "                                         twsummerbot wunderplumb  \n",
       "0                                                NaN         NaN  \n",
       "1                                                NaN         NaN  \n",
       "2                                                NaN         NaN  \n",
       "3                                 [0.116,0.42,0.464]         NaN  \n",
       "4  [0.0,0.001311947,0.0026238939,0.0039358409,0.0...         NaN  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_question_id</th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>question_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>range_min</th>\n",
       "      <th>range_max</th>\n",
       "      <th>open_upper_bound</th>\n",
       "      <th>open_lower_bound</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>35380</td>\n",
       "      <td>35345</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.00</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>35381</td>\n",
       "      <td>35354</td>\n",
       "      <td>no</td>\n",
       "      <td>1.00</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35385</td>\n",
       "      <td>35358</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.00</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>35386</td>\n",
       "      <td>35364</td>\n",
       "      <td>no</td>\n",
       "      <td>0.85</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>35387</td>\n",
       "      <td>35367</td>\n",
       "      <td>no</td>\n",
       "      <td>0.85</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pro_question_id  bot_question_id resolution  question_weight    type  \\\n",
       "94            35380            35345        yes             1.00  binary   \n",
       "95            35381            35354         no             1.00  binary   \n",
       "96            35385            35358        yes             1.00  binary   \n",
       "97            35386            35364         no             0.85  binary   \n",
       "98            35387            35367         no             0.85  binary   \n",
       "\n",
       "   options  range_min  range_max open_upper_bound open_lower_bound  ...  \\\n",
       "94    None        NaN        NaN            False            False  ...   \n",
       "95    None        NaN        NaN            False            False  ...   \n",
       "96    None        NaN        NaN            False            False  ...   \n",
       "97    None        NaN        NaN            False            False  ...   \n",
       "98    None        NaN        NaN            False            False  ...   \n",
       "\n",
       "   metac-o1 metac-o1-preview metac-perplexity minefrac1 mmBot pgodzinai  \\\n",
       "94      0.9              0.9              NaN       NaN  0.95      0.95   \n",
       "95     0.65              0.9              NaN       NaN  0.15       NaN   \n",
       "96     0.85              0.9              NaN       NaN   0.9       NaN   \n",
       "97      0.8             0.85              0.3       NaN  0.85      0.85   \n",
       "98     0.02             0.05             0.03       NaN  0.15      0.05   \n",
       "\n",
       "   pianobot swingswish twsummerbot wunderplumb  \n",
       "94      NaN        0.9       0.762         0.9  \n",
       "95      NaN        0.1       0.126        0.95  \n",
       "96      NaN       0.85       0.828        0.85  \n",
       "97      NaN        0.7       0.132         0.3  \n",
       "98      NaN        0.2        0.27         0.2  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Create df_pro_bot_forecasts, df_bot_vs_pro_peer, df_bot_vs_pro_leaderboard, df_bot_vs_pro_weighted_leaderboard\n",
    "\n",
    "\"\"\"\n",
    "df_pro_bot_forecasts: Spot forecasts for all bots & pro_median, question resolutions, and question weights\n",
    "\n",
    "df_bot_vs_pro_peer: Calculates Peer scores as if there is a tournament with only\n",
    "a single bot and the pro_median. This is the main comparison metric for\n",
    "assessing how a bot compares to the human aggregate. Positive scores mean that\n",
    "the bot did better than the pro_median. Negative scores mean that the bot did\n",
    "worse than the pro_median.\n",
    "\n",
    "df_bot_vs_pro_leaderboard: A leaderboard based on df_bot_vs_pro_peer.\n",
    "\n",
    "df_bot_vs_pro_weighted_leaderboard: A leaderboard based on df_bot_vs_pro_peer\n",
    "with question weighting.\n",
    "\"\"\"\n",
    "\n",
    "# Now pivot df_pro_forecasts; forecaster = columns; forecast = values; index = pro_question_id\n",
    "df_pro_forecasts = df_pro_forecasts.rename(columns={'question_id': 'pro_question_id'})\n",
    "df_pro_forecasts = df_pro_forecasts.pivot(index='pro_question_id', columns='forecaster', values='forecast')\n",
    "# Make the index a column and make it numeric\n",
    "df_pro_forecasts = df_pro_forecasts.reset_index()\n",
    "\n",
    "# Now pivot df_bot_forecasts; forecaster = columns; forecast = values; index = pro_question_id\n",
    "df_bot_forecasts = df_bot_forecasts.rename(columns={'question_id': 'bot_question_id'})\n",
    "df_bot_forecasts = df_bot_forecasts.pivot(index='bot_question_id', columns='forecaster', values='forecast')\n",
    "# Make the index a column and make it numeric\n",
    "df_bot_forecasts = df_bot_forecasts.reset_index()\n",
    "\n",
    "# One row per question, with pro_question_id and bot_question_id and resolution\n",
    "df_pro_bot_resolved_questions_first = df_pro_bot_resolved_questions.groupby(\n",
    "    ['pro_question_id', 'bot_question_id']\n",
    "    ).first().reset_index()[\n",
    "        ['pro_question_id', 'bot_question_id', 'resolution', 'question_weight', 'type', 'options', 'range_min', 'range_max', 'open_upper_bound', 'open_lower_bound']\n",
    "    ]\n",
    "\n",
    "df2 = pd.merge(\n",
    "    df_pro_bot_resolved_questions_first,\n",
    "    df_pro_forecasts[['pro_question_id', 'pro_median']],\n",
    "    on='pro_question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_pro_bot_forecasts = pd.merge(\n",
    "    df2,\n",
    "    df_bot_forecasts,\n",
    "    on='bot_question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "display_head_and_tail(df_pro_bot_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pro_question_id', 'bot_question_id', 'resolution', 'question_weight',\n",
       "       'type', 'options', 'range_min', 'range_max', 'open_upper_bound',\n",
       "       'open_lower_bound', 'pro_median', '4Shadower', 'Bot_Pepa',\n",
       "       'CatrachoCaster', 'CumulativeBot', 'GreeneiBot2', 'Grizeu_Bot',\n",
       "       'InstitutPelFutur', 'KevinTestBot', 'MWG', 'NextWorldLab',\n",
       "       'ProfessorSP', 'RPM_bot', 'SynapseSeer', 'VeritasAI', 'X_bot',\n",
       "       'acm_bot', 'ajf-bot', 'andrewsiah', 'annabot', 'bean_bot', 'bot_median',\n",
       "       'cobyj-bot', 'cookics_bot_TEST', 'jkraybill_bot', 'jonahsingerbot',\n",
       "       'krm-bot', 'laylaps', 'manticAI', 'metac-Gemini-Exp-1206',\n",
       "       'metac-Llama-3.1', 'metac-claude-3-5-sonnet-20240620',\n",
       "       'metac-claude-3-5-sonnet-latest', 'metac-deepseek-r1', 'metac-exa',\n",
       "       'metac-gpt-4o', 'metac-grok-2-1212', 'metac-o1', 'metac-o1-preview',\n",
       "       'metac-perplexity', 'minefrac1', 'mmBot', 'pgodzinai', 'pianobot',\n",
       "       'swingswish', 'twsummerbot', 'wunderplumb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro_bot_forecasts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.009900990099009901,0.42574257425742573,0.39999999999999997,0.12871287128712872,0.03564356435643565]\n",
       "Name: GreeneiBot2, dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure output not truncated\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Show me df_pro_bot_forecasts rows where bot_question_id is 31262 and don't truncate the result?\n",
    "df_pro_bot_forecasts[df_pro_bot_forecasts['bot_question_id'] == 31262]['GreeneiBot2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast resolution as string but ONLY for multiple_choice questions\n",
    "df_pro_bot_forecasts['resolution'] = df_pro_bot_forecasts.apply(\n",
    "    lambda row: str(row['resolution']) if row['type'] == 'multiple_choice' else row['resolution'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro_bot_forecasts['options'] = df_pro_bot_forecasts['options'].apply(parse_options_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_question_id</th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>question_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>range_min</th>\n",
       "      <th>range_max</th>\n",
       "      <th>open_upper_bound</th>\n",
       "      <th>open_lower_bound</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31268</td>\n",
       "      <td>31262</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[0, 1, 2-3, 4-6, &gt;6]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.25,0.3,0.3,0.1,0.05]</td>\n",
       "      <td>[0.014083333333333333,0.6016666666666668,0.17833333333333332,0.04808333333333334,0.15783333333333333]</td>\n",
       "      <td>[0.30000000000000004,0.31,0.25,0.10600000000000001,0.03399999999999991]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.009900990099009901,0.39603960396039606,0.44554455445544555,0.1188118811881188,0.0297029702970297]</td>\n",
       "      <td>[0.014925742574257425,0.5137871287128712,0.3349009900990099,0.10168316831683169,0.03470297029702965]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31269</td>\n",
       "      <td>31263</td>\n",
       "      <td>86.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td>None</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.05, 0.0506666667, 0.0513333333, 0.052, 0.0526666667, 0.0533333333, 0.054, 0.0546666667, 0.0553333333, 0.056, 0.0566666667, 0.0573333333, 0.058, 0.0586666667, 0.0593333333, 0.06, 0.0606666667, 0.0613333333, 0.062, 0.0626666667, 0.0633333333, 0.064, 0.0646666667, 0.0653333333, 0.066, 0.0666666667, 0.0673333333, 0.068, 0.0686666667, 0.0693333333, 0.07, 0.0706666667, 0.0713333333, 0.072, 0.0726666667, 0.0733333333, 0.074, 0.0746666667, 0.0753333333, 0.076, 0.0766666667, 0.0773333333, 0.078, 0.0786666667, 0.0793333333, 0.08, 0.0806666667, 0.0813333333, 0.082, 0.0826666667, 0.0833333333, 0.084, 0.0846666667, 0.0853333333, 0.086, 0.0866666667, 0.0873333333, 0.088, 0.0886666667, 0.0893333333, 0.09, 0.0906666667, 0.0913333333, 0.092, 0.0926666667, 0.0933333333, 0.094, 0.0946666667, 0.0953333333, 0.096, 0.0966666667, 0.0973333333, 0.098, 0.0986666667, 0.0993333333, 0.1, 0.1066666667, 0.1133333333, 0.12, 0.1266666667, 0.1333333333, 0.14, 0.1466666667, 0.1533333333, 0.16, 0.1666666667, 0.1733333333, 0.18, 0.1866666667, 0.1933333333, 0.2, 0.22, 0.24, 0.26, 0.28, 0.3, 0.32, 0.34, 0.36, 0.38, ...]</td>\n",
       "      <td>[0.05, 0.0506666667, 0.0513333333, 0.052, 0.0526666667, 0.0533333333, 0.054, 0.0546666667, 0.0553333333, 0.056, 0.0566666667, 0.0573333333, 0.058, 0.0586666667, 0.0593333333, 0.06, 0.0606666667, 0.0613333333, 0.062, 0.0626666667, 0.0633333333, 0.064, 0.0646666667, 0.0653333333, 0.066, 0.0666666667, 0.0673333333, 0.068, 0.0686666667, 0.0693333333, 0.07, 0.0706666667, 0.0713333333, 0.072, 0.0726666667, 0.0733333333, 0.074, 0.0746666667, 0.0753333333, 0.076, 0.0766666667, 0.0773333333, 0.078, 0.0786666667, 0.0793333333, 0.08, 0.0806666667, 0.0813333333, 0.082, 0.0826666667, 0.0833333333, 0.084, 0.0846666667, 0.0853333333, 0.086, 0.0866666667, 0.0873333333, 0.088, 0.0886666667, 0.0893333333, 0.09, 0.0906666667, 0.0913333333, 0.092, 0.0926666667, 0.0933333333, 0.094, 0.0946666667, 0.0953333333, 0.096, 0.0966666667, 0.0973333333, 0.098, 0.0986666667, 0.0993333333, 0.1, 0.1066666667, 0.1133333333, 0.12, 0.1266666667, 0.1333333333, 0.14, 0.1466666667, 0.1533333333, 0.16, 0.1666666667, 0.1733333333, 0.18, 0.1866666667, 0.1933333333, 0.2, 0.22, 0.24, 0.26, 0.28, 0.3, 0.32, 0.34, 0.36, 0.38, ...]</td>\n",
       "      <td>[0.05, 0.0508333333, 0.0516666667, 0.0525, 0.0533333333, 0.0541666667, 0.055, 0.0558333333, 0.0566666667, 0.0575, 0.0583333333, 0.0591666667, 0.06, 0.0608333333, 0.0616666667, 0.0625, 0.0633333333, 0.0641666667, 0.065, 0.0658333333, 0.0666666667, 0.0675, 0.0683333333, 0.0691666667, 0.07, 0.0708333333, 0.0716666667, 0.0725, 0.0733333333, 0.0741666667, 0.075, 0.0758333333, 0.0766666667, 0.0775, 0.0783333333, 0.0791666667, 0.08, 0.0808333333, 0.0816666667, 0.0825, 0.0833333333, 0.0841666667, 0.085, 0.0858333333, 0.0866666667, 0.0875, 0.0883333333, 0.0891666667, 0.09, 0.0908333333, 0.0916666667, 0.0925, 0.0933333333, 0.0941666667, 0.095, 0.0958333333, 0.0966666667, 0.0975, 0.0983333333, 0.0991666667, 0.1, 0.105, 0.11, 0.115, 0.12, 0.125, 0.13, 0.135, 0.14, 0.145, 0.15, 0.155, 0.16, 0.165, 0.17, 0.175, 0.18, 0.185, 0.19, 0.195, 0.2, 0.22, 0.24, 0.26, 0.28, 0.3, 0.32, 0.34, 0.36, 0.38, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, ...]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0215944348, 0.0218024136, 0.0220262706, 0.0222657692, 0.0225205234, 0.0227900084, 0.0230735761, 0.0233704727, 0.0236798595, 0.0240008339, 0.0243324518, 0.0246737484, 0.0250237592, 0.0253815375, 0.0257461704, 0.0261167925, 0.0264925953, 0.0268728349, 0.0272568365, 0.0276439961, 0.0280337803, 0.0284257242, 0.0288194274, 0.0292145496, 0.0296108048, 0.0300079559, 0.0304058088, 0.0308042061, 0.031203022, 0.0316021576, 0.0320015358, 0.0324010988, 0.0328008038, 0.033200622, 0.0336005361, 0.0340005406, 0.0344006419, 0.0348008594, 0.0352012288, 0.0356018064, 0.0360026751, 0.0364039532, 0.0368058059, 0.0372084598, 0.0376122217, 0.0380175022, 0.0384248443, 0.0388349581, 0.0392487619, 0.0396674303, 0.040092449, 0.0405256766, 0.040969412, 0.0414264662, 0.0419002382, 0.0423947905, 0.0429149226, 0.0434662384, 0.0440552034, 0.0446891875, 0.0453764888, 0.0461263346, 0.0469488546, 0.047855024, 0.0488565752, 0.0499658763, 0.0511957788, 0.0525594355, 0.0540700958, 0.0557408822, 0.0575845575, 0.0596132911, 0.061838434, 0.0642703126, 0.0669180506, 0.0697894271, 0.0728907793, 0.0762269529, 0.0798013046, 0.0836157568, 0.0876709009, 0.091966147, 0.096499911, 0.1012698318, 0.1062730078, 0.1115062433, 0.116966291, 0.1226500836, 0.1285549408, 0.1346787459, 0.1410200827, 0.1475783286, 0.1543537019, 0.1613472593, 0.1685608481, 0.1759970129, 0.1836588644, 0.1915499147, 0.1996738871, 0.208034508, ...]</td>\n",
       "      <td>[0.001, 0.001060875, 0.0011396, 0.0012863125, 0.0015459984, 0.0019048369, 0.0023147701, 0.0027425688, 0.0031719899, 0.0035935463, 0.0040047171, 0.0044081612, 0.0048073678, 0.0052048637, 0.0056023079, 0.0060005117, 0.0063995798, 0.0067992898, 0.0071993689, 0.0075995902, 0.007999808, 0.0083999595, 0.0088000381, 0.0092000616, 0.0096525538, 0.0103347221, 0.0114180238, 0.0128617561, 0.0144931539, 0.0161909912, 0.0178965175, 0.0195748423, 0.0212159342, 0.0228289888, 0.0244265464, 0.0260177161, 0.0276085304, 0.0292020038, 0.0307985773, 0.0323974755, 0.0339977246, 0.0355985069, 0.0371992898, 0.0387998404, 0.0404001295, 0.0420002192, 0.0436001942, 0.0452001261, 0.0468000593, 0.0484758458, 0.0504834257, 0.0530704368, 0.056178071, 0.0595567722, 0.0630314345, 0.0665171977, 0.0699636664, 0.0733563529, 0.0767085411, 0.0800383523, 0.0833589543, 0.0866790344, 0.0900028852, 0.0933311337, 0.0967326953, 0.1004442449, 0.1047006189, 0.1094577119, 0.1144907128, 0.1196353715, 0.1248049846, 0.1299418958, 0.1350232879, 0.1400570021, 0.1452540043, 0.1513017567, 0.1589133116, 0.1680377058, 0.1780770546, 0.1885468618, 0.1991553484, 0.2096896812, 0.2200450325, 0.2302229342, 0.2402681458, 0.2502302229, 0.2601553402, 0.27007834, 0.2800179047, 0.2899799302, 0.2999629146, 0.3099614863, 0.3199691186, 0.3299801956, 0.3403173669, 0.3521487483, 0.3668129253, 0.3844513624, 0.4041888551, 0.4247935739, ...]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31270</td>\n",
       "      <td>31264</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31280</td>\n",
       "      <td>31274</td>\n",
       "      <td>5-9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[0-4, 5-9, &gt;9]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.25,0.6,0.15]</td>\n",
       "      <td>[0.7,0.25,0.05]</td>\n",
       "      <td>[0.15000000000000002,0.54,0.31000000000000005]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.25,0.5,0.25]</td>\n",
       "      <td>[0.27499999999999997,0.5125,0.21249999999999997]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.116,0.42,0.464]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31281</td>\n",
       "      <td>31275</td>\n",
       "      <td>119.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>numeric</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0028571429, 0.0057142857, 0.0085714286, 0.0114285714, 0.0142857143, 0.0171428571, 0.02, 0.0228571429, 0.0257142857, 0.0285714286, 0.0314285714, 0.0342857143, 0.0371428571, 0.04, 0.0428571429, 0.0457142857, 0.0485714286, 0.0514285714, 0.0542857143, 0.0571428571, 0.06, 0.0628571429, 0.0657142857, 0.0685714286, 0.0714285714, 0.0742857143, 0.0771428571, 0.08, 0.0828571429, 0.0857142857, 0.0885714286, 0.0914285714, 0.0942857143, 0.0971428571, 0.1, 0.1066666667, 0.1133333333, 0.12, 0.1266666667, 0.1333333333, 0.14, 0.1466666667, 0.1533333333, 0.16, 0.1666666667, 0.1733333333, 0.18, 0.1866666667, 0.1933333333, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.608, 0.616, 0.624, 0.632, 0.64, 0.648, 0.656, 0.664, 0.672, ...]</td>\n",
       "      <td>[0.0, 0.004, 0.008, 0.012, 0.016, 0.02, 0.024, 0.028, 0.032, 0.036, 0.04, 0.044, 0.048, 0.052, 0.056, 0.06, 0.064, 0.068, 0.072, 0.076, 0.08, 0.084, 0.088, 0.092, 0.096, 0.1, 0.105, 0.11, 0.115, 0.12, 0.125, 0.13, 0.135, 0.14, 0.145, 0.15, 0.155, 0.16, 0.165, 0.17, 0.175, 0.18, 0.185, 0.19, 0.195, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, ...]</td>\n",
       "      <td>[0.0, 0.0025, 0.005, 0.0075, 0.01, 0.0125, 0.015, 0.0175, 0.02, 0.0225, 0.025, 0.0275, 0.03, 0.0325, 0.035, 0.0375, 0.04, 0.0425, 0.045, 0.0475, 0.05, 0.0525, 0.055, 0.0575, 0.06, 0.0625, 0.065, 0.0675, 0.07, 0.0725, 0.075, 0.0775, 0.08, 0.0825, 0.085, 0.0875, 0.09, 0.0925, 0.095, 0.0975, 0.1, 0.105, 0.11, 0.115, 0.12, 0.125, 0.13, 0.135, 0.14, 0.145, 0.15, 0.155, 0.16, 0.165, 0.17, 0.175, 0.18, 0.185, 0.19, 0.195, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.4133333333, 0.4266666667, 0.44, 0.4533333333, 0.4666666667, 0.48, 0.4933333333, 0.5066666667, 0.52, 0.5333333333, 0.5466666667, 0.56, 0.5733333333, 0.5866666667, 0.6, 0.608, 0.616, 0.624, 0.632, ...]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, 0.0006552097, 0.0013605064, 0.0021151815, 0.0029180701, 0.0037675922, 0.0046618077, 0.0055984833, 0.0065751692, 0.0075892831, 0.0086381998, 0.0097193446, 0.0108302867, 0.0119688337, 0.0131331257, 0.014321727, 0.0155337159, 0.0167687729, 0.0180272663, 0.0193103356, 0.020619972, 0.0219590952, 0.0233316264, 0.024742554, 0.0261979914, 0.0277052245, 0.0292727448, 0.030910267, 0.0326287265, 0.034440256, 0.0363581376, 0.0383967303, 0.0405713707, 0.042898249, 0.0453942605, 0.0480768342, 0.0509637431, 0.0540728987, 0.0574221344, 0.0610289827, 0.0649104508, 0.069082799, 0.0735613277, 0.0783601755, 0.0834921337, 0.0889684789, 0.0947988278, 0.1009910149, 0.1075509944, 0.1144827695, 0.1217883466, 0.1294677162, 0.1375188601, 0.1459377845, 0.1547185775, 0.1638534906, 0.173333043, 0.183146147, 0.1932802518, 0.2037215056, 0.2144549309, 0.2254646117, 0.2367338883, 0.2482455564, 0.2599820665, 0.2719257181, 0.2840588463, 0.2963639938, 0.308824066, 0.3214224646, 0.3341431959, 0.3469709515, 0.3598911602, 0.3728900098, 0.3859544391, 0.3990721017, 0.4122313044, 0.4254209242, 0.4386303077, 0.4518491587, 0.4650674199, 0.4782751541, 0.4914624335, 0.5046192399, 0.5177353826, 0.5308004395, 0.5438037232, 0.5567342756, 0.5695808913, 0.5823321691, 0.5949765903, 0.6075026181, 0.6198988152, 0.6321539735, 0.6442572471, 0.6561982838, 0.6679673464, 0.679555418, 0.6909542849, 0.7021565932, ...]</td>\n",
       "      <td>[0.0, 0.0001141583, 0.0002446967, 0.0003862688, 0.0005272579, 0.0006650709, 0.0008243437, 0.0011074433, 0.0016696544, 0.0025699094, 0.0037138357, 0.0049708626, 0.0062610152, 0.0075426566, 0.0089765864, 0.0111726822, 0.0147311078, 0.0195212559, 0.0249547717, 0.0306181288, 0.0363105138, 0.0419407763, 0.0476011969, 0.053516341, 0.0598014349, 0.0663689162, 0.0730761187, 0.0798334547, 0.0865904866, 0.0933196582, 0.1000172031, 0.1066924089, 0.1133554776, 0.1200140176, 0.1266729489, 0.1333343989, 0.1399984689, 0.1466644317, 0.1533314439, 0.1599988203, 0.1666661444, 0.1733332523, 0.1800001372, 0.1866668598, 0.1933334943, 0.2000000995, 0.2066667101, 0.2133333393, 0.2199999878, 0.22666665, 0.2333333196, 0.2399999916, 0.2466666631, 0.2533333329, 0.2600000011, 0.2666666681, 0.2733333345, 0.2800000007, 0.286666667, 0.2933333334, 0.2999999999, 0.3066666665, 0.3133333332, 0.3199999999, 0.3266666666, 0.3333333333, 0.34, 0.3466666667, 0.3533333333, 0.36, 0.3666666667, 0.3733333333, 0.38, 0.3866666667, 0.3934628939, 0.400837331, 0.40925763, 0.4186848364, 0.428718413, 0.4390353607, 0.4494419812, 0.4597974687, 0.4700329298, 0.4801500685, 0.4901790777, 0.500153105, 0.5101028922, 0.5200515519, 0.5300114112, 0.5398722838, 0.5492279015, 0.5576212737, 0.5650210292, 0.571743695, 0.5780856137, 0.5842571713, 0.5904328096, 0.5967209586, 0.603152213, 0.6097133168, ...]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, 0.001311947, 0.0026238939, 0.0039358409, 0.0052477878, 0.0065597348, 0.0078716817, 0.0091836287, 0.0104955756, 0.0118075226, 0.0131194695, 0.0144314165, 0.0157433634, 0.0170553104, 0.0183672573, 0.0196792043, 0.0209911512, 0.0223030982, 0.0236150451, 0.0249269921, 0.026238939, 0.027550886, 0.0288628329, 0.0301747799, 0.0314867268, 0.0327986738, 0.0341106207, 0.0354225677, 0.0367345146, 0.0380464616, 0.0393584085, 0.0406703555, 0.0419823024, 0.0432942494, 0.0446061963, 0.0459181433, 0.0472300902, 0.0485420372, 0.0498539841, 0.0511659311, 0.052477878, 0.053789825, 0.0551017719, 0.0564137189, 0.0577256658, 0.0590376128, 0.0603495597, 0.0616615067, 0.0629734536, 0.0642854006, 0.0655973475, 0.0669092945, 0.0682212414, 0.0695331884, 0.0708451353, 0.0721570823, 0.0734690292, 0.0747809762, 0.0760929231, 0.0774048701, 0.078716817, 0.080028764, 0.0813407109, 0.0826526579, 0.0839646048, 0.0852765518, 0.0865884987, 0.0879004457, 0.0902457862, 0.0933094828, 0.0978079399, 0.1023063969, 0.1068048539, 0.111303311, 0.115801768, 0.120300225, 0.124798682, 0.1292971391, 0.1338199508, 0.1388055027, 0.1440933779, 0.1496807808, 0.1571177226, 0.1652387403, 0.1753118263, 0.1904276903, 0.2058197291, 0.2212117678, 0.237030829, 0.2551785571, 0.273870758, 0.2925629589, 0.3115548313, 0.3307464845, 0.3499926649, 0.3692260274, 0.3884136416, 0.407661417, 0.4269091924, 0.4457073638, ...]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pro_question_id  bot_question_id resolution  question_weight  \\\n",
       "0            31268            31262          0              1.0   \n",
       "1            31269            31263      86.82              1.0   \n",
       "2            31270            31264         no              1.0   \n",
       "3            31280            31274        5-9              1.0   \n",
       "4            31281            31275      119.2              1.0   \n",
       "\n",
       "              type               options  range_min  range_max  \\\n",
       "0  multiple_choice  [0, 1, 2-3, 4-6, >6]        NaN        NaN   \n",
       "1          numeric                  None       60.0      100.0   \n",
       "2           binary                  None        NaN        NaN   \n",
       "3  multiple_choice        [0-4, 5-9, >9]        NaN        NaN   \n",
       "4          numeric                  None        0.0      400.0   \n",
       "\n",
       "  open_upper_bound open_lower_bound  ...  \\\n",
       "0            False            False  ...   \n",
       "1             True             True  ...   \n",
       "2            False            False  ...   \n",
       "3             None             None  ...   \n",
       "4            False            False  ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         metac-o1  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [0.25,0.3,0.3,0.1,0.05]   \n",
       "1  [0.05, 0.0506666667, 0.0513333333, 0.052, 0.0526666667, 0.0533333333, 0.054, 0.0546666667, 0.0553333333, 0.056, 0.0566666667, 0.0573333333, 0.058, 0.0586666667, 0.0593333333, 0.06, 0.0606666667, 0.0613333333, 0.062, 0.0626666667, 0.0633333333, 0.064, 0.0646666667, 0.0653333333, 0.066, 0.0666666667, 0.0673333333, 0.068, 0.0686666667, 0.0693333333, 0.07, 0.0706666667, 0.0713333333, 0.072, 0.0726666667, 0.0733333333, 0.074, 0.0746666667, 0.0753333333, 0.076, 0.0766666667, 0.0773333333, 0.078, 0.0786666667, 0.0793333333, 0.08, 0.0806666667, 0.0813333333, 0.082, 0.0826666667, 0.0833333333, 0.084, 0.0846666667, 0.0853333333, 0.086, 0.0866666667, 0.0873333333, 0.088, 0.0886666667, 0.0893333333, 0.09, 0.0906666667, 0.0913333333, 0.092, 0.0926666667, 0.0933333333, 0.094, 0.0946666667, 0.0953333333, 0.096, 0.0966666667, 0.0973333333, 0.098, 0.0986666667, 0.0993333333, 0.1, 0.1066666667, 0.1133333333, 0.12, 0.1266666667, 0.1333333333, 0.14, 0.1466666667, 0.1533333333, 0.16, 0.1666666667, 0.1733333333, 0.18, 0.1866666667, 0.1933333333, 0.2, 0.22, 0.24, 0.26, 0.28, 0.3, 0.32, 0.34, 0.36, 0.38, ...]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0.1   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [0.25,0.6,0.15]   \n",
       "4                                                                                                                                                                                  [0.0, 0.0028571429, 0.0057142857, 0.0085714286, 0.0114285714, 0.0142857143, 0.0171428571, 0.02, 0.0228571429, 0.0257142857, 0.0285714286, 0.0314285714, 0.0342857143, 0.0371428571, 0.04, 0.0428571429, 0.0457142857, 0.0485714286, 0.0514285714, 0.0542857143, 0.0571428571, 0.06, 0.0628571429, 0.0657142857, 0.0685714286, 0.0714285714, 0.0742857143, 0.0771428571, 0.08, 0.0828571429, 0.0857142857, 0.0885714286, 0.0914285714, 0.0942857143, 0.0971428571, 0.1, 0.1066666667, 0.1133333333, 0.12, 0.1266666667, 0.1333333333, 0.14, 0.1466666667, 0.1533333333, 0.16, 0.1666666667, 0.1733333333, 0.18, 0.1866666667, 0.1933333333, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.608, 0.616, 0.624, 0.632, 0.64, 0.648, 0.656, 0.664, 0.672, ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 metac-o1-preview  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [0.014083333333333333,0.6016666666666668,0.17833333333333332,0.04808333333333334,0.15783333333333333]   \n",
       "1  [0.05, 0.0506666667, 0.0513333333, 0.052, 0.0526666667, 0.0533333333, 0.054, 0.0546666667, 0.0553333333, 0.056, 0.0566666667, 0.0573333333, 0.058, 0.0586666667, 0.0593333333, 0.06, 0.0606666667, 0.0613333333, 0.062, 0.0626666667, 0.0633333333, 0.064, 0.0646666667, 0.0653333333, 0.066, 0.0666666667, 0.0673333333, 0.068, 0.0686666667, 0.0693333333, 0.07, 0.0706666667, 0.0713333333, 0.072, 0.0726666667, 0.0733333333, 0.074, 0.0746666667, 0.0753333333, 0.076, 0.0766666667, 0.0773333333, 0.078, 0.0786666667, 0.0793333333, 0.08, 0.0806666667, 0.0813333333, 0.082, 0.0826666667, 0.0833333333, 0.084, 0.0846666667, 0.0853333333, 0.086, 0.0866666667, 0.0873333333, 0.088, 0.0886666667, 0.0893333333, 0.09, 0.0906666667, 0.0913333333, 0.092, 0.0926666667, 0.0933333333, 0.094, 0.0946666667, 0.0953333333, 0.096, 0.0966666667, 0.0973333333, 0.098, 0.0986666667, 0.0993333333, 0.1, 0.1066666667, 0.1133333333, 0.12, 0.1266666667, 0.1333333333, 0.14, 0.1466666667, 0.1533333333, 0.16, 0.1666666667, 0.1733333333, 0.18, 0.1866666667, 0.1933333333, 0.2, 0.22, 0.24, 0.26, 0.28, 0.3, 0.32, 0.34, 0.36, 0.38, ...]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0.1   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [0.7,0.25,0.05]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [0.0, 0.004, 0.008, 0.012, 0.016, 0.02, 0.024, 0.028, 0.032, 0.036, 0.04, 0.044, 0.048, 0.052, 0.056, 0.06, 0.064, 0.068, 0.072, 0.076, 0.08, 0.084, 0.088, 0.092, 0.096, 0.1, 0.105, 0.11, 0.115, 0.12, 0.125, 0.13, 0.135, 0.14, 0.145, 0.15, 0.155, 0.16, 0.165, 0.17, 0.175, 0.18, 0.185, 0.19, 0.195, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               metac-perplexity  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [0.30000000000000004,0.31,0.25,0.10600000000000001,0.03399999999999991]   \n",
       "1  [0.05, 0.0508333333, 0.0516666667, 0.0525, 0.0533333333, 0.0541666667, 0.055, 0.0558333333, 0.0566666667, 0.0575, 0.0583333333, 0.0591666667, 0.06, 0.0608333333, 0.0616666667, 0.0625, 0.0633333333, 0.0641666667, 0.065, 0.0658333333, 0.0666666667, 0.0675, 0.0683333333, 0.0691666667, 0.07, 0.0708333333, 0.0716666667, 0.0725, 0.0733333333, 0.0741666667, 0.075, 0.0758333333, 0.0766666667, 0.0775, 0.0783333333, 0.0791666667, 0.08, 0.0808333333, 0.0816666667, 0.0825, 0.0833333333, 0.0841666667, 0.085, 0.0858333333, 0.0866666667, 0.0875, 0.0883333333, 0.0891666667, 0.09, 0.0908333333, 0.0916666667, 0.0925, 0.0933333333, 0.0941666667, 0.095, 0.0958333333, 0.0966666667, 0.0975, 0.0983333333, 0.0991666667, 0.1, 0.105, 0.11, 0.115, 0.12, 0.125, 0.13, 0.135, 0.14, 0.145, 0.15, 0.155, 0.16, 0.165, 0.17, 0.175, 0.18, 0.185, 0.19, 0.195, 0.2, 0.22, 0.24, 0.26, 0.28, 0.3, 0.32, 0.34, 0.36, 0.38, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, ...]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           0.1   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [0.15000000000000002,0.54,0.31000000000000005]   \n",
       "4                                                                                                                                                                                                                       [0.0, 0.0025, 0.005, 0.0075, 0.01, 0.0125, 0.015, 0.0175, 0.02, 0.0225, 0.025, 0.0275, 0.03, 0.0325, 0.035, 0.0375, 0.04, 0.0425, 0.045, 0.0475, 0.05, 0.0525, 0.055, 0.0575, 0.06, 0.0625, 0.065, 0.0675, 0.07, 0.0725, 0.075, 0.0775, 0.08, 0.0825, 0.085, 0.0875, 0.09, 0.0925, 0.095, 0.0975, 0.1, 0.105, 0.11, 0.115, 0.12, 0.125, 0.13, 0.135, 0.14, 0.145, 0.15, 0.155, 0.16, 0.165, 0.17, 0.175, 0.18, 0.185, 0.19, 0.195, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.4133333333, 0.4266666667, 0.44, 0.4533333333, 0.4666666667, 0.48, 0.4933333333, 0.5066666667, 0.52, 0.5333333333, 0.5466666667, 0.56, 0.5733333333, 0.5866666667, 0.6, 0.608, 0.616, 0.624, 0.632, ...]   \n",
       "\n",
       "  minefrac1  \\\n",
       "0       NaN   \n",
       "1       NaN   \n",
       "2       NaN   \n",
       "3       NaN   \n",
       "4       NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 mmBot  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [0.009900990099009901,0.39603960396039606,0.44554455445544555,0.1188118811881188,0.0297029702970297]   \n",
       "1  [0.0215944348, 0.0218024136, 0.0220262706, 0.0222657692, 0.0225205234, 0.0227900084, 0.0230735761, 0.0233704727, 0.0236798595, 0.0240008339, 0.0243324518, 0.0246737484, 0.0250237592, 0.0253815375, 0.0257461704, 0.0261167925, 0.0264925953, 0.0268728349, 0.0272568365, 0.0276439961, 0.0280337803, 0.0284257242, 0.0288194274, 0.0292145496, 0.0296108048, 0.0300079559, 0.0304058088, 0.0308042061, 0.031203022, 0.0316021576, 0.0320015358, 0.0324010988, 0.0328008038, 0.033200622, 0.0336005361, 0.0340005406, 0.0344006419, 0.0348008594, 0.0352012288, 0.0356018064, 0.0360026751, 0.0364039532, 0.0368058059, 0.0372084598, 0.0376122217, 0.0380175022, 0.0384248443, 0.0388349581, 0.0392487619, 0.0396674303, 0.040092449, 0.0405256766, 0.040969412, 0.0414264662, 0.0419002382, 0.0423947905, 0.0429149226, 0.0434662384, 0.0440552034, 0.0446891875, 0.0453764888, 0.0461263346, 0.0469488546, 0.047855024, 0.0488565752, 0.0499658763, 0.0511957788, 0.0525594355, 0.0540700958, 0.0557408822, 0.0575845575, 0.0596132911, 0.061838434, 0.0642703126, 0.0669180506, 0.0697894271, 0.0728907793, 0.0762269529, 0.0798013046, 0.0836157568, 0.0876709009, 0.091966147, 0.096499911, 0.1012698318, 0.1062730078, 0.1115062433, 0.116966291, 0.1226500836, 0.1285549408, 0.1346787459, 0.1410200827, 0.1475783286, 0.1543537019, 0.1613472593, 0.1685608481, 0.1759970129, 0.1836588644, 0.1915499147, 0.1996738871, 0.208034508, ...]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  0.2   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [0.25,0.5,0.25]   \n",
       "4            [0.0, 0.0006552097, 0.0013605064, 0.0021151815, 0.0029180701, 0.0037675922, 0.0046618077, 0.0055984833, 0.0065751692, 0.0075892831, 0.0086381998, 0.0097193446, 0.0108302867, 0.0119688337, 0.0131331257, 0.014321727, 0.0155337159, 0.0167687729, 0.0180272663, 0.0193103356, 0.020619972, 0.0219590952, 0.0233316264, 0.024742554, 0.0261979914, 0.0277052245, 0.0292727448, 0.030910267, 0.0326287265, 0.034440256, 0.0363581376, 0.0383967303, 0.0405713707, 0.042898249, 0.0453942605, 0.0480768342, 0.0509637431, 0.0540728987, 0.0574221344, 0.0610289827, 0.0649104508, 0.069082799, 0.0735613277, 0.0783601755, 0.0834921337, 0.0889684789, 0.0947988278, 0.1009910149, 0.1075509944, 0.1144827695, 0.1217883466, 0.1294677162, 0.1375188601, 0.1459377845, 0.1547185775, 0.1638534906, 0.173333043, 0.183146147, 0.1932802518, 0.2037215056, 0.2144549309, 0.2254646117, 0.2367338883, 0.2482455564, 0.2599820665, 0.2719257181, 0.2840588463, 0.2963639938, 0.308824066, 0.3214224646, 0.3341431959, 0.3469709515, 0.3598911602, 0.3728900098, 0.3859544391, 0.3990721017, 0.4122313044, 0.4254209242, 0.4386303077, 0.4518491587, 0.4650674199, 0.4782751541, 0.4914624335, 0.5046192399, 0.5177353826, 0.5308004395, 0.5438037232, 0.5567342756, 0.5695808913, 0.5823321691, 0.5949765903, 0.6075026181, 0.6198988152, 0.6321539735, 0.6442572471, 0.6561982838, 0.6679673464, 0.679555418, 0.6909542849, 0.7021565932, ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        pgodzinai  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [0.014925742574257425,0.5137871287128712,0.3349009900990099,0.10168316831683169,0.03470297029702965]   \n",
       "1  [0.001, 0.001060875, 0.0011396, 0.0012863125, 0.0015459984, 0.0019048369, 0.0023147701, 0.0027425688, 0.0031719899, 0.0035935463, 0.0040047171, 0.0044081612, 0.0048073678, 0.0052048637, 0.0056023079, 0.0060005117, 0.0063995798, 0.0067992898, 0.0071993689, 0.0075995902, 0.007999808, 0.0083999595, 0.0088000381, 0.0092000616, 0.0096525538, 0.0103347221, 0.0114180238, 0.0128617561, 0.0144931539, 0.0161909912, 0.0178965175, 0.0195748423, 0.0212159342, 0.0228289888, 0.0244265464, 0.0260177161, 0.0276085304, 0.0292020038, 0.0307985773, 0.0323974755, 0.0339977246, 0.0355985069, 0.0371992898, 0.0387998404, 0.0404001295, 0.0420002192, 0.0436001942, 0.0452001261, 0.0468000593, 0.0484758458, 0.0504834257, 0.0530704368, 0.056178071, 0.0595567722, 0.0630314345, 0.0665171977, 0.0699636664, 0.0733563529, 0.0767085411, 0.0800383523, 0.0833589543, 0.0866790344, 0.0900028852, 0.0933311337, 0.0967326953, 0.1004442449, 0.1047006189, 0.1094577119, 0.1144907128, 0.1196353715, 0.1248049846, 0.1299418958, 0.1350232879, 0.1400570021, 0.1452540043, 0.1513017567, 0.1589133116, 0.1680377058, 0.1780770546, 0.1885468618, 0.1991553484, 0.2096896812, 0.2200450325, 0.2302229342, 0.2402681458, 0.2502302229, 0.2601553402, 0.27007834, 0.2800179047, 0.2899799302, 0.2999629146, 0.3099614863, 0.3199691186, 0.3299801956, 0.3403173669, 0.3521487483, 0.3668129253, 0.3844513624, 0.4041888551, 0.4247935739, ...]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0.07   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [0.27499999999999997,0.5125,0.21249999999999997]   \n",
       "4                               [0.0, 0.0001141583, 0.0002446967, 0.0003862688, 0.0005272579, 0.0006650709, 0.0008243437, 0.0011074433, 0.0016696544, 0.0025699094, 0.0037138357, 0.0049708626, 0.0062610152, 0.0075426566, 0.0089765864, 0.0111726822, 0.0147311078, 0.0195212559, 0.0249547717, 0.0306181288, 0.0363105138, 0.0419407763, 0.0476011969, 0.053516341, 0.0598014349, 0.0663689162, 0.0730761187, 0.0798334547, 0.0865904866, 0.0933196582, 0.1000172031, 0.1066924089, 0.1133554776, 0.1200140176, 0.1266729489, 0.1333343989, 0.1399984689, 0.1466644317, 0.1533314439, 0.1599988203, 0.1666661444, 0.1733332523, 0.1800001372, 0.1866668598, 0.1933334943, 0.2000000995, 0.2066667101, 0.2133333393, 0.2199999878, 0.22666665, 0.2333333196, 0.2399999916, 0.2466666631, 0.2533333329, 0.2600000011, 0.2666666681, 0.2733333345, 0.2800000007, 0.286666667, 0.2933333334, 0.2999999999, 0.3066666665, 0.3133333332, 0.3199999999, 0.3266666666, 0.3333333333, 0.34, 0.3466666667, 0.3533333333, 0.36, 0.3666666667, 0.3733333333, 0.38, 0.3866666667, 0.3934628939, 0.400837331, 0.40925763, 0.4186848364, 0.428718413, 0.4390353607, 0.4494419812, 0.4597974687, 0.4700329298, 0.4801500685, 0.4901790777, 0.500153105, 0.5101028922, 0.5200515519, 0.5300114112, 0.5398722838, 0.5492279015, 0.5576212737, 0.5650210292, 0.571743695, 0.5780856137, 0.5842571713, 0.5904328096, 0.5967209586, 0.603152213, 0.6097133168, ...]   \n",
       "\n",
       "  pianobot swingswish  \\\n",
       "0      NaN        NaN   \n",
       "1      NaN        NaN   \n",
       "2      NaN        NaN   \n",
       "3      NaN        NaN   \n",
       "4      NaN        NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              twsummerbot  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [0.116,0.42,0.464]   \n",
       "4  [0.0, 0.001311947, 0.0026238939, 0.0039358409, 0.0052477878, 0.0065597348, 0.0078716817, 0.0091836287, 0.0104955756, 0.0118075226, 0.0131194695, 0.0144314165, 0.0157433634, 0.0170553104, 0.0183672573, 0.0196792043, 0.0209911512, 0.0223030982, 0.0236150451, 0.0249269921, 0.026238939, 0.027550886, 0.0288628329, 0.0301747799, 0.0314867268, 0.0327986738, 0.0341106207, 0.0354225677, 0.0367345146, 0.0380464616, 0.0393584085, 0.0406703555, 0.0419823024, 0.0432942494, 0.0446061963, 0.0459181433, 0.0472300902, 0.0485420372, 0.0498539841, 0.0511659311, 0.052477878, 0.053789825, 0.0551017719, 0.0564137189, 0.0577256658, 0.0590376128, 0.0603495597, 0.0616615067, 0.0629734536, 0.0642854006, 0.0655973475, 0.0669092945, 0.0682212414, 0.0695331884, 0.0708451353, 0.0721570823, 0.0734690292, 0.0747809762, 0.0760929231, 0.0774048701, 0.078716817, 0.080028764, 0.0813407109, 0.0826526579, 0.0839646048, 0.0852765518, 0.0865884987, 0.0879004457, 0.0902457862, 0.0933094828, 0.0978079399, 0.1023063969, 0.1068048539, 0.111303311, 0.115801768, 0.120300225, 0.124798682, 0.1292971391, 0.1338199508, 0.1388055027, 0.1440933779, 0.1496807808, 0.1571177226, 0.1652387403, 0.1753118263, 0.1904276903, 0.2058197291, 0.2212117678, 0.237030829, 0.2551785571, 0.273870758, 0.2925629589, 0.3115548313, 0.3307464845, 0.3499926649, 0.3692260274, 0.3884136416, 0.407661417, 0.4269091924, 0.4457073638, ...]   \n",
       "\n",
       "  wunderplumb  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_question_id</th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>question_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>range_min</th>\n",
       "      <th>range_max</th>\n",
       "      <th>open_upper_bound</th>\n",
       "      <th>open_lower_bound</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>35380</td>\n",
       "      <td>35345</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.00</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>35381</td>\n",
       "      <td>35354</td>\n",
       "      <td>no</td>\n",
       "      <td>1.00</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35385</td>\n",
       "      <td>35358</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.00</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>35386</td>\n",
       "      <td>35364</td>\n",
       "      <td>no</td>\n",
       "      <td>0.85</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>35387</td>\n",
       "      <td>35367</td>\n",
       "      <td>no</td>\n",
       "      <td>0.85</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pro_question_id  bot_question_id resolution  question_weight    type  \\\n",
       "94            35380            35345        yes             1.00  binary   \n",
       "95            35381            35354         no             1.00  binary   \n",
       "96            35385            35358        yes             1.00  binary   \n",
       "97            35386            35364         no             0.85  binary   \n",
       "98            35387            35367         no             0.85  binary   \n",
       "\n",
       "   options  range_min  range_max open_upper_bound open_lower_bound  ...  \\\n",
       "94    None        NaN        NaN            False            False  ...   \n",
       "95    None        NaN        NaN            False            False  ...   \n",
       "96    None        NaN        NaN            False            False  ...   \n",
       "97    None        NaN        NaN            False            False  ...   \n",
       "98    None        NaN        NaN            False            False  ...   \n",
       "\n",
       "   metac-o1 metac-o1-preview metac-perplexity minefrac1 mmBot pgodzinai  \\\n",
       "94      0.9              0.9              NaN       NaN  0.95      0.95   \n",
       "95     0.65              0.9              NaN       NaN  0.15       NaN   \n",
       "96     0.85              0.9              NaN       NaN   0.9       NaN   \n",
       "97      0.8             0.85              0.3       NaN  0.85      0.85   \n",
       "98     0.02             0.05             0.03       NaN  0.15      0.05   \n",
       "\n",
       "   pianobot swingswish twsummerbot wunderplumb  \n",
       "94      NaN        0.9       0.762         0.9  \n",
       "95      NaN        0.1       0.126        0.95  \n",
       "96      NaN       0.85       0.828        0.85  \n",
       "97      NaN        0.7       0.132         0.3  \n",
       "98      NaN        0.2        0.27         0.2  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple function to parse CDF strings for numeric questions\n",
    "def parse_numeric_forecasts(df):\n",
    "    \"\"\"\n",
    "    Parse CDF strings for numeric questions in-place.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with forecast data\n",
    "    \"\"\"\n",
    "    # Get numeric questions\n",
    "    numeric_mask = df['type'] == 'numeric'\n",
    "\n",
    "    # List of columns to process\n",
    "    forecast_cols = [col for col in df.columns if col in all_bots or col in ['pro_median', 'bot_median']]\n",
    "\n",
    "    # Process each column\n",
    "    for col in forecast_cols:\n",
    "        # Process only for numeric questions and only where the column exists\n",
    "        if col in df.columns:\n",
    "            for idx in df[numeric_mask].index:\n",
    "                value = df.at[idx, col]\n",
    "\n",
    "                # Skip NaN values\n",
    "                if pd.isna(value):\n",
    "                    continue\n",
    "\n",
    "                # Process string values\n",
    "                if isinstance(value, str):\n",
    "                    try:\n",
    "                        # Parse the CDF string to an array\n",
    "                        parsed_array = np.array([float(x) for x in value.strip('[]').split(',')])\n",
    "                        df.at[idx, col] = parsed_array\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not parse {col} at index {idx}: {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Now parse the numeric forecasts\n",
    "df_pro_bot_forecasts = parse_numeric_forecasts(df_pro_bot_forecasts)\n",
    "display_head_and_tail(df_pro_bot_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n",
      "/home/benwilson/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:38: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  peer_score = np.log(forecast_for_resolution / geometric_mean)\n"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "df_bot_vs_pro_peer = calculate_all_peer_scores(df_pro_bot_forecasts, all_bots)\n",
    "# @Check: -> This wasn't implemented when I saw it, so I'm not sure the correct intention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_question_id</th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>question_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>range_min</th>\n",
       "      <th>range_max</th>\n",
       "      <th>open_upper_bound</th>\n",
       "      <th>open_lower_bound</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "      <th>bot_team_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31268</td>\n",
       "      <td>31262</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[0, 1, 2-3, 4-6, &gt;6]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2.644992</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.292635</td>\n",
       "      <td>2.703087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.010635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31280</td>\n",
       "      <td>31274</td>\n",
       "      <td>5-9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[0-4, 5-9, &gt;9]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565314</td>\n",
       "      <td>0.204794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.127833</td>\n",
       "      <td>0.152526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.310155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31292</td>\n",
       "      <td>31286</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[Larry Ellison, Elon Musk, Mark Zuckerberg, Bernard Arnault &amp; family, Jeff Bezos, Someone else]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247562</td>\n",
       "      <td>0.096331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.184571</td>\n",
       "      <td>0.112526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31321</td>\n",
       "      <td>31370</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[0, 1, 2, Greater than 2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518794</td>\n",
       "      <td>-1.211941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.806476</td>\n",
       "      <td>-0.494101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.624154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31368</td>\n",
       "      <td>31366</td>\n",
       "      <td>0% and &lt;5%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[Less than -5%, -5% and &lt;0%, 0% and &lt;5%, Greater than 5%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441833</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.021979</td>\n",
       "      <td>0.200671</td>\n",
       "      <td>0.253781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.325422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pro_question_id  bot_question_id   resolution  question_weight  \\\n",
       "0             31268            31262            0              1.0   \n",
       "3             31280            31274          5-9              1.0   \n",
       "6             31292            31286   Jeff Bezos              1.0   \n",
       "9             31321            31370            0              1.0   \n",
       "13            31368            31366  0% and <5%              1.0   \n",
       "\n",
       "               type  \\\n",
       "0   multiple_choice   \n",
       "3   multiple_choice   \n",
       "6   multiple_choice   \n",
       "9   multiple_choice   \n",
       "13  multiple_choice   \n",
       "\n",
       "                                                                                            options  \\\n",
       "0                                                                              [0, 1, 2-3, 4-6, >6]   \n",
       "3                                                                                    [0-4, 5-9, >9]   \n",
       "6   [Larry Ellison, Elon Musk, Mark Zuckerberg, Bernard Arnault & family, Jeff Bezos, Someone else]   \n",
       "9                                                                         [0, 1, 2, Greater than 2]   \n",
       "13                                      [Less than -5%, -5% and <0%, 0% and <5%, Greater than 5%]   \n",
       "\n",
       "    range_min  range_max open_upper_bound open_lower_bound  ...  \\\n",
       "0         NaN        NaN            False            False  ...   \n",
       "3         NaN        NaN             None             None  ...   \n",
       "6         NaN        NaN            False            False  ...   \n",
       "9         NaN        NaN             None             None  ...   \n",
       "13        NaN        NaN             None             None  ...   \n",
       "\n",
       "   metac-o1-preview  metac-perplexity  minefrac1     mmBot  pgodzinai  \\\n",
       "0          2.644992          5.703782        NaN  2.292635   2.703087   \n",
       "3         -0.565314          0.204794        NaN  0.127833   0.152526   \n",
       "6          0.247562          0.096331        NaN -0.184571   0.112526   \n",
       "9         -0.518794         -1.211941        NaN -0.806476  -0.494101   \n",
       "13         0.441833          0.510826   0.021979  0.200671   0.253781   \n",
       "\n",
       "    pianobot  swingswish  twsummerbot  wunderplumb  bot_team_median  \n",
       "0        NaN         NaN          NaN          NaN         5.010635  \n",
       "3        NaN         NaN    -0.046520          NaN         0.310155  \n",
       "6        NaN         NaN          NaN          NaN         0.112526  \n",
       "9        NaN         NaN    -0.624154          NaN        -0.693147  \n",
       "13       NaN         NaN          NaN          NaN        -0.325422  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_question_id</th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>question_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>range_min</th>\n",
       "      <th>range_max</th>\n",
       "      <th>open_upper_bound</th>\n",
       "      <th>open_lower_bound</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "      <th>bot_team_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>35169</td>\n",
       "      <td>35119</td>\n",
       "      <td>Not in top 50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[0-10, 11-20, 21-30, 31-40, 41-50, Not in top 50]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.879198</td>\n",
       "      <td>-1.780586</td>\n",
       "      <td>-3.007032</td>\n",
       "      <td>-2.879198</td>\n",
       "      <td>-3.390024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.348570</td>\n",
       "      <td>-2.409195</td>\n",
       "      <td>-3.795489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>35170</td>\n",
       "      <td>35121</td>\n",
       "      <td>3 or more</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[0, 1, 2, 3 or more]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656780</td>\n",
       "      <td>-0.300105</td>\n",
       "      <td>-0.523248</td>\n",
       "      <td>0.105361</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.276509</td>\n",
       "      <td>-0.644609</td>\n",
       "      <td>-0.656780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>35171</td>\n",
       "      <td>35123</td>\n",
       "      <td>7.5 and 8.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[&lt;7.5, 7.5 and 8.5, &gt;8.5 and &lt;9.0, 9.0 and 9.5, &gt;9.5]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.321756</td>\n",
       "      <td>-0.265703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.182322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.178330</td>\n",
       "      <td>-0.567984</td>\n",
       "      <td>-0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>35377</td>\n",
       "      <td>35334</td>\n",
       "      <td>Jimmy Patronis</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[Jimmy Patronis, Gay Valimont, Someone else]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069566</td>\n",
       "      <td>-0.048289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.124829</td>\n",
       "      <td>-0.080377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.113529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.147818</td>\n",
       "      <td>-0.124829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>35378</td>\n",
       "      <td>35336</td>\n",
       "      <td>31-49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[0-24, 25-30, 31-49, 50-70, &gt;70]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.704748</td>\n",
       "      <td>-1.704748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.704748</td>\n",
       "      <td>-0.318454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.480973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.749237</td>\n",
       "      <td>-0.480973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pro_question_id  bot_question_id      resolution  question_weight  \\\n",
       "81            35169            35119   Not in top 50              1.0   \n",
       "82            35170            35121       3 or more              1.0   \n",
       "83            35171            35123   7.5 and 8.5              1.0   \n",
       "91            35377            35334  Jimmy Patronis              1.0   \n",
       "92            35378            35336           31-49              1.0   \n",
       "\n",
       "               type  \\\n",
       "81  multiple_choice   \n",
       "82  multiple_choice   \n",
       "83  multiple_choice   \n",
       "91  multiple_choice   \n",
       "92  multiple_choice   \n",
       "\n",
       "                                                      options  range_min  \\\n",
       "81          [0-10, 11-20, 21-30, 31-40, 41-50, Not in top 50]        NaN   \n",
       "82                                       [0, 1, 2, 3 or more]        NaN   \n",
       "83  [<7.5, 7.5 and 8.5, >8.5 and <9.0, 9.0 and 9.5, >9.5]        NaN   \n",
       "91               [Jimmy Patronis, Gay Valimont, Someone else]        NaN   \n",
       "92                           [0-24, 25-30, 31-49, 50-70, >70]        NaN   \n",
       "\n",
       "    range_max open_upper_bound open_lower_bound  ... metac-o1-preview  \\\n",
       "81        NaN            False            False  ...        -2.879198   \n",
       "82        NaN             None             None  ...        -0.656780   \n",
       "83        NaN             None             None  ...        -1.321756   \n",
       "91        NaN            False            False  ...        -0.069566   \n",
       "92        NaN            False            False  ...        -1.704748   \n",
       "\n",
       "    metac-perplexity  minefrac1     mmBot  pgodzinai  pianobot  swingswish  \\\n",
       "81         -1.780586  -3.007032 -2.879198  -3.390024       NaN         NaN   \n",
       "82         -0.300105  -0.523248  0.105361   0.259511       NaN         NaN   \n",
       "83         -0.265703        NaN -0.182322        NaN       NaN         NaN   \n",
       "91         -0.048289        NaN -0.124829  -0.080377       NaN   -0.113529   \n",
       "92         -1.704748        NaN -1.704748  -0.318454       NaN   -0.480973   \n",
       "\n",
       "    twsummerbot  wunderplumb  bot_team_median  \n",
       "81    -2.348570    -2.409195        -3.795489  \n",
       "82     0.276509    -0.644609        -0.656780  \n",
       "83    -0.178330    -0.567984        -0.693147  \n",
       "91          NaN    -0.147818        -0.124829  \n",
       "92          NaN    -0.749237        -0.480973  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_question_id</th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>question_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>range_min</th>\n",
       "      <th>range_max</th>\n",
       "      <th>open_upper_bound</th>\n",
       "      <th>open_lower_bound</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "      <th>bot_team_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31270</td>\n",
       "      <td>31264</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092275</td>\n",
       "      <td>-0.092275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.210058</td>\n",
       "      <td>-0.059485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.149434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31282</td>\n",
       "      <td>31276</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251314</td>\n",
       "      <td>0.441833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.320472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31294</td>\n",
       "      <td>31288</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054067</td>\n",
       "      <td>-0.054067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.111226</td>\n",
       "      <td>-0.147158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.398124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.171850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31338</td>\n",
       "      <td>31334</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054067</td>\n",
       "      <td>-0.057158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.499776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.057158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33876</td>\n",
       "      <td>33751</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008457</td>\n",
       "      <td>0.008457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.068083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.076070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.076070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pro_question_id  bot_question_id resolution  question_weight    type  \\\n",
       "2             31270            31264         no              1.0  binary   \n",
       "5             31282            31276        yes              1.0  binary   \n",
       "8             31294            31288        yes              1.0  binary   \n",
       "12            31338            31334        yes              1.0  binary   \n",
       "16            33876            33751         no              1.0  binary   \n",
       "\n",
       "   options  range_min  range_max open_upper_bound open_lower_bound  ...  \\\n",
       "2     None        NaN        NaN            False            False  ...   \n",
       "5     None        NaN        NaN             None             None  ...   \n",
       "8     None        NaN        NaN            False            False  ...   \n",
       "12    None        NaN        NaN            False            False  ...   \n",
       "16    None        NaN        NaN            False            False  ...   \n",
       "\n",
       "   metac-o1-preview  metac-perplexity  minefrac1     mmBot  pgodzinai  \\\n",
       "2         -0.092275         -0.092275        NaN -0.210058  -0.059485   \n",
       "5         -0.251314          0.441833        NaN  0.510826   0.320472   \n",
       "8         -0.054067         -0.054067        NaN -0.111226  -0.147158   \n",
       "12        -0.182322          0.000000        NaN  0.054067  -0.057158   \n",
       "16         0.008457          0.008457        NaN -0.068083        NaN   \n",
       "\n",
       "    pianobot  swingswish  twsummerbot  wunderplumb  bot_team_median  \n",
       "2        NaN         NaN          NaN          NaN        -0.149434  \n",
       "5        NaN         NaN          NaN          NaN         0.287682  \n",
       "8        NaN         NaN    -0.398124          NaN        -0.171850  \n",
       "12       NaN         NaN    -0.499776          NaN        -0.057158  \n",
       "16       NaN         NaN    -0.076070          NaN        -0.076070  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_question_id</th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>question_weight</th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>range_min</th>\n",
       "      <th>range_max</th>\n",
       "      <th>open_upper_bound</th>\n",
       "      <th>open_lower_bound</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "      <th>bot_team_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>35380</td>\n",
       "      <td>35345</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.00</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.054067</td>\n",
       "      <td>-0.220515</td>\n",
       "      <td>-0.054067</td>\n",
       "      <td>-0.054067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>35381</td>\n",
       "      <td>35354</td>\n",
       "      <td>no</td>\n",
       "      <td>1.00</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.251292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.111226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.054067</td>\n",
       "      <td>-0.083382</td>\n",
       "      <td>-2.944439</td>\n",
       "      <td>-0.111226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35385</td>\n",
       "      <td>35358</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.00</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.074901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.132060</td>\n",
       "      <td>-0.158283</td>\n",
       "      <td>-0.132060</td>\n",
       "      <td>-0.132060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>35386</td>\n",
       "      <td>35364</td>\n",
       "      <td>no</td>\n",
       "      <td>0.85</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.680430</td>\n",
       "      <td>0.628948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.680430</td>\n",
       "      <td>-0.680430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.091255</td>\n",
       "      <td>0.811793</td>\n",
       "      <td>0.628948</td>\n",
       "      <td>-0.091255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>35387</td>\n",
       "      <td>35367</td>\n",
       "      <td>no</td>\n",
       "      <td>0.85</td>\n",
       "      <td>binary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.112251</td>\n",
       "      <td>-0.017709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.163782</td>\n",
       "      <td>-0.241614</td>\n",
       "      <td>-0.163782</td>\n",
       "      <td>-0.112251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pro_question_id  bot_question_id resolution  question_weight    type  \\\n",
       "94            35380            35345        yes             1.00  binary   \n",
       "95            35381            35354         no             1.00  binary   \n",
       "96            35385            35358        yes             1.00  binary   \n",
       "97            35386            35364         no             0.85  binary   \n",
       "98            35387            35367         no             0.85  binary   \n",
       "\n",
       "   options  range_min  range_max open_upper_bound open_lower_bound  ...  \\\n",
       "94    None        NaN        NaN            False            False  ...   \n",
       "95    None        NaN        NaN            False            False  ...   \n",
       "96    None        NaN        NaN            False            False  ...   \n",
       "97    None        NaN        NaN            False            False  ...   \n",
       "98    None        NaN        NaN            False            False  ...   \n",
       "\n",
       "   metac-o1-preview  metac-perplexity  minefrac1     mmBot  pgodzinai  \\\n",
       "94        -0.054067               NaN        NaN  0.000000   0.000000   \n",
       "95        -2.251292               NaN        NaN -0.111226        NaN   \n",
       "96        -0.074901               NaN        NaN -0.074901        NaN   \n",
       "97        -0.680430          0.628948        NaN -0.680430  -0.680430   \n",
       "98        -0.017709          0.000000        NaN -0.112251  -0.017709   \n",
       "\n",
       "    pianobot  swingswish  twsummerbot  wunderplumb  bot_team_median  \n",
       "94       NaN   -0.054067    -0.220515    -0.054067        -0.054067  \n",
       "95       NaN   -0.054067    -0.083382    -2.944439        -0.111226  \n",
       "96       NaN   -0.132060    -0.158283    -0.132060        -0.132060  \n",
       "97       NaN   -0.091255     0.811793     0.628948        -0.091255  \n",
       "98       NaN   -0.163782    -0.241614    -0.163782        -0.112251  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show me a few rows from each type of question in df_bot_vs_pro_peer\n",
    "display_head_and_tail(df_bot_vs_pro_peer[df_bot_vs_pro_peer['type'] == 'multiple_choice'])\n",
    "display_head_and_tail(df_bot_vs_pro_peer[df_bot_vs_pro_peer['type'] == 'binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bot</th>\n",
       "      <th>Peer Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metac-o1</td>\n",
       "      <td>3864.168122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metac-o1-preview</td>\n",
       "      <td>3162.155445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bot_median</td>\n",
       "      <td>2974.983652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manticAI</td>\n",
       "      <td>2142.538438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>metac-Gemini-Exp-1206</td>\n",
       "      <td>2072.216227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acm_bot</td>\n",
       "      <td>1876.466009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>twsummerbot</td>\n",
       "      <td>1763.532046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>metac-perplexity</td>\n",
       "      <td>1697.555196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GreeneiBot2</td>\n",
       "      <td>1603.998618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cookics_bot_TEST</td>\n",
       "      <td>1140.390796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>metac-claude-3-5-sonnet-latest</td>\n",
       "      <td>1134.209821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SynapseSeer</td>\n",
       "      <td>1066.533051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CumulativeBot</td>\n",
       "      <td>1030.716475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pgodzinai</td>\n",
       "      <td>926.081448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jkraybill_bot</td>\n",
       "      <td>627.932509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>metac-deepseek-r1</td>\n",
       "      <td>614.572462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>question_weight</td>\n",
       "      <td>378.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>metac-exa</td>\n",
       "      <td>265.384263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MWG</td>\n",
       "      <td>215.551323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>annabot</td>\n",
       "      <td>21.125670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>andrewsiah</td>\n",
       "      <td>-4.170684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cobyj-bot</td>\n",
       "      <td>-15.593332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>X_bot</td>\n",
       "      <td>-16.052813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pianobot</td>\n",
       "      <td>-20.745921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CatrachoCaster</td>\n",
       "      <td>-214.389722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KevinTestBot</td>\n",
       "      <td>-244.046973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>jonahsingerbot</td>\n",
       "      <td>-318.088290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>krm-bot</td>\n",
       "      <td>-387.131345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ProfessorSP</td>\n",
       "      <td>-406.072162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mmBot</td>\n",
       "      <td>-453.312468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>metac-grok-2-1212</td>\n",
       "      <td>-492.938695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bean_bot</td>\n",
       "      <td>-494.373003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4Shadower</td>\n",
       "      <td>-586.017986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>metac-claude-3-5-sonnet-20240620</td>\n",
       "      <td>-647.579684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>swingswish</td>\n",
       "      <td>-763.021897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RPM_bot</td>\n",
       "      <td>-905.938514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>metac-Llama-3.1</td>\n",
       "      <td>-1029.014161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>InstitutPelFutur</td>\n",
       "      <td>-1087.748963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>wunderplumb</td>\n",
       "      <td>-1189.786803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>VeritasAI</td>\n",
       "      <td>-1521.091541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NextWorldLab</td>\n",
       "      <td>-1565.096041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bot_Pepa</td>\n",
       "      <td>-1589.575284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>laylaps</td>\n",
       "      <td>-1665.296188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>minefrac1</td>\n",
       "      <td>-1850.747385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Grizeu_Bot</td>\n",
       "      <td>-1898.666894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>metac-gpt-4o</td>\n",
       "      <td>-2618.918368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ajf-bot</td>\n",
       "      <td>-3239.712801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bot   Peer Score\n",
       "Rank                                               \n",
       "1                             metac-o1  3864.168122\n",
       "2                     metac-o1-preview  3162.155445\n",
       "3                           bot_median  2974.983652\n",
       "4                             manticAI  2142.538438\n",
       "5                metac-Gemini-Exp-1206  2072.216227\n",
       "6                              acm_bot  1876.466009\n",
       "7                          twsummerbot  1763.532046\n",
       "8                     metac-perplexity  1697.555196\n",
       "9                          GreeneiBot2  1603.998618\n",
       "10                    cookics_bot_TEST  1140.390796\n",
       "11      metac-claude-3-5-sonnet-latest  1134.209821\n",
       "12                         SynapseSeer  1066.533051\n",
       "13                       CumulativeBot  1030.716475\n",
       "14                           pgodzinai   926.081448\n",
       "15                       jkraybill_bot   627.932509\n",
       "16                   metac-deepseek-r1   614.572462\n",
       "17                     question_weight   378.020000\n",
       "18                           metac-exa   265.384263\n",
       "19                                 MWG   215.551323\n",
       "20                             annabot    21.125670\n",
       "21                          andrewsiah    -4.170684\n",
       "22                           cobyj-bot   -15.593332\n",
       "23                               X_bot   -16.052813\n",
       "24                            pianobot   -20.745921\n",
       "25                      CatrachoCaster  -214.389722\n",
       "26                        KevinTestBot  -244.046973\n",
       "27                      jonahsingerbot  -318.088290\n",
       "28                             krm-bot  -387.131345\n",
       "29                         ProfessorSP  -406.072162\n",
       "30                               mmBot  -453.312468\n",
       "31                   metac-grok-2-1212  -492.938695\n",
       "32                            bean_bot  -494.373003\n",
       "33                           4Shadower  -586.017986\n",
       "34    metac-claude-3-5-sonnet-20240620  -647.579684\n",
       "35                          swingswish  -763.021897\n",
       "36                             RPM_bot  -905.938514\n",
       "37                     metac-Llama-3.1 -1029.014161\n",
       "38                    InstitutPelFutur -1087.748963\n",
       "39                         wunderplumb -1189.786803\n",
       "40                           VeritasAI -1521.091541\n",
       "41                        NextWorldLab -1565.096041\n",
       "42                            Bot_Pepa -1589.575284\n",
       "43                             laylaps -1665.296188\n",
       "44                           minefrac1 -1850.747385\n",
       "45                          Grizeu_Bot -1898.666894\n",
       "46                        metac-gpt-4o -2618.918368\n",
       "47                             ajf-bot -3239.712801"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean pro median forecast on questions that resolved yes: 74.0%\n",
      "mean pro median forecast on questions that resolved no: 22.0%\n",
      "mean metac-o1 forecast on questions that resolved yes: 73.0%\n",
      "mean metac-o1 forecast on questions that resolved no: 28.000000000000004%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Average pro median forecast on questions that resolved yes/no vs top bot\n",
    "\n",
    "top_bot = leaderboard['bot'][1]\n",
    "\n",
    "resolved_yes = df_pro_bot_forecasts[df_pro_bot_forecasts['resolution'] == 'yes']\n",
    "resolved_no = df_pro_bot_forecasts[df_pro_bot_forecasts['resolution'] == 'no']\n",
    "\n",
    "# Calculate the average pro median forecast for questions that resolved yes\n",
    "mean_pro_median_yes = resolved_yes['pro_median'].mean().round(2) * 100\n",
    "mean_pro_median_no = resolved_no['pro_median'].mean().round(2) * 100\n",
    "\n",
    "mean_bot_yes = resolved_yes[top_bot].mean().round(2) * 100\n",
    "mean_bot_no = resolved_no[top_bot].mean().round(2) * 100\n",
    "\n",
    "print(f'mean pro median forecast on questions that resolved yes: {mean_pro_median_yes}%')\n",
    "print(f'mean pro median forecast on questions that resolved no: {mean_pro_median_no}%')\n",
    "print(f'mean {top_bot} forecast on questions that resolved yes: {mean_bot_yes}%')\n",
    "print(f'mean {top_bot} forecast on questions that resolved no: {mean_bot_no}%')\n",
    "\n",
    "# Plot the data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create x-coordinates with jitter for each group separately\n",
    "x_bot_yes = np.random.normal(0, 0.04, len(resolved_yes))\n",
    "x_pro_yes = np.random.normal(1, 0.04, len(resolved_yes))\n",
    "x_bot_no = np.random.normal(0, 0.04, len(resolved_no))\n",
    "x_pro_no = np.random.normal(1, 0.04, len(resolved_no))\n",
    "\n",
    "# Plot points for \"yes\" resolution\n",
    "plt.scatter(x_bot_yes, resolved_yes['pro_median'] * 100,\n",
    "           color='blue', alpha=0.6, label='Resolved Yes')\n",
    "plt.scatter(x_pro_yes, resolved_yes[top_bot] * 100,\n",
    "           color='blue', alpha=0.6)\n",
    "\n",
    "# Plot points for \"no\" resolution\n",
    "plt.scatter(x_bot_no, resolved_no['pro_median'] * 100,\n",
    "           color='red', alpha=0.6, label='Resolved No')\n",
    "plt.scatter(x_pro_no, resolved_no[top_bot] * 100,\n",
    "           color='red', alpha=0.6)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xticks([0, 1], ['pro_median', top_bot])\n",
    "plt.ylabel('Probability (%)')\n",
    "plt.title('Pro Median vs Top Bot Forecasts')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Set y-axis limits from 0 to 100\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1932996/946735765.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  weighted_scores = df_long.groupby('forecaster').apply(lambda x: (x['score'] * x['question_weight']).sum(axis=0))\n"
     ]
    }
   ],
   "source": [
    "bot_vs_pro_peer_for_scores = df_bot_vs_pro_peer.copy()\n",
    "bot_vs_pro_peer_for_scores = bot_vs_pro_peer_for_scores.drop(['resolution', 'question_weight', 'bot_question_id', 'pro_median', 'options', 'type'], axis=1)\n",
    "\n",
    "total_scores = bot_vs_pro_peer_for_scores.sum(axis=0)\n",
    "\n",
    "df_bot_vs_pro_peer = df_bot_vs_pro_peer.drop('pro_median', axis=1)\n",
    "\n",
    "# First pivot to long format - each row will be a question-forecaster pair\n",
    "df_long = df_bot_vs_pro_peer.melt(\n",
    "    id_vars=['bot_question_id', 'pro_question_id', 'question_weight', 'resolution', 'type', 'options'],\n",
    "    var_name='forecaster',\n",
    "    value_name='score'\n",
    ")\n",
    "\n",
    "# Drop any rows where score is NaN\n",
    "df_long = df_long.dropna(subset=['score'])\n",
    "\n",
    "# Cast question_weight as numeric\n",
    "df_long['question_weight'] = pd.to_numeric(df_long['question_weight'], errors='coerce')\n",
    "\n",
    "# Group first, then do the multiplication and sum\n",
    "weighted_scores = df_long.groupby('forecaster').apply(lambda x: (x['score'] * x['question_weight']).sum(axis=0))\n",
    "\n",
    "# Calculate number of questions answered by each bot\n",
    "num_questions = df_long.groupby('forecaster')['bot_question_id'].nunique()\n",
    "#num_weighted_questions = df_bot_vs_pro_peer.mul(df_pro_bot_forecasts['question_weight'], axis=0).apply(lambda col: col[col.notna() & col.apply(np.isreal)].count())\n",
    "\n",
    "# Create a new DataFrame with the results\n",
    "results = pd.DataFrame({\n",
    "    'Peer_vs_Pro': total_scores,\n",
    "    'Count': num_questions\n",
    "})\n",
    "\n",
    "weighted_results = pd.DataFrame({\n",
    "    'W_Peer_vs_Pro': weighted_scores,\n",
    "    'Count': num_questions\n",
    "})\n",
    "\n",
    "df_bot_vs_pro_leaderboard = results.sort_values(by='Peer_vs_Pro', ascending=False)\n",
    "df_bot_vs_pro_weighted_leaderboard = weighted_results.sort_values(by='W_Peer_vs_Pro', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro_baseline = df_pro_baseline.rename(columns={'question_id': 'pro_question_id'})\n",
    "df_pro_baseline = df_pro_baseline[['pro_question_id', 'forecaster', 'score']]\n",
    "\n",
    "# Now make it wide! forecaster = columns; score = values; index = pro_question_id\n",
    "df_pro_baseline_wide = df_pro_baseline.pivot(index='pro_question_id', columns='forecaster', values='score').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "cellView": "form",
    "id": "tXKRpXAVHMRt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Forecaster</th>\n",
       "      <th>Weighted_Baseline</th>\n",
       "      <th>Count</th>\n",
       "      <th>Weighted Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pro_median</td>\n",
       "      <td>4238.561607</td>\n",
       "      <td>97</td>\n",
       "      <td>93.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>metac-o1</td>\n",
       "      <td>3010.353788</td>\n",
       "      <td>96</td>\n",
       "      <td>92.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>metac-perplexity</td>\n",
       "      <td>2774.080331</td>\n",
       "      <td>94</td>\n",
       "      <td>90.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>acm_bot</td>\n",
       "      <td>2239.058675</td>\n",
       "      <td>85</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>metac-claude-3-5-sonnet-20240620</td>\n",
       "      <td>2018.110211</td>\n",
       "      <td>95</td>\n",
       "      <td>91.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>bot_median</td>\n",
       "      <td>1970.633069</td>\n",
       "      <td>97</td>\n",
       "      <td>93.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>manticAI</td>\n",
       "      <td>1865.126260</td>\n",
       "      <td>74</td>\n",
       "      <td>70.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>metac-exa</td>\n",
       "      <td>1826.275681</td>\n",
       "      <td>94</td>\n",
       "      <td>90.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>twsummerbot</td>\n",
       "      <td>1819.064141</td>\n",
       "      <td>62</td>\n",
       "      <td>59.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>metac-claude-3-5-sonnet-latest</td>\n",
       "      <td>1740.315188</td>\n",
       "      <td>96</td>\n",
       "      <td>92.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>metac-Llama-3.1</td>\n",
       "      <td>1701.182403</td>\n",
       "      <td>94</td>\n",
       "      <td>90.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>jkraybill_bot</td>\n",
       "      <td>1616.055709</td>\n",
       "      <td>47</td>\n",
       "      <td>45.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>metac-Gemini-Exp-1206</td>\n",
       "      <td>1595.682612</td>\n",
       "      <td>81</td>\n",
       "      <td>77.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>NextWorldLab</td>\n",
       "      <td>1583.026226</td>\n",
       "      <td>85</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>metac-o1-preview</td>\n",
       "      <td>1527.657141</td>\n",
       "      <td>96</td>\n",
       "      <td>92.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>metac-deepseek-r1</td>\n",
       "      <td>1518.308625</td>\n",
       "      <td>55</td>\n",
       "      <td>52.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>laylaps</td>\n",
       "      <td>1500.567874</td>\n",
       "      <td>68</td>\n",
       "      <td>65.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>mmBot</td>\n",
       "      <td>1482.726445</td>\n",
       "      <td>97</td>\n",
       "      <td>93.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Grizeu_Bot</td>\n",
       "      <td>1399.477718</td>\n",
       "      <td>55</td>\n",
       "      <td>52.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>metac-grok-2-1212</td>\n",
       "      <td>1167.867161</td>\n",
       "      <td>96</td>\n",
       "      <td>92.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>VeritasAI</td>\n",
       "      <td>1136.682492</td>\n",
       "      <td>82</td>\n",
       "      <td>78.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>metac-gpt-4o</td>\n",
       "      <td>1045.133678</td>\n",
       "      <td>96</td>\n",
       "      <td>92.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>SynapseSeer</td>\n",
       "      <td>1039.484635</td>\n",
       "      <td>28</td>\n",
       "      <td>26.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>annabot</td>\n",
       "      <td>1031.973930</td>\n",
       "      <td>31</td>\n",
       "      <td>29.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>GreeneiBot2</td>\n",
       "      <td>932.883580</td>\n",
       "      <td>62</td>\n",
       "      <td>59.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>MWG</td>\n",
       "      <td>741.424747</td>\n",
       "      <td>30</td>\n",
       "      <td>28.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>InstitutPelFutur</td>\n",
       "      <td>722.687015</td>\n",
       "      <td>95</td>\n",
       "      <td>91.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>cookics_bot_TEST</td>\n",
       "      <td>714.198372</td>\n",
       "      <td>29</td>\n",
       "      <td>27.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Bot_Pepa</td>\n",
       "      <td>660.801699</td>\n",
       "      <td>47</td>\n",
       "      <td>45.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>ajf-bot</td>\n",
       "      <td>484.445030</td>\n",
       "      <td>37</td>\n",
       "      <td>35.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>swingswish</td>\n",
       "      <td>429.966112</td>\n",
       "      <td>8</td>\n",
       "      <td>7.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>KevinTestBot</td>\n",
       "      <td>331.099444</td>\n",
       "      <td>9</td>\n",
       "      <td>8.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>X_bot</td>\n",
       "      <td>274.539365</td>\n",
       "      <td>7</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>CumulativeBot</td>\n",
       "      <td>253.839701</td>\n",
       "      <td>11</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>CatrachoCaster</td>\n",
       "      <td>247.266717</td>\n",
       "      <td>21</td>\n",
       "      <td>19.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>jonahsingerbot</td>\n",
       "      <td>224.154392</td>\n",
       "      <td>5</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>4Shadower</td>\n",
       "      <td>210.548617</td>\n",
       "      <td>15</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>bean_bot</td>\n",
       "      <td>210.542752</td>\n",
       "      <td>5</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>pgodzinai</td>\n",
       "      <td>177.134104</td>\n",
       "      <td>81</td>\n",
       "      <td>77.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>wunderplumb</td>\n",
       "      <td>112.150245</td>\n",
       "      <td>27</td>\n",
       "      <td>25.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>krm-bot</td>\n",
       "      <td>65.989405</td>\n",
       "      <td>10</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>andrewsiah</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>cobyj-bot</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>RPM_bot</td>\n",
       "      <td>-8.690533</td>\n",
       "      <td>8</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>ProfessorSP</td>\n",
       "      <td>-217.106298</td>\n",
       "      <td>20</td>\n",
       "      <td>18.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>pianobot</td>\n",
       "      <td>-217.321204</td>\n",
       "      <td>5</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>minefrac1</td>\n",
       "      <td>-299.566506</td>\n",
       "      <td>55</td>\n",
       "      <td>52.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                        Forecaster  Weighted_Baseline  Count  \\\n",
       "0      1                        pro_median        4238.561607     97   \n",
       "1      2                          metac-o1        3010.353788     96   \n",
       "2      3                  metac-perplexity        2774.080331     94   \n",
       "3      4                           acm_bot        2239.058675     85   \n",
       "4      5  metac-claude-3-5-sonnet-20240620        2018.110211     95   \n",
       "5      6                        bot_median        1970.633069     97   \n",
       "6      7                          manticAI        1865.126260     74   \n",
       "7      8                         metac-exa        1826.275681     94   \n",
       "8      9                       twsummerbot        1819.064141     62   \n",
       "9     10    metac-claude-3-5-sonnet-latest        1740.315188     96   \n",
       "10    11                   metac-Llama-3.1        1701.182403     94   \n",
       "11    12                     jkraybill_bot        1616.055709     47   \n",
       "12    13             metac-Gemini-Exp-1206        1595.682612     81   \n",
       "13    14                      NextWorldLab        1583.026226     85   \n",
       "14    15                  metac-o1-preview        1527.657141     96   \n",
       "15    16                 metac-deepseek-r1        1518.308625     55   \n",
       "16    17                           laylaps        1500.567874     68   \n",
       "17    18                             mmBot        1482.726445     97   \n",
       "18    19                        Grizeu_Bot        1399.477718     55   \n",
       "19    20                 metac-grok-2-1212        1167.867161     96   \n",
       "20    21                         VeritasAI        1136.682492     82   \n",
       "21    22                      metac-gpt-4o        1045.133678     96   \n",
       "22    23                       SynapseSeer        1039.484635     28   \n",
       "23    24                           annabot        1031.973930     31   \n",
       "24    25                       GreeneiBot2         932.883580     62   \n",
       "25    26                               MWG         741.424747     30   \n",
       "26    27                  InstitutPelFutur         722.687015     95   \n",
       "27    28                  cookics_bot_TEST         714.198372     29   \n",
       "28    29                          Bot_Pepa         660.801699     47   \n",
       "29    30                           ajf-bot         484.445030     37   \n",
       "30    31                        swingswish         429.966112      8   \n",
       "31    32                      KevinTestBot         331.099444      9   \n",
       "32    33                             X_bot         274.539365      7   \n",
       "33    34                     CumulativeBot         253.839701     11   \n",
       "34    35                    CatrachoCaster         247.266717     21   \n",
       "35    36                    jonahsingerbot         224.154392      5   \n",
       "36    37                         4Shadower         210.548617     15   \n",
       "37    38                          bean_bot         210.542752      5   \n",
       "38    39                         pgodzinai         177.134104     81   \n",
       "39    40                       wunderplumb         112.150245     27   \n",
       "40    41                           krm-bot          65.989405     10   \n",
       "41    42                        andrewsiah           0.000000      0   \n",
       "42    43                         cobyj-bot           0.000000      0   \n",
       "43    44                           RPM_bot          -8.690533      8   \n",
       "44    45                       ProfessorSP        -217.106298     20   \n",
       "45    46                          pianobot        -217.321204      5   \n",
       "46    47                         minefrac1        -299.566506     55   \n",
       "\n",
       "    Weighted Count  \n",
       "0            93.10  \n",
       "1            92.10  \n",
       "2            90.10  \n",
       "3            81.25  \n",
       "4            91.50  \n",
       "5            93.10  \n",
       "6            70.45  \n",
       "7            90.10  \n",
       "8            59.40  \n",
       "9            92.10  \n",
       "10           90.10  \n",
       "11           45.05  \n",
       "12           77.50  \n",
       "13           81.25  \n",
       "14           92.10  \n",
       "15           52.10  \n",
       "16           65.10  \n",
       "17           93.10  \n",
       "18           52.35  \n",
       "19           92.10  \n",
       "20           78.10  \n",
       "21           92.10  \n",
       "22           26.15  \n",
       "23           29.30  \n",
       "24           59.35  \n",
       "25           28.60  \n",
       "26           91.10  \n",
       "27           27.40  \n",
       "28           45.05  \n",
       "29           35.25  \n",
       "30            7.70  \n",
       "31            8.40  \n",
       "32            7.00  \n",
       "33           10.25  \n",
       "34           19.70  \n",
       "35            4.70  \n",
       "36           14.00  \n",
       "37            4.70  \n",
       "38           77.40  \n",
       "39           25.55  \n",
       "40            9.50  \n",
       "41            0.00  \n",
       "42            0.00  \n",
       "43            8.00  \n",
       "44           18.60  \n",
       "45            4.70  \n",
       "46           52.10  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Create df_pro_bot_baseline_leaderboard, df_pro_bot_baseline_weighted_leaderboard\n",
    "\n",
    "df_pro_bot_baseline_weights = pd.merge(\n",
    "    df_pro_bot_resolved_questions,\n",
    "    df_bot_baseline_wide,\n",
    "    on='bot_question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_pro_bot_baseline_weights = pd.merge(\n",
    "    df_pro_bot_baseline_weights,\n",
    "    df_pro_baseline_wide[['pro_question_id', 'pro_median']],\n",
    "    on='pro_question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Remove rows where pro_question_id is NaN (only want overlapping questions here)\n",
    "df_pro_bot_baseline_weights = df_pro_bot_baseline_weights.dropna(subset=['pro_question_id'])\n",
    "\n",
    "# Create a list of columns to keep\n",
    "forecaster_cols = ['pro_median'] + [col for col in df_pro_bot_baseline_weights.columns if col in all_bots]\n",
    "df_filtered = df_pro_bot_baseline_weights[forecaster_cols]\n",
    "\n",
    "# Calculate the sum for each forecaster\n",
    "forecaster_scores = df_filtered.sum()\n",
    "forecaster_weighted_scores = df_filtered.mul(df_pro_bot_baseline_weights['question_weight'], axis=0).sum()\n",
    "\n",
    "question_counts = df_filtered.notna().sum()\n",
    "question_weighted_counts = df_filtered.notna().mul(df_pro_bot_baseline_weights['question_weight'], axis=0).sum()\n",
    "\n",
    "# Create a DataFrame for the leaderboard\n",
    "leaderboard = pd.DataFrame({\n",
    "    'Forecaster': forecaster_scores.index,\n",
    "    'Baseline': forecaster_scores.values,\n",
    "    'Count': question_counts.values\n",
    "})\n",
    "\n",
    "# Create a DataFrame for the leaderboard\n",
    "weighted_leaderboard = pd.DataFrame({\n",
    "    'Forecaster': forecaster_weighted_scores.index,\n",
    "    'Weighted_Baseline': forecaster_weighted_scores.values,\n",
    "    'Count': question_counts.values,\n",
    "    'Weighted Count': question_weighted_counts.values\n",
    "})\n",
    "\n",
    "# Sort the leaderboard by score in descending order\n",
    "leaderboard = leaderboard.sort_values('Baseline', ascending=False).reset_index(drop=True)\n",
    "weighted_leaderboard = weighted_leaderboard.sort_values('Weighted_Baseline', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Add a 'Rank' column\n",
    "leaderboard['Rank'] = leaderboard.index + 1\n",
    "weighted_leaderboard['Rank'] = weighted_leaderboard.index + 1\n",
    "\n",
    "# Reorder columns to have Rank first\n",
    "leaderboard = leaderboard[['Rank', 'Forecaster', 'Baseline', 'Count']]\n",
    "weighted_leaderboard = weighted_leaderboard[['Rank', 'Forecaster', 'Weighted_Baseline', 'Count', 'Weighted Count']]\n",
    "\n",
    "#leaderboard\n",
    "weighted_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_score</th>\n",
       "      <th>W_count</th>\n",
       "      <th>W_ave</th>\n",
       "      <th>W_stdev</th>\n",
       "      <th>std_err</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>t_crit</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>cdf</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pro_median</th>\n",
       "      <td>4238.6</td>\n",
       "      <td>93.1</td>\n",
       "      <td>45.5</td>\n",
       "      <td>62.229168</td>\n",
       "      <td>6.449398</td>\n",
       "      <td>7.059105</td>\n",
       "      <td>1.985277</td>\n",
       "      <td>58.3</td>\n",
       "      <td>32.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-o1</th>\n",
       "      <td>3010.4</td>\n",
       "      <td>92.1</td>\n",
       "      <td>32.7</td>\n",
       "      <td>57.756859</td>\n",
       "      <td>6.018299</td>\n",
       "      <td>5.431054</td>\n",
       "      <td>1.985550</td>\n",
       "      <td>44.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-perplexity</th>\n",
       "      <td>2774.1</td>\n",
       "      <td>90.1</td>\n",
       "      <td>30.8</td>\n",
       "      <td>67.210383</td>\n",
       "      <td>7.080664</td>\n",
       "      <td>4.348308</td>\n",
       "      <td>1.986114</td>\n",
       "      <td>44.9</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acm_bot</th>\n",
       "      <td>2239.1</td>\n",
       "      <td>81.2</td>\n",
       "      <td>27.6</td>\n",
       "      <td>55.554054</td>\n",
       "      <td>6.163169</td>\n",
       "      <td>4.471343</td>\n",
       "      <td>1.988985</td>\n",
       "      <td>39.8</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-claude-3-5-sonnet-20240620</th>\n",
       "      <td>2018.1</td>\n",
       "      <td>91.5</td>\n",
       "      <td>22.1</td>\n",
       "      <td>64.219307</td>\n",
       "      <td>6.713594</td>\n",
       "      <td>3.285252</td>\n",
       "      <td>1.985788</td>\n",
       "      <td>35.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bot_median</th>\n",
       "      <td>1970.6</td>\n",
       "      <td>93.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>65.554743</td>\n",
       "      <td>6.794058</td>\n",
       "      <td>3.115493</td>\n",
       "      <td>1.985277</td>\n",
       "      <td>34.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.998776</td>\n",
       "      <td>0.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manticAI</th>\n",
       "      <td>1865.1</td>\n",
       "      <td>70.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>66.353059</td>\n",
       "      <td>7.905338</td>\n",
       "      <td>3.348936</td>\n",
       "      <td>1.993488</td>\n",
       "      <td>42.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.999343</td>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-exa</th>\n",
       "      <td>1826.3</td>\n",
       "      <td>90.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>82.219585</td>\n",
       "      <td>8.661894</td>\n",
       "      <td>2.340069</td>\n",
       "      <td>1.986114</td>\n",
       "      <td>37.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.989243</td>\n",
       "      <td>0.021514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twsummerbot</th>\n",
       "      <td>1819.1</td>\n",
       "      <td>59.4</td>\n",
       "      <td>30.6</td>\n",
       "      <td>54.747799</td>\n",
       "      <td>7.103517</td>\n",
       "      <td>4.311100</td>\n",
       "      <td>2.000163</td>\n",
       "      <td>44.8</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-claude-3-5-sonnet-latest</th>\n",
       "      <td>1740.3</td>\n",
       "      <td>92.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>71.545983</td>\n",
       "      <td>7.455134</td>\n",
       "      <td>2.534620</td>\n",
       "      <td>1.985550</td>\n",
       "      <td>33.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.993518</td>\n",
       "      <td>0.012963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-Llama-3.1</th>\n",
       "      <td>1701.2</td>\n",
       "      <td>90.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>62.154929</td>\n",
       "      <td>6.548068</td>\n",
       "      <td>2.883453</td>\n",
       "      <td>1.986114</td>\n",
       "      <td>31.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.997535</td>\n",
       "      <td>0.004930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jkraybill_bot</th>\n",
       "      <td>1616.1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>59.756838</td>\n",
       "      <td>8.903079</td>\n",
       "      <td>4.029223</td>\n",
       "      <td>2.013412</td>\n",
       "      <td>53.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-Gemini-Exp-1206</th>\n",
       "      <td>1595.7</td>\n",
       "      <td>77.5</td>\n",
       "      <td>20.6</td>\n",
       "      <td>67.099981</td>\n",
       "      <td>7.622046</td>\n",
       "      <td>2.701303</td>\n",
       "      <td>1.990426</td>\n",
       "      <td>35.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.995749</td>\n",
       "      <td>0.008502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NextWorldLab</th>\n",
       "      <td>1583.0</td>\n",
       "      <td>81.2</td>\n",
       "      <td>19.5</td>\n",
       "      <td>66.411747</td>\n",
       "      <td>7.367722</td>\n",
       "      <td>2.644427</td>\n",
       "      <td>1.988985</td>\n",
       "      <td>34.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.995080</td>\n",
       "      <td>0.009840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <td>1527.7</td>\n",
       "      <td>92.1</td>\n",
       "      <td>16.6</td>\n",
       "      <td>87.111568</td>\n",
       "      <td>9.077077</td>\n",
       "      <td>1.827344</td>\n",
       "      <td>1.985550</td>\n",
       "      <td>34.6</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.070922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-deepseek-r1</th>\n",
       "      <td>1518.3</td>\n",
       "      <td>52.1</td>\n",
       "      <td>29.1</td>\n",
       "      <td>62.764970</td>\n",
       "      <td>8.695578</td>\n",
       "      <td>3.351382</td>\n",
       "      <td>2.005379</td>\n",
       "      <td>46.6</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.001519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laylaps</th>\n",
       "      <td>1500.6</td>\n",
       "      <td>65.1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>74.457365</td>\n",
       "      <td>9.228204</td>\n",
       "      <td>2.497799</td>\n",
       "      <td>1.996341</td>\n",
       "      <td>41.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.992463</td>\n",
       "      <td>0.015074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmBot</th>\n",
       "      <td>1482.7</td>\n",
       "      <td>93.1</td>\n",
       "      <td>15.9</td>\n",
       "      <td>79.990502</td>\n",
       "      <td>8.290173</td>\n",
       "      <td>1.921090</td>\n",
       "      <td>1.985277</td>\n",
       "      <td>32.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.971093</td>\n",
       "      <td>0.057813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grizeu_Bot</th>\n",
       "      <td>1399.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>26.7</td>\n",
       "      <td>60.886905</td>\n",
       "      <td>8.415222</td>\n",
       "      <td>3.176755</td>\n",
       "      <td>2.005555</td>\n",
       "      <td>43.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.998740</td>\n",
       "      <td>0.002521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-grok-2-1212</th>\n",
       "      <td>1167.9</td>\n",
       "      <td>92.1</td>\n",
       "      <td>12.7</td>\n",
       "      <td>79.322449</td>\n",
       "      <td>8.265446</td>\n",
       "      <td>1.534149</td>\n",
       "      <td>1.985550</td>\n",
       "      <td>29.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>0.935771</td>\n",
       "      <td>0.128459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VeritasAI</th>\n",
       "      <td>1136.7</td>\n",
       "      <td>78.1</td>\n",
       "      <td>14.6</td>\n",
       "      <td>61.124913</td>\n",
       "      <td>6.916601</td>\n",
       "      <td>2.104241</td>\n",
       "      <td>1.990095</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.980692</td>\n",
       "      <td>0.038617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-gpt-4o</th>\n",
       "      <td>1045.1</td>\n",
       "      <td>92.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>67.764165</td>\n",
       "      <td>7.061066</td>\n",
       "      <td>1.607096</td>\n",
       "      <td>1.985550</td>\n",
       "      <td>25.4</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>0.944253</td>\n",
       "      <td>0.111494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SynapseSeer</th>\n",
       "      <td>1039.5</td>\n",
       "      <td>26.2</td>\n",
       "      <td>39.8</td>\n",
       "      <td>62.843548</td>\n",
       "      <td>12.289235</td>\n",
       "      <td>3.234607</td>\n",
       "      <td>2.053076</td>\n",
       "      <td>65.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>0.003397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annabot</th>\n",
       "      <td>1032.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>35.2</td>\n",
       "      <td>57.689624</td>\n",
       "      <td>10.657710</td>\n",
       "      <td>3.304739</td>\n",
       "      <td>2.044183</td>\n",
       "      <td>57.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.002586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreeneiBot2</th>\n",
       "      <td>932.9</td>\n",
       "      <td>59.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>73.832186</td>\n",
       "      <td>9.583748</td>\n",
       "      <td>1.640104</td>\n",
       "      <td>2.000141</td>\n",
       "      <td>34.9</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.946818</td>\n",
       "      <td>0.106364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MWG</th>\n",
       "      <td>741.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>25.9</td>\n",
       "      <td>78.735891</td>\n",
       "      <td>14.722777</td>\n",
       "      <td>1.760805</td>\n",
       "      <td>2.046561</td>\n",
       "      <td>56.1</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>0.955325</td>\n",
       "      <td>0.089349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InstitutPelFutur</th>\n",
       "      <td>722.7</td>\n",
       "      <td>91.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>100.840633</td>\n",
       "      <td>10.565167</td>\n",
       "      <td>0.750854</td>\n",
       "      <td>1.985829</td>\n",
       "      <td>28.9</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0.772651</td>\n",
       "      <td>0.454697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cookics_bot_TEST</th>\n",
       "      <td>714.2</td>\n",
       "      <td>27.4</td>\n",
       "      <td>26.1</td>\n",
       "      <td>63.256652</td>\n",
       "      <td>12.084562</td>\n",
       "      <td>2.156937</td>\n",
       "      <td>2.049541</td>\n",
       "      <td>50.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.979856</td>\n",
       "      <td>0.040287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot_Pepa</th>\n",
       "      <td>660.8</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>69.738787</td>\n",
       "      <td>10.390274</td>\n",
       "      <td>1.411723</td>\n",
       "      <td>2.013412</td>\n",
       "      <td>35.6</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>0.917472</td>\n",
       "      <td>0.165057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajf-bot</th>\n",
       "      <td>484.4</td>\n",
       "      <td>35.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>86.568228</td>\n",
       "      <td>14.580720</td>\n",
       "      <td>0.942554</td>\n",
       "      <td>2.028730</td>\n",
       "      <td>43.3</td>\n",
       "      <td>-15.8</td>\n",
       "      <td>0.823745</td>\n",
       "      <td>0.352510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swingswish</th>\n",
       "      <td>430.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>55.8</td>\n",
       "      <td>52.065740</td>\n",
       "      <td>18.763190</td>\n",
       "      <td>2.976027</td>\n",
       "      <td>2.367123</td>\n",
       "      <td>100.3</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.989142</td>\n",
       "      <td>0.021716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KevinTestBot</th>\n",
       "      <td>331.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>39.4</td>\n",
       "      <td>76.256855</td>\n",
       "      <td>26.311114</td>\n",
       "      <td>1.498097</td>\n",
       "      <td>2.311496</td>\n",
       "      <td>100.2</td>\n",
       "      <td>-21.4</td>\n",
       "      <td>0.912252</td>\n",
       "      <td>0.175497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_bot</th>\n",
       "      <td>274.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>31.693801</td>\n",
       "      <td>11.979131</td>\n",
       "      <td>3.274020</td>\n",
       "      <td>2.446912</td>\n",
       "      <td>68.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.991526</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CumulativeBot</th>\n",
       "      <td>253.8</td>\n",
       "      <td>10.2</td>\n",
       "      <td>24.8</td>\n",
       "      <td>78.924719</td>\n",
       "      <td>24.651941</td>\n",
       "      <td>1.004580</td>\n",
       "      <td>2.231848</td>\n",
       "      <td>79.8</td>\n",
       "      <td>-30.3</td>\n",
       "      <td>0.829673</td>\n",
       "      <td>0.340653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatrachoCaster</th>\n",
       "      <td>247.3</td>\n",
       "      <td>19.7</td>\n",
       "      <td>12.6</td>\n",
       "      <td>75.371584</td>\n",
       "      <td>16.981440</td>\n",
       "      <td>0.739137</td>\n",
       "      <td>2.088777</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-22.9</td>\n",
       "      <td>0.765500</td>\n",
       "      <td>0.469001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonahsingerbot</th>\n",
       "      <td>224.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>47.7</td>\n",
       "      <td>64.220182</td>\n",
       "      <td>29.622561</td>\n",
       "      <td>1.610003</td>\n",
       "      <td>2.784843</td>\n",
       "      <td>130.2</td>\n",
       "      <td>-34.8</td>\n",
       "      <td>0.905799</td>\n",
       "      <td>0.188401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bean_bot</th>\n",
       "      <td>210.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>44.8</td>\n",
       "      <td>76.356439</td>\n",
       "      <td>35.220599</td>\n",
       "      <td>1.271879</td>\n",
       "      <td>2.784843</td>\n",
       "      <td>142.9</td>\n",
       "      <td>-53.3</td>\n",
       "      <td>0.861262</td>\n",
       "      <td>0.277476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4Shadower</th>\n",
       "      <td>210.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>116.146112</td>\n",
       "      <td>31.041354</td>\n",
       "      <td>0.484489</td>\n",
       "      <td>2.147239</td>\n",
       "      <td>81.7</td>\n",
       "      <td>-51.6</td>\n",
       "      <td>0.681950</td>\n",
       "      <td>0.636100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgodzinai</th>\n",
       "      <td>177.1</td>\n",
       "      <td>77.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>103.639119</td>\n",
       "      <td>11.780215</td>\n",
       "      <td>0.194271</td>\n",
       "      <td>1.990453</td>\n",
       "      <td>25.7</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>0.576760</td>\n",
       "      <td>0.846479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wunderplumb</th>\n",
       "      <td>112.2</td>\n",
       "      <td>25.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>102.069000</td>\n",
       "      <td>20.192887</td>\n",
       "      <td>0.217376</td>\n",
       "      <td>2.056603</td>\n",
       "      <td>45.9</td>\n",
       "      <td>-37.1</td>\n",
       "      <td>0.585144</td>\n",
       "      <td>0.829712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krm-bot</th>\n",
       "      <td>66.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>68.182124</td>\n",
       "      <td>22.121202</td>\n",
       "      <td>0.314009</td>\n",
       "      <td>2.264709</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-43.2</td>\n",
       "      <td>0.619458</td>\n",
       "      <td>0.761083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrewsiah</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cobyj-bot</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPM_bot</th>\n",
       "      <td>-8.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>89.625559</td>\n",
       "      <td>31.687420</td>\n",
       "      <td>-0.034282</td>\n",
       "      <td>2.364624</td>\n",
       "      <td>73.8</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>0.486805</td>\n",
       "      <td>0.973609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProfessorSP</th>\n",
       "      <td>-217.1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>-11.7</td>\n",
       "      <td>80.594072</td>\n",
       "      <td>18.687303</td>\n",
       "      <td>-0.624616</td>\n",
       "      <td>2.095243</td>\n",
       "      <td>27.5</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>0.270118</td>\n",
       "      <td>0.540237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pianobot</th>\n",
       "      <td>-217.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>124.350728</td>\n",
       "      <td>57.358714</td>\n",
       "      <td>-0.806130</td>\n",
       "      <td>2.798986</td>\n",
       "      <td>114.3</td>\n",
       "      <td>-206.8</td>\n",
       "      <td>0.234388</td>\n",
       "      <td>0.468776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minefrac1</th>\n",
       "      <td>-299.6</td>\n",
       "      <td>52.1</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>70.581980</td>\n",
       "      <td>9.778562</td>\n",
       "      <td>-0.588004</td>\n",
       "      <td>2.005649</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>0.279560</td>\n",
       "      <td>0.559119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  W_score  W_count  W_ave     W_stdev  \\\n",
       "pro_median                         4238.6     93.1   45.5   62.229168   \n",
       "metac-o1                           3010.4     92.1   32.7   57.756859   \n",
       "metac-perplexity                   2774.1     90.1   30.8   67.210383   \n",
       "acm_bot                            2239.1     81.2   27.6   55.554054   \n",
       "metac-claude-3-5-sonnet-20240620   2018.1     91.5   22.1   64.219307   \n",
       "bot_median                         1970.6     93.1   21.2   65.554743   \n",
       "manticAI                           1865.1     70.4   26.5   66.353059   \n",
       "metac-exa                          1826.3     90.1   20.3   82.219585   \n",
       "twsummerbot                        1819.1     59.4   30.6   54.747799   \n",
       "metac-claude-3-5-sonnet-latest     1740.3     92.1   18.9   71.545983   \n",
       "metac-Llama-3.1                    1701.2     90.1   18.9   62.154929   \n",
       "jkraybill_bot                      1616.1     45.0   35.9   59.756838   \n",
       "metac-Gemini-Exp-1206              1595.7     77.5   20.6   67.099981   \n",
       "NextWorldLab                       1583.0     81.2   19.5   66.411747   \n",
       "metac-o1-preview                   1527.7     92.1   16.6   87.111568   \n",
       "metac-deepseek-r1                  1518.3     52.1   29.1   62.764970   \n",
       "laylaps                            1500.6     65.1   23.1   74.457365   \n",
       "mmBot                              1482.7     93.1   15.9   79.990502   \n",
       "Grizeu_Bot                         1399.5     52.4   26.7   60.886905   \n",
       "metac-grok-2-1212                  1167.9     92.1   12.7   79.322449   \n",
       "VeritasAI                          1136.7     78.1   14.6   61.124913   \n",
       "metac-gpt-4o                       1045.1     92.1   11.3   67.764165   \n",
       "SynapseSeer                        1039.5     26.2   39.8   62.843548   \n",
       "annabot                            1032.0     29.3   35.2   57.689624   \n",
       "GreeneiBot2                         932.9     59.4   15.7   73.832186   \n",
       "MWG                                 741.4     28.6   25.9   78.735891   \n",
       "InstitutPelFutur                    722.7     91.1    7.9  100.840633   \n",
       "cookics_bot_TEST                    714.2     27.4   26.1   63.256652   \n",
       "Bot_Pepa                            660.8     45.0   14.7   69.738787   \n",
       "ajf-bot                             484.4     35.2   13.7   86.568228   \n",
       "swingswish                          430.0      7.7   55.8   52.065740   \n",
       "KevinTestBot                        331.1      8.4   39.4   76.256855   \n",
       "X_bot                               274.5      7.0   39.2   31.693801   \n",
       "CumulativeBot                       253.8     10.2   24.8   78.924719   \n",
       "CatrachoCaster                      247.3     19.7   12.6   75.371584   \n",
       "jonahsingerbot                      224.2      4.7   47.7   64.220182   \n",
       "bean_bot                            210.5      4.7   44.8   76.356439   \n",
       "4Shadower                           210.5     14.0   15.0  116.146112   \n",
       "pgodzinai                           177.1     77.4    2.3  103.639119   \n",
       "wunderplumb                         112.2     25.6    4.4  102.069000   \n",
       "krm-bot                              66.0      9.5    6.9   68.182124   \n",
       "andrewsiah                            0.0      0.0    NaN         NaN   \n",
       "cobyj-bot                             0.0      0.0    NaN         NaN   \n",
       "RPM_bot                              -8.7      8.0   -1.1   89.625559   \n",
       "ProfessorSP                        -217.1     18.6  -11.7   80.594072   \n",
       "pianobot                           -217.3      4.7  -46.2  124.350728   \n",
       "minefrac1                          -299.6     52.1   -5.7   70.581980   \n",
       "\n",
       "                                    std_err    t_stat    t_crit  upper_bound  \\\n",
       "pro_median                         6.449398  7.059105  1.985277         58.3   \n",
       "metac-o1                           6.018299  5.431054  1.985550         44.6   \n",
       "metac-perplexity                   7.080664  4.348308  1.986114         44.9   \n",
       "acm_bot                            6.163169  4.471343  1.988985         39.8   \n",
       "metac-claude-3-5-sonnet-20240620   6.713594  3.285252  1.985788         35.4   \n",
       "bot_median                         6.794058  3.115493  1.985277         34.7   \n",
       "manticAI                           7.905338  3.348936  1.993488         42.2   \n",
       "metac-exa                          8.661894  2.340069  1.986114         37.5   \n",
       "twsummerbot                        7.103517  4.311100  2.000163         44.8   \n",
       "metac-claude-3-5-sonnet-latest     7.455134  2.534620  1.985550         33.7   \n",
       "metac-Llama-3.1                    6.548068  2.883453  1.986114         31.9   \n",
       "jkraybill_bot                      8.903079  4.029223  2.013412         53.8   \n",
       "metac-Gemini-Exp-1206              7.622046  2.701303  1.990426         35.8   \n",
       "NextWorldLab                       7.367722  2.644427  1.988985         34.1   \n",
       "metac-o1-preview                   9.077077  1.827344  1.985550         34.6   \n",
       "metac-deepseek-r1                  8.695578  3.351382  2.005379         46.6   \n",
       "laylaps                            9.228204  2.497799  1.996341         41.5   \n",
       "mmBot                              8.290173  1.921090  1.985277         32.4   \n",
       "Grizeu_Bot                         8.415222  3.176755  2.005555         43.6   \n",
       "metac-grok-2-1212                  8.265446  1.534149  1.985550         29.1   \n",
       "VeritasAI                          6.916601  2.104241  1.990095         28.3   \n",
       "metac-gpt-4o                       7.061066  1.607096  1.985550         25.4   \n",
       "SynapseSeer                       12.289235  3.234607  2.053076         65.0   \n",
       "annabot                           10.657710  3.304739  2.044183         57.0   \n",
       "GreeneiBot2                        9.583748  1.640104  2.000141         34.9   \n",
       "MWG                               14.722777  1.760805  2.046561         56.1   \n",
       "InstitutPelFutur                  10.565167  0.750854  1.985829         28.9   \n",
       "cookics_bot_TEST                  12.084562  2.156937  2.049541         50.8   \n",
       "Bot_Pepa                          10.390274  1.411723  2.013412         35.6   \n",
       "ajf-bot                           14.580720  0.942554  2.028730         43.3   \n",
       "swingswish                        18.763190  2.976027  2.367123        100.3   \n",
       "KevinTestBot                      26.311114  1.498097  2.311496        100.2   \n",
       "X_bot                             11.979131  3.274020  2.446912         68.5   \n",
       "CumulativeBot                     24.651941  1.004580  2.231848         79.8   \n",
       "CatrachoCaster                    16.981440  0.739137  2.088777         48.0   \n",
       "jonahsingerbot                    29.622561  1.610003  2.784843        130.2   \n",
       "bean_bot                          35.220599  1.271879  2.784843        142.9   \n",
       "4Shadower                         31.041354  0.484489  2.147239         81.7   \n",
       "pgodzinai                         11.780215  0.194271  1.990453         25.7   \n",
       "wunderplumb                       20.192887  0.217376  2.056603         45.9   \n",
       "krm-bot                           22.121202  0.314009  2.264709         57.0   \n",
       "andrewsiah                              NaN       NaN       NaN          NaN   \n",
       "cobyj-bot                               NaN       NaN       NaN          NaN   \n",
       "RPM_bot                           31.687420 -0.034282  2.364624         73.8   \n",
       "ProfessorSP                       18.687303 -0.624616  2.095243         27.5   \n",
       "pianobot                          57.358714 -0.806130  2.798986        114.3   \n",
       "minefrac1                          9.778562 -0.588004  2.005649         13.9   \n",
       "\n",
       "                                  lower_bound       cdf   p_value  \n",
       "pro_median                               32.7  1.000000  0.000000  \n",
       "metac-o1                                 20.7  1.000000  0.000000  \n",
       "metac-perplexity                         16.7  0.999982  0.000036  \n",
       "acm_bot                                  15.3  0.999987  0.000025  \n",
       "metac-claude-3-5-sonnet-20240620          8.7  0.999275  0.001450  \n",
       "bot_median                                7.7  0.998776  0.002449  \n",
       "manticAI                                 10.7  0.999343  0.001314  \n",
       "metac-exa                                 3.1  0.989243  0.021514  \n",
       "twsummerbot                              16.4  0.999968  0.000063  \n",
       "metac-claude-3-5-sonnet-latest            4.1  0.993518  0.012963  \n",
       "metac-Llama-3.1                           5.9  0.997535  0.004930  \n",
       "jkraybill_bot                            17.9  0.999891  0.000218  \n",
       "metac-Gemini-Exp-1206                     5.4  0.995749  0.008502  \n",
       "NextWorldLab                              4.8  0.995080  0.009840  \n",
       "metac-o1-preview                         -1.4  0.964539  0.070922  \n",
       "metac-deepseek-r1                        11.7  0.999241  0.001519  \n",
       "laylaps                                   4.6  0.992463  0.015074  \n",
       "mmBot                                    -0.5  0.971093  0.057813  \n",
       "Grizeu_Bot                                9.9  0.998740  0.002521  \n",
       "metac-grok-2-1212                        -3.7  0.935771  0.128459  \n",
       "VeritasAI                                 0.8  0.980692  0.038617  \n",
       "metac-gpt-4o                             -2.7  0.944253  0.111494  \n",
       "SynapseSeer                              14.5  0.998302  0.003397  \n",
       "annabot                                  13.4  0.998707  0.002586  \n",
       "GreeneiBot2                              -3.5  0.946818  0.106364  \n",
       "MWG                                      -4.2  0.955325  0.089349  \n",
       "InstitutPelFutur                        -13.0  0.772651  0.454697  \n",
       "cookics_bot_TEST                          1.3  0.979856  0.040287  \n",
       "Bot_Pepa                                 -6.3  0.917472  0.165057  \n",
       "ajf-bot                                 -15.8  0.823745  0.352510  \n",
       "swingswish                               11.4  0.989142  0.021716  \n",
       "KevinTestBot                            -21.4  0.912252  0.175497  \n",
       "X_bot                                     9.9  0.991526  0.016949  \n",
       "CumulativeBot                           -30.3  0.829673  0.340653  \n",
       "CatrachoCaster                          -22.9  0.765500  0.469001  \n",
       "jonahsingerbot                          -34.8  0.905799  0.188401  \n",
       "bean_bot                                -53.3  0.861262  0.277476  \n",
       "4Shadower                               -51.6  0.681950  0.636100  \n",
       "pgodzinai                               -21.2  0.576760  0.846479  \n",
       "wunderplumb                             -37.1  0.585144  0.829712  \n",
       "krm-bot                                 -43.2  0.619458  0.761083  \n",
       "andrewsiah                                NaN       NaN        NA  \n",
       "cobyj-bot                                 NaN       NaN        NA  \n",
       "RPM_bot                                 -76.0  0.486805  0.973609  \n",
       "ProfessorSP                             -50.8  0.270118  0.540237  \n",
       "pianobot                               -206.8  0.234388  0.468776  \n",
       "minefrac1                               -25.4  0.279560  0.559119  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make me a list that's pro_median and all the bot forecasters\n",
    "forecasters = ['pro_median'] + [col for col in df_pro_bot_baseline_weights.columns if col in all_bots]\n",
    "\n",
    "hey = calculate_t_test(df_pro_bot_baseline_weights, forecasters)\n",
    "\n",
    "hey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGNedTHmU-Bm",
    "outputId": "a7935679-8993-4329-d05d-fd701c4b77a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_score</th>\n",
       "      <th>W_count</th>\n",
       "      <th>W_ave</th>\n",
       "      <th>W_stdev</th>\n",
       "      <th>std_err</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>t_crit</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>cdf</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobyj-bot</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrewsiah</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bean_bot</th>\n",
       "      <td>-0.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.069849</td>\n",
       "      <td>0.032219</td>\n",
       "      <td>-4.265106</td>\n",
       "      <td>2.784843</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.015349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonahsingerbot</th>\n",
       "      <td>-0.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.050272</td>\n",
       "      <td>0.023189</td>\n",
       "      <td>-5.273630</td>\n",
       "      <td>2.784843</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.007677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_bot</th>\n",
       "      <td>-0.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.354068</td>\n",
       "      <td>0.133825</td>\n",
       "      <td>-0.747195</td>\n",
       "      <td>2.446912</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.241594</td>\n",
       "      <td>0.483189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPM_bot</th>\n",
       "      <td>-1.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.824532</td>\n",
       "      <td>0.311644</td>\n",
       "      <td>-0.523406</td>\n",
       "      <td>2.446912</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.309726</td>\n",
       "      <td>0.619452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CumulativeBot</th>\n",
       "      <td>-1.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.257798</td>\n",
       "      <td>0.080522</td>\n",
       "      <td>-1.315132</td>\n",
       "      <td>2.231848</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.110066</td>\n",
       "      <td>0.220132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swingswish</th>\n",
       "      <td>-1.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.140275</td>\n",
       "      <td>0.050552</td>\n",
       "      <td>-3.074947</td>\n",
       "      <td>2.367123</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>0.018953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SynapseSeer</th>\n",
       "      <td>-1.3</td>\n",
       "      <td>26.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.452555</td>\n",
       "      <td>0.088498</td>\n",
       "      <td>-0.568910</td>\n",
       "      <td>2.053076</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.287231</td>\n",
       "      <td>0.574463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KevinTestBot</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.589466</td>\n",
       "      <td>0.203385</td>\n",
       "      <td>-0.897116</td>\n",
       "      <td>2.311496</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.198952</td>\n",
       "      <td>0.397903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grizeu_Bot</th>\n",
       "      <td>-1.7</td>\n",
       "      <td>51.4</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.173392</td>\n",
       "      <td>0.163747</td>\n",
       "      <td>-0.206616</td>\n",
       "      <td>2.006447</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.418571</td>\n",
       "      <td>0.837143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pianobot</th>\n",
       "      <td>-2.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.916204</td>\n",
       "      <td>0.422613</td>\n",
       "      <td>-1.384327</td>\n",
       "      <td>2.798986</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.121941</td>\n",
       "      <td>0.243882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatrachoCaster</th>\n",
       "      <td>-3.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.520901</td>\n",
       "      <td>0.117361</td>\n",
       "      <td>-1.365532</td>\n",
       "      <td>2.088777</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.094144</td>\n",
       "      <td>0.188288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krm-bot</th>\n",
       "      <td>-5.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.511546</td>\n",
       "      <td>0.165967</td>\n",
       "      <td>-3.229846</td>\n",
       "      <td>2.264709</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.011127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annabot</th>\n",
       "      <td>-6.2</td>\n",
       "      <td>29.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.520869</td>\n",
       "      <td>0.096226</td>\n",
       "      <td>-2.211795</td>\n",
       "      <td>2.044183</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.017610</td>\n",
       "      <td>0.035221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4Shadower</th>\n",
       "      <td>-6.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.767322</td>\n",
       "      <td>0.205075</td>\n",
       "      <td>-2.143194</td>\n",
       "      <td>2.147239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.025797</td>\n",
       "      <td>0.051593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cookics_bot_TEST</th>\n",
       "      <td>-6.9</td>\n",
       "      <td>27.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.744699</td>\n",
       "      <td>0.142267</td>\n",
       "      <td>-1.764876</td>\n",
       "      <td>2.049541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.044576</td>\n",
       "      <td>0.089152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jkraybill_bot</th>\n",
       "      <td>-7.5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.512853</td>\n",
       "      <td>0.077272</td>\n",
       "      <td>-2.197133</td>\n",
       "      <td>2.014642</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>0.033441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twsummerbot</th>\n",
       "      <td>-8.9</td>\n",
       "      <td>58.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.659710</td>\n",
       "      <td>0.086327</td>\n",
       "      <td>-1.758391</td>\n",
       "      <td>2.000855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.042006</td>\n",
       "      <td>0.084012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MWG</th>\n",
       "      <td>-9.8</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.705240</td>\n",
       "      <td>0.131872</td>\n",
       "      <td>-2.589625</td>\n",
       "      <td>2.046561</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.015163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProfessorSP</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.936277</td>\n",
       "      <td>0.217094</td>\n",
       "      <td>-2.484480</td>\n",
       "      <td>2.095243</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.023289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreeneiBot2</th>\n",
       "      <td>-10.4</td>\n",
       "      <td>58.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.849883</td>\n",
       "      <td>0.111260</td>\n",
       "      <td>-1.597976</td>\n",
       "      <td>2.000832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.057772</td>\n",
       "      <td>0.115544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acm_bot</th>\n",
       "      <td>-10.5</td>\n",
       "      <td>80.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.914265</td>\n",
       "      <td>0.102059</td>\n",
       "      <td>-1.287717</td>\n",
       "      <td>1.989344</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.100796</td>\n",
       "      <td>0.201592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajf-bot</th>\n",
       "      <td>-10.9</td>\n",
       "      <td>34.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.085589</td>\n",
       "      <td>0.185496</td>\n",
       "      <td>-1.722395</td>\n",
       "      <td>2.030778</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.047145</td>\n",
       "      <td>0.094289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-o1</th>\n",
       "      <td>-11.5</td>\n",
       "      <td>91.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.888227</td>\n",
       "      <td>0.093060</td>\n",
       "      <td>-1.360468</td>\n",
       "      <td>1.985829</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.088538</td>\n",
       "      <td>0.177076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot_Pepa</th>\n",
       "      <td>-11.5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.737537</td>\n",
       "      <td>0.111125</td>\n",
       "      <td>-2.343166</td>\n",
       "      <td>2.014642</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-perplexity</th>\n",
       "      <td>-11.9</td>\n",
       "      <td>89.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.993669</td>\n",
       "      <td>0.105270</td>\n",
       "      <td>-1.264731</td>\n",
       "      <td>1.986405</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.104652</td>\n",
       "      <td>0.209303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laylaps</th>\n",
       "      <td>-12.9</td>\n",
       "      <td>64.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.082674</td>\n",
       "      <td>-2.440461</td>\n",
       "      <td>1.996907</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.017488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wunderplumb</th>\n",
       "      <td>-13.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.900051</td>\n",
       "      <td>0.178062</td>\n",
       "      <td>-2.984094</td>\n",
       "      <td>2.056603</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.006348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manticAI</th>\n",
       "      <td>-14.6</td>\n",
       "      <td>69.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.670946</td>\n",
       "      <td>0.080510</td>\n",
       "      <td>-2.613354</td>\n",
       "      <td>1.993968</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>0.011014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-deepseek-r1</th>\n",
       "      <td>-14.6</td>\n",
       "      <td>52.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.731525</td>\n",
       "      <td>0.101347</td>\n",
       "      <td>-2.766689</td>\n",
       "      <td>2.005379</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.007864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-Gemini-Exp-1206</th>\n",
       "      <td>-15.2</td>\n",
       "      <td>76.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.943797</td>\n",
       "      <td>0.107907</td>\n",
       "      <td>-1.846774</td>\n",
       "      <td>1.990822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.068698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NextWorldLab</th>\n",
       "      <td>-16.9</td>\n",
       "      <td>80.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.906964</td>\n",
       "      <td>0.101244</td>\n",
       "      <td>-2.078393</td>\n",
       "      <td>1.989344</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.020455</td>\n",
       "      <td>0.040909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bot_median</th>\n",
       "      <td>-17.3</td>\n",
       "      <td>92.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.919122</td>\n",
       "      <td>0.095773</td>\n",
       "      <td>-1.963996</td>\n",
       "      <td>1.985550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.026290</td>\n",
       "      <td>0.052579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minefrac1</th>\n",
       "      <td>-19.2</td>\n",
       "      <td>51.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.880990</td>\n",
       "      <td>0.123242</td>\n",
       "      <td>-3.043641</td>\n",
       "      <td>2.006545</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.003717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-claude-3-5-sonnet-20240620</th>\n",
       "      <td>-19.5</td>\n",
       "      <td>90.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.009138</td>\n",
       "      <td>0.106078</td>\n",
       "      <td>-2.031065</td>\n",
       "      <td>1.986072</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.022608</td>\n",
       "      <td>0.045215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmBot</th>\n",
       "      <td>-21.9</td>\n",
       "      <td>92.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.725010</td>\n",
       "      <td>0.075546</td>\n",
       "      <td>-3.150104</td>\n",
       "      <td>1.985550</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.002208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-grok-2-1212</th>\n",
       "      <td>-22.9</td>\n",
       "      <td>91.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.048829</td>\n",
       "      <td>0.109887</td>\n",
       "      <td>-2.283528</td>\n",
       "      <td>1.985829</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.012375</td>\n",
       "      <td>0.024750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgodzinai</th>\n",
       "      <td>-23.9</td>\n",
       "      <td>76.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.956452</td>\n",
       "      <td>0.109425</td>\n",
       "      <td>-2.858686</td>\n",
       "      <td>1.990849</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.005498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VeritasAI</th>\n",
       "      <td>-24.3</td>\n",
       "      <td>77.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.660703</td>\n",
       "      <td>0.075245</td>\n",
       "      <td>-4.185910</td>\n",
       "      <td>1.990482</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-claude-3-5-sonnet-latest</th>\n",
       "      <td>-24.4</td>\n",
       "      <td>91.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.784315</td>\n",
       "      <td>0.082173</td>\n",
       "      <td>-3.265827</td>\n",
       "      <td>1.985829</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.001544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-Llama-3.1</th>\n",
       "      <td>-26.1</td>\n",
       "      <td>89.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.998799</td>\n",
       "      <td>0.105813</td>\n",
       "      <td>-2.768565</td>\n",
       "      <td>1.986405</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.006863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-exa</th>\n",
       "      <td>-26.6</td>\n",
       "      <td>89.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.848974</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>-3.324097</td>\n",
       "      <td>1.986405</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.001294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InstitutPelFutur</th>\n",
       "      <td>-26.9</td>\n",
       "      <td>90.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.973767</td>\n",
       "      <td>0.102587</td>\n",
       "      <td>-2.908524</td>\n",
       "      <td>1.986114</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.004584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <td>-27.8</td>\n",
       "      <td>91.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.877434</td>\n",
       "      <td>0.091930</td>\n",
       "      <td>-3.314974</td>\n",
       "      <td>1.985829</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.001322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-gpt-4o</th>\n",
       "      <td>-30.5</td>\n",
       "      <td>91.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.913940</td>\n",
       "      <td>0.095754</td>\n",
       "      <td>-3.492827</td>\n",
       "      <td>1.985829</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  W_score  W_count  W_ave   W_stdev   std_err  \\\n",
       "cobyj-bot                             0.0      0.0    NaN       NaN       NaN   \n",
       "andrewsiah                            0.0      0.0    NaN       NaN       NaN   \n",
       "bean_bot                             -0.6      4.7   -0.1  0.069849  0.032219   \n",
       "jonahsingerbot                       -0.6      4.7   -0.1  0.050272  0.023189   \n",
       "X_bot                                -0.7      7.0   -0.1  0.354068  0.133825   \n",
       "RPM_bot                              -1.1      7.0   -0.2  0.824532  0.311644   \n",
       "CumulativeBot                        -1.1     10.2   -0.1  0.257798  0.080522   \n",
       "swingswish                           -1.2      7.7   -0.2  0.140275  0.050552   \n",
       "SynapseSeer                          -1.3     26.2   -0.1  0.452555  0.088498   \n",
       "KevinTestBot                         -1.5      8.4   -0.2  0.589466  0.203385   \n",
       "Grizeu_Bot                           -1.7     51.4   -0.0  1.173392  0.163747   \n",
       "pianobot                             -2.7      4.7   -0.6  0.916204  0.422613   \n",
       "CatrachoCaster                       -3.2     19.7   -0.2  0.520901  0.117361   \n",
       "krm-bot                              -5.1      9.5   -0.5  0.511546  0.165967   \n",
       "annabot                              -6.2     29.3   -0.2  0.520869  0.096226   \n",
       "4Shadower                            -6.2     14.0   -0.4  0.767322  0.205075   \n",
       "cookics_bot_TEST                     -6.9     27.4   -0.3  0.744699  0.142267   \n",
       "jkraybill_bot                        -7.5     44.0   -0.2  0.512853  0.077272   \n",
       "twsummerbot                          -8.9     58.4   -0.2  0.659710  0.086327   \n",
       "MWG                                  -9.8     28.6   -0.3  0.705240  0.131872   \n",
       "ProfessorSP                         -10.0     18.6   -0.5  0.936277  0.217094   \n",
       "GreeneiBot2                         -10.4     58.4   -0.2  0.849883  0.111260   \n",
       "acm_bot                             -10.5     80.2   -0.1  0.914265  0.102059   \n",
       "ajf-bot                             -10.9     34.2   -0.3  1.085589  0.185496   \n",
       "metac-o1                            -11.5     91.1   -0.1  0.888227  0.093060   \n",
       "Bot_Pepa                            -11.5     44.0   -0.3  0.737537  0.111125   \n",
       "metac-perplexity                    -11.9     89.1   -0.1  0.993669  0.105270   \n",
       "laylaps                             -12.9     64.1   -0.2  0.661905  0.082674   \n",
       "wunderplumb                         -13.6     25.6   -0.5  0.900051  0.178062   \n",
       "manticAI                            -14.6     69.4   -0.2  0.670946  0.080510   \n",
       "metac-deepseek-r1                   -14.6     52.1   -0.3  0.731525  0.101347   \n",
       "metac-Gemini-Exp-1206               -15.2     76.5   -0.2  0.943797  0.107907   \n",
       "NextWorldLab                        -16.9     80.2   -0.2  0.906964  0.101244   \n",
       "bot_median                          -17.3     92.1   -0.2  0.919122  0.095773   \n",
       "minefrac1                           -19.2     51.1   -0.4  0.880990  0.123242   \n",
       "metac-claude-3-5-sonnet-20240620    -19.5     90.5   -0.2  1.009138  0.106078   \n",
       "mmBot                               -21.9     92.1   -0.2  0.725010  0.075546   \n",
       "metac-grok-2-1212                   -22.9     91.1   -0.3  1.048829  0.109887   \n",
       "pgodzinai                           -23.9     76.4   -0.3  0.956452  0.109425   \n",
       "VeritasAI                           -24.3     77.1   -0.3  0.660703  0.075245   \n",
       "metac-claude-3-5-sonnet-latest      -24.4     91.1   -0.3  0.784315  0.082173   \n",
       "metac-Llama-3.1                     -26.1     89.1   -0.3  0.998799  0.105813   \n",
       "metac-exa                           -26.6     89.1   -0.3  0.848974  0.089941   \n",
       "InstitutPelFutur                    -26.9     90.1   -0.3  0.973767  0.102587   \n",
       "metac-o1-preview                    -27.8     91.1   -0.3  0.877434  0.091930   \n",
       "metac-gpt-4o                        -30.5     91.1   -0.3  0.913940  0.095754   \n",
       "\n",
       "                                    t_stat    t_crit  upper_bound  \\\n",
       "cobyj-bot                              NaN       NaN          NaN   \n",
       "andrewsiah                             NaN       NaN          NaN   \n",
       "bean_bot                         -4.265106  2.784843         -0.0   \n",
       "jonahsingerbot                   -5.273630  2.784843         -0.1   \n",
       "X_bot                            -0.747195  2.446912          0.2   \n",
       "RPM_bot                          -0.523406  2.446912          0.6   \n",
       "CumulativeBot                    -1.315132  2.231848          0.1   \n",
       "swingswish                       -3.074947  2.367123         -0.0   \n",
       "SynapseSeer                      -0.568910  2.053076          0.1   \n",
       "KevinTestBot                     -0.897116  2.311496          0.3   \n",
       "Grizeu_Bot                       -0.206616  2.006447          0.3   \n",
       "pianobot                         -1.384327  2.798986          0.6   \n",
       "CatrachoCaster                   -1.365532  2.088777          0.1   \n",
       "krm-bot                          -3.229846  2.264709         -0.2   \n",
       "annabot                          -2.211795  2.044183         -0.0   \n",
       "4Shadower                        -2.143194  2.147239          0.0   \n",
       "cookics_bot_TEST                 -1.764876  2.049541          0.0   \n",
       "jkraybill_bot                    -2.197133  2.014642         -0.0   \n",
       "twsummerbot                      -1.758391  2.000855          0.0   \n",
       "MWG                              -2.589625  2.046561         -0.1   \n",
       "ProfessorSP                      -2.484480  2.095243         -0.1   \n",
       "GreeneiBot2                      -1.597976  2.000832          0.0   \n",
       "acm_bot                          -1.287717  1.989344          0.1   \n",
       "ajf-bot                          -1.722395  2.030778          0.1   \n",
       "metac-o1                         -1.360468  1.985829          0.1   \n",
       "Bot_Pepa                         -2.343166  2.014642         -0.0   \n",
       "metac-perplexity                 -1.264731  1.986405          0.1   \n",
       "laylaps                          -2.440461  1.996907         -0.0   \n",
       "wunderplumb                      -2.984094  2.056603         -0.2   \n",
       "manticAI                         -2.613354  1.993968         -0.0   \n",
       "metac-deepseek-r1                -2.766689  2.005379         -0.1   \n",
       "metac-Gemini-Exp-1206            -1.846774  1.990822          0.0   \n",
       "NextWorldLab                     -2.078393  1.989344         -0.0   \n",
       "bot_median                       -1.963996  1.985550          0.0   \n",
       "minefrac1                        -3.043641  2.006545         -0.1   \n",
       "metac-claude-3-5-sonnet-20240620 -2.031065  1.986072         -0.0   \n",
       "mmBot                            -3.150104  1.985550         -0.1   \n",
       "metac-grok-2-1212                -2.283528  1.985829         -0.0   \n",
       "pgodzinai                        -2.858686  1.990849         -0.1   \n",
       "VeritasAI                        -4.185910  1.990482         -0.2   \n",
       "metac-claude-3-5-sonnet-latest   -3.265827  1.985829         -0.1   \n",
       "metac-Llama-3.1                  -2.768565  1.986405         -0.1   \n",
       "metac-exa                        -3.324097  1.986405         -0.1   \n",
       "InstitutPelFutur                 -2.908524  1.986114         -0.1   \n",
       "metac-o1-preview                 -3.314974  1.985829         -0.1   \n",
       "metac-gpt-4o                     -3.492827  1.985829         -0.1   \n",
       "\n",
       "                                  lower_bound       cdf   p_value  \n",
       "cobyj-bot                                 NaN       NaN        NA  \n",
       "andrewsiah                                NaN       NaN        NA  \n",
       "bean_bot                                 -0.2  0.007674  0.015349  \n",
       "jonahsingerbot                           -0.2  0.003839  0.007677  \n",
       "X_bot                                    -0.4  0.241594  0.483189  \n",
       "RPM_bot                                  -0.9  0.309726  0.619452  \n",
       "CumulativeBot                            -0.3  0.110066  0.220132  \n",
       "swingswish                               -0.3  0.009476  0.018953  \n",
       "SynapseSeer                              -0.2  0.287231  0.574463  \n",
       "KevinTestBot                             -0.7  0.198952  0.397903  \n",
       "Grizeu_Bot                               -0.4  0.418571  0.837143  \n",
       "pianobot                                 -1.8  0.121941  0.243882  \n",
       "CatrachoCaster                           -0.4  0.094144  0.188288  \n",
       "krm-bot                                  -0.9  0.005563  0.011127  \n",
       "annabot                                  -0.4  0.017610  0.035221  \n",
       "4Shadower                                -0.9  0.025797  0.051593  \n",
       "cookics_bot_TEST                         -0.5  0.044576  0.089152  \n",
       "jkraybill_bot                            -0.3  0.016721  0.033441  \n",
       "twsummerbot                              -0.3  0.042006  0.084012  \n",
       "MWG                                      -0.6  0.007581  0.015163  \n",
       "ProfessorSP                              -1.0  0.011644  0.023289  \n",
       "GreeneiBot2                              -0.4  0.057772  0.115544  \n",
       "acm_bot                                  -0.3  0.100796  0.201592  \n",
       "ajf-bot                                  -0.7  0.047145  0.094289  \n",
       "metac-o1                                 -0.3  0.088538  0.177076  \n",
       "Bot_Pepa                                 -0.5  0.011905  0.023810  \n",
       "metac-perplexity                         -0.3  0.104652  0.209303  \n",
       "laylaps                                  -0.4  0.008744  0.017488  \n",
       "wunderplumb                              -0.9  0.003174  0.006348  \n",
       "manticAI                                 -0.4  0.005507  0.011014  \n",
       "metac-deepseek-r1                        -0.5  0.003932  0.007864  \n",
       "metac-Gemini-Exp-1206                    -0.4  0.034349  0.068698  \n",
       "NextWorldLab                             -0.4  0.020455  0.040909  \n",
       "bot_median                               -0.4  0.026290  0.052579  \n",
       "minefrac1                                -0.6  0.001859  0.003717  \n",
       "metac-claude-3-5-sonnet-20240620         -0.4  0.022608  0.045215  \n",
       "mmBot                                    -0.4  0.001104  0.002208  \n",
       "metac-grok-2-1212                        -0.5  0.012375  0.024750  \n",
       "pgodzinai                                -0.5  0.002749  0.005498  \n",
       "VeritasAI                                -0.5  0.000038  0.000076  \n",
       "metac-claude-3-5-sonnet-latest           -0.4  0.000772  0.001544  \n",
       "metac-Llama-3.1                          -0.5  0.003432  0.006863  \n",
       "metac-exa                                -0.5  0.000647  0.001294  \n",
       "InstitutPelFutur                         -0.5  0.002292  0.004584  \n",
       "metac-o1-preview                         -0.5  0.000661  0.001322  \n",
       "metac-gpt-4o                             -0.5  0.000371  0.000743  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Weighted head-to-head, T test\n",
    "\n",
    "\"\"\"\n",
    "df_W_leaderboard: A leaderboard based on df_bot_vs_pro_peer with question\n",
    "weighting and the calculations for doing a weighted T test\n",
    "\"\"\"\n",
    "\n",
    "forecaster_weighted_scores = forecaster_weighted_scores.fillna(0)\n",
    "\n",
    "# Cast weights as numeric\n",
    "df_bot_vs_pro_peer['question_weight'] = pd.to_numeric(df_bot_vs_pro_peer['question_weight'], errors='coerce')\n",
    "\n",
    "# Calculate weighted statistics for each bot\n",
    "df_W_leaderboard = calculate_t_test(df_bot_vs_pro_peer, all_bots)\n",
    "\n",
    "df_W_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "df_W_leaderboard.to_csv('notebook_outputs/weighted_t_test_h2h_bot_vs_pros.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d_ZdL0A0qTz",
    "outputId": "e30ee8fb-0faf-45ae-974e-d4af282e0252"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Bot</th>\n",
       "      <th>W_score</th>\n",
       "      <th>W_count</th>\n",
       "      <th>W_ave</th>\n",
       "      <th>W_stdev</th>\n",
       "      <th>std_err</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>t_crit</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>cdf</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>metac-o1</td>\n",
       "      <td>3631.1</td>\n",
       "      <td>375.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>35.071140</td>\n",
       "      <td>1.810294</td>\n",
       "      <td>5.344293</td>\n",
       "      <td>1.965985</td>\n",
       "      <td>13.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>metac-o1-preview</td>\n",
       "      <td>3121.4</td>\n",
       "      <td>368.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>45.961589</td>\n",
       "      <td>2.393573</td>\n",
       "      <td>3.536820</td>\n",
       "      <td>1.966093</td>\n",
       "      <td>13.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.999772</td>\n",
       "      <td>0.000457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>metac-Gemini-Exp-1206</td>\n",
       "      <td>1880.5</td>\n",
       "      <td>347.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>44.895844</td>\n",
       "      <td>2.409719</td>\n",
       "      <td>2.248133</td>\n",
       "      <td>1.966458</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.987402</td>\n",
       "      <td>0.025197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SynapseSeer</td>\n",
       "      <td>966.5</td>\n",
       "      <td>152.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>35.699215</td>\n",
       "      <td>2.895113</td>\n",
       "      <td>2.195568</td>\n",
       "      <td>1.974879</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.985176</td>\n",
       "      <td>0.029648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>manticAI</td>\n",
       "      <td>2055.2</td>\n",
       "      <td>315.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>55.690063</td>\n",
       "      <td>3.134498</td>\n",
       "      <td>2.077154</td>\n",
       "      <td>1.967187</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.980701</td>\n",
       "      <td>0.038598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>twsummerbot</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>241.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.091140</td>\n",
       "      <td>2.902709</td>\n",
       "      <td>2.070153</td>\n",
       "      <td>1.969313</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.980247</td>\n",
       "      <td>0.039507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>acm_bot</td>\n",
       "      <td>1738.4</td>\n",
       "      <td>344.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.846332</td>\n",
       "      <td>2.469143</td>\n",
       "      <td>2.042154</td>\n",
       "      <td>1.966521</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.979051</td>\n",
       "      <td>0.041899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>cookics_bot_TEST</td>\n",
       "      <td>1143.8</td>\n",
       "      <td>162.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.796454</td>\n",
       "      <td>3.669887</td>\n",
       "      <td>1.916829</td>\n",
       "      <td>1.974138</td>\n",
       "      <td>14.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.971488</td>\n",
       "      <td>0.057024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>CumulativeBot</td>\n",
       "      <td>991.4</td>\n",
       "      <td>104.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>52.180325</td>\n",
       "      <td>5.104446</td>\n",
       "      <td>1.858584</td>\n",
       "      <td>1.982136</td>\n",
       "      <td>19.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.967036</td>\n",
       "      <td>0.065928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>metac-claude-3-5-sonnet-latest</td>\n",
       "      <td>951.3</td>\n",
       "      <td>370.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>38.263066</td>\n",
       "      <td>1.988342</td>\n",
       "      <td>1.291954</td>\n",
       "      <td>1.966063</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.901410</td>\n",
       "      <td>0.197181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>GreeneiBot2</td>\n",
       "      <td>1494.7</td>\n",
       "      <td>264.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>59.728354</td>\n",
       "      <td>3.675052</td>\n",
       "      <td>1.539811</td>\n",
       "      <td>1.968596</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.124808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>metac-perplexity</td>\n",
       "      <td>1558.4</td>\n",
       "      <td>354.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>59.588378</td>\n",
       "      <td>3.165209</td>\n",
       "      <td>1.389181</td>\n",
       "      <td>1.966371</td>\n",
       "      <td>10.6</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.917174</td>\n",
       "      <td>0.165652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>metac-deepseek-r1</td>\n",
       "      <td>516.8</td>\n",
       "      <td>277.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>37.353210</td>\n",
       "      <td>2.240780</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>1.968165</td>\n",
       "      <td>6.3</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>0.796366</td>\n",
       "      <td>0.407268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>pgodzinai</td>\n",
       "      <td>1106.7</td>\n",
       "      <td>325.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>66.686159</td>\n",
       "      <td>3.696695</td>\n",
       "      <td>0.919954</td>\n",
       "      <td>1.966949</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.820860</td>\n",
       "      <td>0.358280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>metac-exa</td>\n",
       "      <td>599.9</td>\n",
       "      <td>365.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>63.459389</td>\n",
       "      <td>3.320161</td>\n",
       "      <td>0.494611</td>\n",
       "      <td>1.966142</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>0.689413</td>\n",
       "      <td>0.621173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>MWG</td>\n",
       "      <td>253.8</td>\n",
       "      <td>113.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>40.674084</td>\n",
       "      <td>3.819037</td>\n",
       "      <td>0.585936</td>\n",
       "      <td>1.980468</td>\n",
       "      <td>9.8</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>0.720454</td>\n",
       "      <td>0.559093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>jkraybill_bot</td>\n",
       "      <td>625.4</td>\n",
       "      <td>207.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.560780</td>\n",
       "      <td>4.760477</td>\n",
       "      <td>0.633389</td>\n",
       "      <td>1.971015</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>0.736410</td>\n",
       "      <td>0.527181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>metac-claude-3-5-sonnet-20240620</td>\n",
       "      <td>-759.5</td>\n",
       "      <td>373.7</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>44.090480</td>\n",
       "      <td>2.280718</td>\n",
       "      <td>-0.891011</td>\n",
       "      <td>1.966014</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>0.186749</td>\n",
       "      <td>0.373498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>metac-grok-2-1212</td>\n",
       "      <td>-550.1</td>\n",
       "      <td>373.3</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>50.164246</td>\n",
       "      <td>2.596293</td>\n",
       "      <td>-0.567553</td>\n",
       "      <td>1.966016</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>0.285340</td>\n",
       "      <td>0.570681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>metac-Llama-3.1</td>\n",
       "      <td>-980.9</td>\n",
       "      <td>370.6</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>41.810063</td>\n",
       "      <td>2.171783</td>\n",
       "      <td>-1.218611</td>\n",
       "      <td>1.966062</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>0.111885</td>\n",
       "      <td>0.223769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>mmBot</td>\n",
       "      <td>-587.4</td>\n",
       "      <td>373.0</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>58.298439</td>\n",
       "      <td>3.018498</td>\n",
       "      <td>-0.521671</td>\n",
       "      <td>1.966017</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>0.301105</td>\n",
       "      <td>0.602210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>VeritasAI</td>\n",
       "      <td>-1602.2</td>\n",
       "      <td>330.0</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>38.754780</td>\n",
       "      <td>2.133316</td>\n",
       "      <td>-2.275710</td>\n",
       "      <td>1.966760</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.023506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>InstitutPelFutur</td>\n",
       "      <td>-877.8</td>\n",
       "      <td>356.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>64.603477</td>\n",
       "      <td>3.423881</td>\n",
       "      <td>-0.720127</td>\n",
       "      <td>1.966305</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-9.2</td>\n",
       "      <td>0.235960</td>\n",
       "      <td>0.471921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>NextWorldLab</td>\n",
       "      <td>-1377.9</td>\n",
       "      <td>337.6</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>51.433388</td>\n",
       "      <td>2.799472</td>\n",
       "      <td>-1.458157</td>\n",
       "      <td>1.966664</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-9.6</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.145730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>metac-gpt-4o</td>\n",
       "      <td>-2235.4</td>\n",
       "      <td>373.3</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>45.401670</td>\n",
       "      <td>2.349802</td>\n",
       "      <td>-2.548209</td>\n",
       "      <td>1.966016</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>0.005614</td>\n",
       "      <td>0.011229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>CatrachoCaster</td>\n",
       "      <td>-289.4</td>\n",
       "      <td>81.6</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>31.956725</td>\n",
       "      <td>3.538536</td>\n",
       "      <td>-1.002608</td>\n",
       "      <td>1.988342</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>0.159526</td>\n",
       "      <td>0.319052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>laylaps</td>\n",
       "      <td>-1489.1</td>\n",
       "      <td>322.1</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>63.980238</td>\n",
       "      <td>3.564926</td>\n",
       "      <td>-1.296855</td>\n",
       "      <td>1.967050</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>0.097806</td>\n",
       "      <td>0.195612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>ProfessorSP</td>\n",
       "      <td>-426.8</td>\n",
       "      <td>128.6</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>55.165460</td>\n",
       "      <td>4.863650</td>\n",
       "      <td>-0.682142</td>\n",
       "      <td>1.978123</td>\n",
       "      <td>6.3</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>0.248193</td>\n",
       "      <td>0.496385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>krm-bot</td>\n",
       "      <td>-354.7</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>49.875492</td>\n",
       "      <td>4.890694</td>\n",
       "      <td>-0.697334</td>\n",
       "      <td>1.982327</td>\n",
       "      <td>6.3</td>\n",
       "      <td>-13.1</td>\n",
       "      <td>0.243582</td>\n",
       "      <td>0.487165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>wunderplumb</td>\n",
       "      <td>-986.1</td>\n",
       "      <td>174.0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>52.965893</td>\n",
       "      <td>4.015334</td>\n",
       "      <td>-1.411434</td>\n",
       "      <td>1.973195</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-13.6</td>\n",
       "      <td>0.079956</td>\n",
       "      <td>0.159913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>andrewsiah</td>\n",
       "      <td>2.6</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>35.805092</td>\n",
       "      <td>7.146739</td>\n",
       "      <td>0.014679</td>\n",
       "      <td>2.060341</td>\n",
       "      <td>14.8</td>\n",
       "      <td>-14.6</td>\n",
       "      <td>0.505796</td>\n",
       "      <td>0.988409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>annabot</td>\n",
       "      <td>-190.6</td>\n",
       "      <td>83.8</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>59.112228</td>\n",
       "      <td>6.458906</td>\n",
       "      <td>-0.352222</td>\n",
       "      <td>1.986408</td>\n",
       "      <td>10.6</td>\n",
       "      <td>-15.1</td>\n",
       "      <td>0.362784</td>\n",
       "      <td>0.725567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Bot_Pepa</td>\n",
       "      <td>-1490.1</td>\n",
       "      <td>169.4</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>44.265702</td>\n",
       "      <td>3.400530</td>\n",
       "      <td>-2.586005</td>\n",
       "      <td>1.973733</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.010555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>4Shadower</td>\n",
       "      <td>-646.3</td>\n",
       "      <td>115.5</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>53.867867</td>\n",
       "      <td>5.012320</td>\n",
       "      <td>-1.116305</td>\n",
       "      <td>1.979785</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>0.133314</td>\n",
       "      <td>0.266629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>minefrac1</td>\n",
       "      <td>-1757.1</td>\n",
       "      <td>188.2</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>44.125849</td>\n",
       "      <td>3.216071</td>\n",
       "      <td>-2.902190</td>\n",
       "      <td>1.972106</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-15.7</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.004150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>KevinTestBot</td>\n",
       "      <td>-220.4</td>\n",
       "      <td>89.5</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>67.650877</td>\n",
       "      <td>7.150920</td>\n",
       "      <td>-0.344310</td>\n",
       "      <td>1.985505</td>\n",
       "      <td>11.7</td>\n",
       "      <td>-16.7</td>\n",
       "      <td>0.365715</td>\n",
       "      <td>0.731430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>jonahsingerbot</td>\n",
       "      <td>-333.4</td>\n",
       "      <td>64.8</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>48.015548</td>\n",
       "      <td>5.964779</td>\n",
       "      <td>-0.862600</td>\n",
       "      <td>1.995273</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.195794</td>\n",
       "      <td>0.391588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>bean_bot</td>\n",
       "      <td>-208.8</td>\n",
       "      <td>67.8</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>59.955662</td>\n",
       "      <td>7.281408</td>\n",
       "      <td>-0.422940</td>\n",
       "      <td>1.993771</td>\n",
       "      <td>11.4</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.336849</td>\n",
       "      <td>0.673697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>Grizeu_Bot</td>\n",
       "      <td>-1882.6</td>\n",
       "      <td>193.2</td>\n",
       "      <td>-9.7</td>\n",
       "      <td>56.704237</td>\n",
       "      <td>4.079442</td>\n",
       "      <td>-2.388521</td>\n",
       "      <td>1.971774</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-17.8</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.017884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>cobyj-bot</td>\n",
       "      <td>-12.1</td>\n",
       "      <td>31.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>48.040991</td>\n",
       "      <td>8.559663</td>\n",
       "      <td>-0.045046</td>\n",
       "      <td>2.039850</td>\n",
       "      <td>17.1</td>\n",
       "      <td>-17.8</td>\n",
       "      <td>0.482182</td>\n",
       "      <td>0.964365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>X_bot</td>\n",
       "      <td>-16.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>23.908632</td>\n",
       "      <td>9.036614</td>\n",
       "      <td>-0.253774</td>\n",
       "      <td>2.446912</td>\n",
       "      <td>19.8</td>\n",
       "      <td>-24.4</td>\n",
       "      <td>0.404071</td>\n",
       "      <td>0.808142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>ajf-bot</td>\n",
       "      <td>-3208.3</td>\n",
       "      <td>229.2</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>83.295569</td>\n",
       "      <td>5.502524</td>\n",
       "      <td>-2.544414</td>\n",
       "      <td>1.969928</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-24.8</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.011607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>pianobot</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>19.6</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>52.323487</td>\n",
       "      <td>11.833775</td>\n",
       "      <td>-0.055042</td>\n",
       "      <td>2.093823</td>\n",
       "      <td>24.1</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>0.478347</td>\n",
       "      <td>0.956694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>swingswish</td>\n",
       "      <td>-777.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>73.047892</td>\n",
       "      <td>9.074447</td>\n",
       "      <td>-1.321436</td>\n",
       "      <td>1.995273</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-30.1</td>\n",
       "      <td>0.095538</td>\n",
       "      <td>0.191075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>RPM_bot</td>\n",
       "      <td>-815.6</td>\n",
       "      <td>23.8</td>\n",
       "      <td>-34.3</td>\n",
       "      <td>91.545402</td>\n",
       "      <td>18.784720</td>\n",
       "      <td>-1.828100</td>\n",
       "      <td>2.061508</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-73.1</td>\n",
       "      <td>0.040339</td>\n",
       "      <td>0.080679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                               Bot  W_score  W_count  W_ave  \\\n",
       "0      1                          metac-o1   3631.1    375.3    9.7   \n",
       "1      2                  metac-o1-preview   3121.4    368.7    8.5   \n",
       "2      3             metac-Gemini-Exp-1206   1880.5    347.1    5.4   \n",
       "3      4                       SynapseSeer    966.5    152.0    6.4   \n",
       "4      5                          manticAI   2055.2    315.7    6.5   \n",
       "5      6                       twsummerbot   1450.0    241.3    6.0   \n",
       "6      7                           acm_bot   1738.4    344.8    5.0   \n",
       "7      8                  cookics_bot_TEST   1143.8    162.6    7.0   \n",
       "8      9                     CumulativeBot    991.4    104.5    9.5   \n",
       "9     10    metac-claude-3-5-sonnet-latest    951.3    370.3    2.6   \n",
       "10    11                       GreeneiBot2   1494.7    264.1    5.7   \n",
       "11    12                  metac-perplexity   1558.4    354.4    4.4   \n",
       "12    13                 metac-deepseek-r1    516.8    277.9    1.9   \n",
       "13    14                         pgodzinai   1106.7    325.4    3.4   \n",
       "14    15                         metac-exa    599.9    365.3    1.6   \n",
       "15    16                               MWG    253.8    113.4    2.2   \n",
       "16    17                     jkraybill_bot    625.4    207.4    3.0   \n",
       "17    18  metac-claude-3-5-sonnet-20240620   -759.5    373.7   -2.0   \n",
       "18    19                 metac-grok-2-1212   -550.1    373.3   -1.5   \n",
       "19    20                   metac-Llama-3.1   -980.9    370.6   -2.6   \n",
       "20    21                             mmBot   -587.4    373.0   -1.6   \n",
       "21    22                         VeritasAI  -1602.2    330.0   -4.9   \n",
       "22    23                  InstitutPelFutur   -877.8    356.0   -2.5   \n",
       "23    24                      NextWorldLab  -1377.9    337.6   -4.1   \n",
       "24    25                      metac-gpt-4o  -2235.4    373.3   -6.0   \n",
       "25    26                    CatrachoCaster   -289.4     81.6   -3.5   \n",
       "26    27                           laylaps  -1489.1    322.1   -4.6   \n",
       "27    28                       ProfessorSP   -426.8    128.6   -3.3   \n",
       "28    29                           krm-bot   -354.7    104.0   -3.4   \n",
       "29    30                       wunderplumb   -986.1    174.0   -5.7   \n",
       "30    31                        andrewsiah      2.6     25.1    0.1   \n",
       "31    32                           annabot   -190.6     83.8   -2.3   \n",
       "32    33                          Bot_Pepa  -1490.1    169.4   -8.8   \n",
       "33    34                         4Shadower   -646.3    115.5   -5.6   \n",
       "34    35                         minefrac1  -1757.1    188.2   -9.3   \n",
       "35    36                      KevinTestBot   -220.4     89.5   -2.5   \n",
       "36    37                    jonahsingerbot   -333.4     64.8   -5.1   \n",
       "37    38                          bean_bot   -208.8     67.8   -3.1   \n",
       "38    39                        Grizeu_Bot  -1882.6    193.2   -9.7   \n",
       "39    40                         cobyj-bot    -12.1     31.5   -0.4   \n",
       "40    41                             X_bot    -16.1      7.0   -2.3   \n",
       "41    42                           ajf-bot  -3208.3    229.2  -14.0   \n",
       "42    43                          pianobot    -12.7     19.6   -0.7   \n",
       "43    44                        swingswish   -777.0     64.8  -12.0   \n",
       "44    45                           RPM_bot   -815.6     23.8  -34.3   \n",
       "\n",
       "      W_stdev    std_err    t_stat    t_crit  upper_bound  lower_bound  \\\n",
       "0   35.071140   1.810294  5.344293  1.965985         13.2          6.1   \n",
       "1   45.961589   2.393573  3.536820  1.966093         13.2          3.8   \n",
       "2   44.895844   2.409719  2.248133  1.966458         10.2          0.7   \n",
       "3   35.699215   2.895113  2.195568  1.974879         12.1          0.6   \n",
       "4   55.690063   3.134498  2.077154  1.967187         12.7          0.3   \n",
       "5   45.091140   2.902709  2.070153  1.969313         11.7          0.3   \n",
       "6   45.846332   2.469143  2.042154  1.966521          9.9          0.2   \n",
       "7   46.796454   3.669887  1.916829  1.974138         14.3         -0.2   \n",
       "8   52.180325   5.104446  1.858584  1.982136         19.6         -0.6   \n",
       "9   38.263066   1.988342  1.291954  1.966063          6.5         -1.3   \n",
       "10  59.728354   3.675052  1.539811  1.968596         12.9         -1.6   \n",
       "11  59.588378   3.165209  1.389181  1.966371         10.6         -1.8   \n",
       "12  37.353210   2.240780  0.829975  1.968165          6.3         -2.6   \n",
       "13  66.686159   3.696695  0.919954  1.966949         10.7         -3.9   \n",
       "14  63.459389   3.320161  0.494611  1.966142          8.2         -4.9   \n",
       "15  40.674084   3.819037  0.585936  1.980468          9.8         -5.3   \n",
       "16  68.560780   4.760477  0.633389  1.971015         12.4         -6.4   \n",
       "17  44.090480   2.280718 -0.891011  1.966014          2.5         -6.5   \n",
       "18  50.164246   2.596293 -0.567553  1.966016          3.6         -6.6   \n",
       "19  41.810063   2.171783 -1.218611  1.966062          1.6         -6.9   \n",
       "20  58.298439   3.018498 -0.521671  1.966017          4.4         -7.5   \n",
       "21  38.754780   2.133316 -2.275710  1.966760         -0.7         -9.1   \n",
       "22  64.603477   3.423881 -0.720127  1.966305          4.3         -9.2   \n",
       "23  51.433388   2.799472 -1.458157  1.966664          1.4         -9.6   \n",
       "24  45.401670   2.349802 -2.548209  1.966016         -1.4        -10.6   \n",
       "25  31.956725   3.538536 -1.002608  1.988342          3.5        -10.6   \n",
       "26  63.980238   3.564926 -1.296855  1.967050          2.4        -11.6   \n",
       "27  55.165460   4.863650 -0.682142  1.978123          6.3        -12.9   \n",
       "28  49.875492   4.890694 -0.697334  1.982327          6.3        -13.1   \n",
       "29  52.965893   4.015334 -1.411434  1.973195          2.3        -13.6   \n",
       "30  35.805092   7.146739  0.014679  2.060341         14.8        -14.6   \n",
       "31  59.112228   6.458906 -0.352222  1.986408         10.6        -15.1   \n",
       "32  44.265702   3.400530 -2.586005  1.973733         -2.1        -15.5   \n",
       "33  53.867867   5.012320 -1.116305  1.979785          4.3        -15.5   \n",
       "34  44.125849   3.216071 -2.902190  1.972106         -3.0        -15.7   \n",
       "35  67.650877   7.150920 -0.344310  1.985505         11.7        -16.7   \n",
       "36  48.015548   5.964779 -0.862600  1.995273          6.8        -17.0   \n",
       "37  59.955662   7.281408 -0.422940  1.993771         11.4        -17.6   \n",
       "38  56.704237   4.079442 -2.388521  1.971774         -1.7        -17.8   \n",
       "39  48.040991   8.559663 -0.045046  2.039850         17.1        -17.8   \n",
       "40  23.908632   9.036614 -0.253774  2.446912         19.8        -24.4   \n",
       "41  83.295569   5.502524 -2.544414  1.969928         -3.2        -24.8   \n",
       "42  52.323487  11.833775 -0.055042  2.093823         24.1        -25.4   \n",
       "43  73.047892   9.074447 -1.321436  1.995273          6.1        -30.1   \n",
       "44  91.545402  18.784720 -1.828100  2.061508          4.4        -73.1   \n",
       "\n",
       "         cdf   p_value  \n",
       "0   1.000000  0.000000  \n",
       "1   0.999772  0.000457  \n",
       "2   0.987402  0.025197  \n",
       "3   0.985176  0.029648  \n",
       "4   0.980701  0.038598  \n",
       "5   0.980247  0.039507  \n",
       "6   0.979051  0.041899  \n",
       "7   0.971488  0.057024  \n",
       "8   0.967036  0.065928  \n",
       "9   0.901410  0.197181  \n",
       "10  0.937596  0.124808  \n",
       "11  0.917174  0.165652  \n",
       "12  0.796366  0.407268  \n",
       "13  0.820860  0.358280  \n",
       "14  0.689413  0.621173  \n",
       "15  0.720454  0.559093  \n",
       "16  0.736410  0.527181  \n",
       "17  0.186749  0.373498  \n",
       "18  0.285340  0.570681  \n",
       "19  0.111885  0.223769  \n",
       "20  0.301105  0.602210  \n",
       "21  0.011753  0.023506  \n",
       "22  0.235960  0.471921  \n",
       "23  0.072865  0.145730  \n",
       "24  0.005614  0.011229  \n",
       "25  0.159526  0.319052  \n",
       "26  0.097806  0.195612  \n",
       "27  0.248193  0.496385  \n",
       "28  0.243582  0.487165  \n",
       "29  0.079956  0.159913  \n",
       "30  0.505796  0.988409  \n",
       "31  0.362784  0.725567  \n",
       "32  0.005278  0.010555  \n",
       "33  0.133314  0.266629  \n",
       "34  0.002075  0.004150  \n",
       "35  0.365715  0.731430  \n",
       "36  0.195794  0.391588  \n",
       "37  0.336849  0.673697  \n",
       "38  0.008942  0.017884  \n",
       "39  0.482182  0.964365  \n",
       "40  0.404071  0.808142  \n",
       "41  0.005803  0.011607  \n",
       "42  0.478347  0.956694  \n",
       "43  0.095538  0.191075  \n",
       "44  0.040339  0.080679  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Weighted Bot Peer, T test (to compare bots against each other, use ALL QUESTIONS)\n",
    "\n",
    "df_W_bot_peer_leaderboard = pd.DataFrame()\n",
    "\n",
    "df3 = pd.DataFrame()\n",
    "\n",
    "forecaster_weighted_scores = forecaster_weighted_scores.fillna(0)\n",
    "\n",
    "# OMIT bot_median column for this bit\n",
    "df_bot_peer_wide_b = df_bot_peer_wide.drop('bot_median', axis=1)\n",
    "df_bot_peer = df_bot_peer[df_bot_peer['forecaster'] != 'bot_median']\n",
    "\n",
    "bots_for_peer = np.array(list(set(df_bot_peer['forecaster'])))\n",
    "\n",
    "df_W_leaderboard = calculate_t_test(df_bot_peer_wide_b, bots_for_peer)\n",
    "\n",
    "df_W_leaderboard_print = df_W_leaderboard.sort_values(by='lower_bound', ascending=False)\n",
    "df_W_leaderboard_print['Rank'] = range(1, len(df_W_leaderboard_print) + 1)\n",
    "\n",
    "# Make index into a column - Bot\n",
    "df_W_leaderboard_print = df_W_leaderboard_print.reset_index()\n",
    "df_W_leaderboard_print = df_W_leaderboard_print.rename(columns={'index': 'Bot'})\n",
    "#df_W_leaderboard_print = df_W_leaderboard_print[['Rank', 'Bot', 'W_ave', 'W_count', 'lower_bound', 'upper_bound']]\n",
    "# Make rank the first column; leave rest the same\n",
    "cols = df_W_leaderboard_print.columns.tolist()\n",
    "cols = ['Rank'] + cols[:-1]\n",
    "df_W_leaderboard_print = df_W_leaderboard_print[cols]\n",
    "\n",
    "df_W_leaderboard_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "df_W_leaderboard_print.to_csv('notebook_outputs/weighted_bot_peer_leaderboard_t_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>4Shadower</th>\n",
       "      <th>Bot_Pepa</th>\n",
       "      <th>CatrachoCaster</th>\n",
       "      <th>CumulativeBot</th>\n",
       "      <th>GreeneiBot2</th>\n",
       "      <th>Grizeu_Bot</th>\n",
       "      <th>InstitutPelFutur</th>\n",
       "      <th>KevinTestBot</th>\n",
       "      <th>MWG</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "      <th>question_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-242.660874</td>\n",
       "      <td>135.575273</td>\n",
       "      <td>47.259183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-205.076095</td>\n",
       "      <td>121.194882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-242.660874</td>\n",
       "      <td>-198.879258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-96.476789</td>\n",
       "      <td>-99.090018</td>\n",
       "      <td>-94.660371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.951703</td>\n",
       "      <td>7.951703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.819041</td>\n",
       "      <td>44.625993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.892980</td>\n",
       "      <td>23.948225</td>\n",
       "      <td>-86.527528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.821518</td>\n",
       "      <td>13.821518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.307071</td>\n",
       "      <td>17.305437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.076868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.094531</td>\n",
       "      <td>4.282464</td>\n",
       "      <td>-28.806893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.663415</td>\n",
       "      <td>...</td>\n",
       "      <td>6.442579</td>\n",
       "      <td>16.621639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.559053</td>\n",
       "      <td>11.145899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.706540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.694891</td>\n",
       "      <td>-66.461608</td>\n",
       "      <td>-58.368696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.698675</td>\n",
       "      <td>-0.691552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.414502</td>\n",
       "      <td>14.411756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.932651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bot_question_id  4Shadower  Bot_Pepa  CatrachoCaster  CumulativeBot  \\\n",
       "0            31262        NaN       NaN             NaN            NaN   \n",
       "1            31263        NaN       NaN             NaN            NaN   \n",
       "2            31264        NaN       NaN             NaN            NaN   \n",
       "3            31274        NaN       NaN        2.076868            NaN   \n",
       "4            31275        NaN       NaN             NaN            NaN   \n",
       "\n",
       "   GreeneiBot2  Grizeu_Bot  InstitutPelFutur  KevinTestBot        MWG  ...  \\\n",
       "0  -242.660874  135.575273         47.259183           NaN        NaN  ...   \n",
       "1   -96.476789  -99.090018        -94.660371           NaN        NaN  ...   \n",
       "2    18.892980   23.948225        -86.527528           NaN        NaN  ...   \n",
       "3    31.094531    4.282464        -28.806893           NaN  14.663415  ...   \n",
       "4    30.694891  -66.461608        -58.368696           NaN        NaN  ...   \n",
       "\n",
       "   metac-o1-preview  metac-perplexity  minefrac1       mmBot   pgodzinai  \\\n",
       "0       -205.076095        121.194882        NaN -242.660874 -198.879258   \n",
       "1          7.951703          7.951703        NaN   55.819041   44.625993   \n",
       "2         13.821518         13.821518        NaN    1.307071   17.305437   \n",
       "3          6.442579         16.621639        NaN    8.559053   11.145899   \n",
       "4         35.698675         -0.691552        NaN   39.414502   14.411756   \n",
       "\n",
       "   pianobot  swingswish  twsummerbot  wunderplumb  question_weight  \n",
       "0       NaN         NaN          NaN          NaN              1.0  \n",
       "1       NaN         NaN          NaN          NaN              1.0  \n",
       "2       NaN         NaN          NaN          NaN              1.0  \n",
       "3       NaN         NaN    -9.706540          NaN              1.0  \n",
       "4       NaN         NaN   -70.932651          NaN              1.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bot_peer_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "88QO8eyW6T_T",
    "outputId": "e83d6794-13a2-454d-cb70-0a38b065d9e7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Histogram of bot\n",
    "\n",
    "if 'mf-bot-1' in df_bot_peer_wide.columns:\n",
    "  name = 'mf-bot-1'\n",
    "else:\n",
    "  name = 'metac-o1-preview'\n",
    "\n",
    "scores = df_bot_peer_wide[name].dropna()\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "n, bins, patches = plt.hist(scores, bins=30, density=True, alpha=0.7, color='skyblue')\n",
    "\n",
    "# Fit a normal distribution to the data\n",
    "mu, std = norm.fit(scores)\n",
    "\n",
    "# Plot the PDF of the fitted normal distribution\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(f\"Histogram of {name} Scores with Fitted Gaussian\", fontsize=16)\n",
    "plt.xlabel(\"Score\", fontsize=14)\n",
    "plt.ylabel(\"Density\", fontsize=14)\n",
    "\n",
    "# Add text box with distribution parameters\n",
    "textstr = f'$\\mu={mu:.2f}$\\n$\\sigma={std:.2f}$'\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=14,\n",
    "         verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>4Shadower</th>\n",
       "      <th>Bot_Pepa</th>\n",
       "      <th>CatrachoCaster</th>\n",
       "      <th>CumulativeBot</th>\n",
       "      <th>GreeneiBot2</th>\n",
       "      <th>Grizeu_Bot</th>\n",
       "      <th>InstitutPelFutur</th>\n",
       "      <th>KevinTestBot</th>\n",
       "      <th>MWG</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "      <th>question_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-242.660874</td>\n",
       "      <td>135.575273</td>\n",
       "      <td>47.259183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-205.076095</td>\n",
       "      <td>121.194882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-242.660874</td>\n",
       "      <td>-198.879258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-96.476789</td>\n",
       "      <td>-99.090018</td>\n",
       "      <td>-94.660371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.951703</td>\n",
       "      <td>7.951703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.819041</td>\n",
       "      <td>44.625993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.892980</td>\n",
       "      <td>23.948225</td>\n",
       "      <td>-86.527528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.821518</td>\n",
       "      <td>13.821518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.307071</td>\n",
       "      <td>17.305437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.076868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.094531</td>\n",
       "      <td>4.282464</td>\n",
       "      <td>-28.806893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.663415</td>\n",
       "      <td>...</td>\n",
       "      <td>6.442579</td>\n",
       "      <td>16.621639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.559053</td>\n",
       "      <td>11.145899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.706540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.694891</td>\n",
       "      <td>-66.461608</td>\n",
       "      <td>-58.368696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.698675</td>\n",
       "      <td>-0.691552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.414502</td>\n",
       "      <td>14.411756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.932651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bot_question_id  4Shadower  Bot_Pepa  CatrachoCaster  CumulativeBot  \\\n",
       "0            31262        NaN       NaN             NaN            NaN   \n",
       "1            31263        NaN       NaN             NaN            NaN   \n",
       "2            31264        NaN       NaN             NaN            NaN   \n",
       "3            31274        NaN       NaN        2.076868            NaN   \n",
       "4            31275        NaN       NaN             NaN            NaN   \n",
       "\n",
       "   GreeneiBot2  Grizeu_Bot  InstitutPelFutur  KevinTestBot        MWG  ...  \\\n",
       "0  -242.660874  135.575273         47.259183           NaN        NaN  ...   \n",
       "1   -96.476789  -99.090018        -94.660371           NaN        NaN  ...   \n",
       "2    18.892980   23.948225        -86.527528           NaN        NaN  ...   \n",
       "3    31.094531    4.282464        -28.806893           NaN  14.663415  ...   \n",
       "4    30.694891  -66.461608        -58.368696           NaN        NaN  ...   \n",
       "\n",
       "   metac-o1-preview  metac-perplexity  minefrac1       mmBot   pgodzinai  \\\n",
       "0       -205.076095        121.194882        NaN -242.660874 -198.879258   \n",
       "1          7.951703          7.951703        NaN   55.819041   44.625993   \n",
       "2         13.821518         13.821518        NaN    1.307071   17.305437   \n",
       "3          6.442579         16.621639        NaN    8.559053   11.145899   \n",
       "4         35.698675         -0.691552        NaN   39.414502   14.411756   \n",
       "\n",
       "   pianobot  swingswish  twsummerbot  wunderplumb  question_weight  \n",
       "0       NaN         NaN          NaN          NaN              1.0  \n",
       "1       NaN         NaN          NaN          NaN              1.0  \n",
       "2       NaN         NaN          NaN          NaN              1.0  \n",
       "3       NaN         NaN    -9.706540          NaN              1.0  \n",
       "4       NaN         NaN   -70.932651          NaN              1.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bot_question_id</th>\n",
       "      <th>4Shadower</th>\n",
       "      <th>Bot_Pepa</th>\n",
       "      <th>CatrachoCaster</th>\n",
       "      <th>CumulativeBot</th>\n",
       "      <th>GreeneiBot2</th>\n",
       "      <th>Grizeu_Bot</th>\n",
       "      <th>InstitutPelFutur</th>\n",
       "      <th>KevinTestBot</th>\n",
       "      <th>MWG</th>\n",
       "      <th>...</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>metac-perplexity</th>\n",
       "      <th>minefrac1</th>\n",
       "      <th>mmBot</th>\n",
       "      <th>pgodzinai</th>\n",
       "      <th>pianobot</th>\n",
       "      <th>swingswish</th>\n",
       "      <th>twsummerbot</th>\n",
       "      <th>wunderplumb</th>\n",
       "      <th>question_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>35619</td>\n",
       "      <td>6.356385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.356385</td>\n",
       "      <td>8.985116</td>\n",
       "      <td>14.048951</td>\n",
       "      <td>-5.740252</td>\n",
       "      <td>6.356385</td>\n",
       "      <td>-5.740252</td>\n",
       "      <td>10.822423</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.740252</td>\n",
       "      <td>6.356385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.486061</td>\n",
       "      <td>13.624559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.941684</td>\n",
       "      <td>6.356385</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>35620</td>\n",
       "      <td>-3.848478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.026137</td>\n",
       "      <td>-2.646385</td>\n",
       "      <td>3.161815</td>\n",
       "      <td>-3.848478</td>\n",
       "      <td>11.301510</td>\n",
       "      <td>-3.848478</td>\n",
       "      <td>-23.803402</td>\n",
       "      <td>...</td>\n",
       "      <td>2.026137</td>\n",
       "      <td>2.026137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.583046</td>\n",
       "      <td>8.230127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.848478</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>35621</td>\n",
       "      <td>34.934257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.681382</td>\n",
       "      <td>36.351904</td>\n",
       "      <td>-16.055800</td>\n",
       "      <td>-62.135408</td>\n",
       "      <td>-96.717277</td>\n",
       "      <td>34.934257</td>\n",
       "      <td>32.624547</td>\n",
       "      <td>...</td>\n",
       "      <td>9.104719</td>\n",
       "      <td>-48.411348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.059642</td>\n",
       "      <td>31.449931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.934257</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>35622</td>\n",
       "      <td>-58.153367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.351771</td>\n",
       "      <td>-85.428443</td>\n",
       "      <td>-29.096400</td>\n",
       "      <td>42.884269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>78.874603</td>\n",
       "      <td>78.874603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.533049</td>\n",
       "      <td>105.344243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.818274</td>\n",
       "      <td>-97.726020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>35705</td>\n",
       "      <td>-31.742288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.330777</td>\n",
       "      <td>50.023660</td>\n",
       "      <td>26.291942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.620330</td>\n",
       "      <td>22.674004</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.061593</td>\n",
       "      <td>-0.620330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.601475</td>\n",
       "      <td>79.739445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.305945</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bot_question_id  4Shadower  Bot_Pepa  CatrachoCaster  CumulativeBot  \\\n",
       "404            35619   6.356385       NaN        6.356385       8.985116   \n",
       "405            35620  -3.848478       NaN        2.026137      -2.646385   \n",
       "406            35621  34.934257       NaN      -15.681382      36.351904   \n",
       "407            35622 -58.153367       NaN             NaN            NaN   \n",
       "408            35705 -31.742288       NaN             NaN      43.330777   \n",
       "\n",
       "     GreeneiBot2  Grizeu_Bot  InstitutPelFutur  KevinTestBot        MWG  ...  \\\n",
       "404    14.048951   -5.740252          6.356385     -5.740252  10.822423  ...   \n",
       "405     3.161815   -3.848478         11.301510     -3.848478 -23.803402  ...   \n",
       "406   -16.055800  -62.135408        -96.717277     34.934257  32.624547  ...   \n",
       "407   -14.351771  -85.428443        -29.096400     42.884269        NaN  ...   \n",
       "408    50.023660   26.291942               NaN     -0.620330  22.674004  ...   \n",
       "\n",
       "     metac-o1-preview  metac-perplexity  minefrac1       mmBot   pgodzinai  \\\n",
       "404         -5.740252          6.356385        NaN    0.486061   13.624559   \n",
       "405          2.026137          2.026137        NaN    7.583046    8.230127   \n",
       "406          9.104719        -48.411348        NaN   29.059642   31.449931   \n",
       "407         78.874603         78.874603        NaN  114.533049  105.344243   \n",
       "408        -37.061593         -0.620330        NaN   -8.601475   79.739445   \n",
       "\n",
       "     pianobot  swingswish  twsummerbot  wunderplumb  question_weight  \n",
       "404       NaN         NaN     7.941684     6.356385              1.0  \n",
       "405       NaN         NaN          NaN    -3.848478              1.0  \n",
       "406       NaN         NaN          NaN    34.934257              1.0  \n",
       "407       NaN         NaN    -1.818274   -97.726020              1.0  \n",
       "408       NaN         NaN          NaN    10.305945              1.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_bot_peer_wide.shape\n",
    "\n",
    "display_head_and_tail(df_bot_peer_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxVJxrCpuXV_",
    "outputId": "3df39cbc-b594-40e1-d08f-1b0e9736d6ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT LEADERBOARD\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5% CI</th>\n",
       "      <th>10% CI</th>\n",
       "      <th>Median</th>\n",
       "      <th>90% CI</th>\n",
       "      <th>97.5% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>metac-o1</th>\n",
       "      <td>6.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>11.8</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <td>3.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manticAI</th>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-Gemini-Exp-1206</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acm_bot</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-perplexity</th>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreeneiBot2</th>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twsummerbot</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cookics_bot_TEST</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgodzinai</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CumulativeBot</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-claude-3-5-sonnet-latest</th>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SynapseSeer</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jkraybill_bot</th>\n",
       "      <td>-3.9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-exa</th>\n",
       "      <td>-5.3</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-deepseek-r1</th>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MWG</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrewsiah</th>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cobyj-bot</th>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_bot</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pianobot</th>\n",
       "      <td>-1.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annabot</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bean_bot</th>\n",
       "      <td>-3.1</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KevinTestBot</th>\n",
       "      <td>-4.3</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonahsingerbot</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatrachoCaster</th>\n",
       "      <td>-2.3</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krm-bot</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProfessorSP</th>\n",
       "      <td>-4.5</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-grok-2-1212</th>\n",
       "      <td>-6.6</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4Shadower</th>\n",
       "      <td>-4.8</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmBot</th>\n",
       "      <td>-7.8</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swingswish</th>\n",
       "      <td>-5.2</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPM_bot</th>\n",
       "      <td>-4.8</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InstitutPelFutur</th>\n",
       "      <td>-8.8</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-claude-3-5-sonnet-20240620</th>\n",
       "      <td>-6.8</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wunderplumb</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-Llama-3.1</th>\n",
       "      <td>-6.7</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NextWorldLab</th>\n",
       "      <td>-8.9</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laylaps</th>\n",
       "      <td>-10.1</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot_Pepa</th>\n",
       "      <td>-7.2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VeritasAI</th>\n",
       "      <td>-7.7</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minefrac1</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grizeu_Bot</th>\n",
       "      <td>-9.2</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-gpt-4o</th>\n",
       "      <td>-10.6</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajf-bot</th>\n",
       "      <td>-14.6</td>\n",
       "      <td>-12.4</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  2.5% CI  10% CI  Median  90% CI  97.5% CI\n",
       "metac-o1                              6.2     7.4     9.7    11.8      13.1\n",
       "metac-o1-preview                      3.1     5.3     8.3    11.1      12.8\n",
       "manticAI                              0.2     2.1     5.6     8.8      10.6\n",
       "metac-Gemini-Exp-1206                 0.6     1.9     5.2     8.1       9.4\n",
       "acm_bot                               0.1     1.7     4.6     7.5       8.9\n",
       "metac-perplexity                     -1.7     0.4     4.2     8.0       9.6\n",
       "GreeneiBot2                          -1.2     0.7     4.0     7.1       8.9\n",
       "twsummerbot                           0.2     1.4     3.8     6.1       7.3\n",
       "cookics_bot_TEST                      0.1     1.0     3.0     5.1       6.1\n",
       "pgodzinai                            -3.5    -1.4     2.9     6.9       8.7\n",
       "CumulativeBot                        -0.3     0.9     2.7     4.4       5.4\n",
       "metac-claude-3-5-sonnet-latest       -1.1     0.1     2.6     5.1       6.4\n",
       "SynapseSeer                           0.4     1.1     2.6     4.0       4.9\n",
       "jkraybill_bot                        -3.9    -1.8     1.7     4.9       6.3\n",
       "metac-exa                            -5.3    -2.8     1.6     5.4       7.8\n",
       "metac-deepseek-r1                    -1.7    -0.8     1.3     3.5       4.6\n",
       "MWG                                  -1.5    -0.7     0.7     2.2       2.8\n",
       "andrewsiah                           -0.9    -0.6    -0.0     0.6       1.0\n",
       "cobyj-bot                            -1.4    -0.9    -0.0     0.8       1.3\n",
       "X_bot                                -0.4    -0.3    -0.0     0.1       0.2\n",
       "pianobot                             -1.3    -0.8    -0.0     0.7       1.1\n",
       "annabot                              -3.5    -2.3    -0.4     1.3       2.2\n",
       "bean_bot                             -3.1    -2.2    -0.5     1.1       1.7\n",
       "KevinTestBot                         -4.3    -2.8    -0.6     1.4       2.6\n",
       "jonahsingerbot                       -3.0    -2.2    -0.8     0.4       1.0\n",
       "CatrachoCaster                       -2.3    -1.7    -0.8     0.2       0.8\n",
       "krm-bot                              -3.5    -2.6    -0.9     0.7       1.6\n",
       "ProfessorSP                          -4.5    -3.4    -1.2     1.0       2.2\n",
       "metac-grok-2-1212                    -6.6    -4.9    -1.6     1.7       3.5\n",
       "4Shadower                            -4.8    -3.6    -1.7     0.3       1.2\n",
       "mmBot                                -7.8    -5.7    -1.7     2.1       4.2\n",
       "swingswish                           -5.2    -4.0    -1.9    -0.2       0.6\n",
       "RPM_bot                              -4.8    -3.8    -2.0    -0.7      -0.1\n",
       "InstitutPelFutur                     -8.8    -6.6    -2.1     2.0       4.0\n",
       "metac-claude-3-5-sonnet-20240620     -6.8    -5.0    -2.1     0.9       2.2\n",
       "wunderplumb                          -6.0    -4.7    -2.5    -0.3       0.7\n",
       "metac-Llama-3.1                      -6.7    -5.4    -2.7     0.0       1.5\n",
       "NextWorldLab                         -8.9    -6.9    -3.6    -0.5       0.9\n",
       "laylaps                             -10.1    -8.1    -3.8    -0.1       1.6\n",
       "Bot_Pepa                             -7.2    -6.0    -3.9    -2.0      -0.9\n",
       "VeritasAI                            -7.7    -6.4    -4.3    -2.0      -0.8\n",
       "minefrac1                            -8.0    -6.7    -4.6    -2.6      -1.5\n",
       "Grizeu_Bot                           -9.2    -7.6    -5.0    -2.3      -0.6\n",
       "metac-gpt-4o                        -10.6    -9.1    -5.7    -2.9      -1.4\n",
       "ajf-bot                             -14.6   -12.4    -8.3    -4.4      -2.0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'bot_median' from all_bots list\n",
    "all_bots_wo_median = np.delete(all_bots, np.where(all_bots == 'bot_median')[0][0])\n",
    "df_bot_peer_wide_wo_median = df_bot_peer_wide.drop('bot_median', axis=1)\n",
    "\n",
    "NUM = round(df_bot_peer_wide['question_weight'].sum())\n",
    "ITER = 1000\n",
    "\n",
    "result_df = weighted_bootstrap_analysis(df_bot_peer_wide_wo_median, all_bots_wo_median, NUM, ITER)\n",
    "average_df = result_df / NUM\n",
    "\n",
    "print(f'BOT LEADERBOARD\\n\\n')\n",
    "df_rounded = average_df.round(1)\n",
    "df_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "MXAev2sNXdbZ",
    "outputId": "eebb723f-5494-4b89-cf0d-efa5b1626cb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "HEAD-TO-HEAD LEADERBOARD\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5% CI</th>\n",
       "      <th>10% CI</th>\n",
       "      <th>Median</th>\n",
       "      <th>90% CI</th>\n",
       "      <th>97.5% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cobyj-bot</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrewsiah</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_bot</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonahsingerbot</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bean_bot</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPM_bot</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CumulativeBot</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swingswish</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KevinTestBot</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SynapseSeer</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grizeu_Bot</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pianobot</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatrachoCaster</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krm-bot</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4Shadower</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annabot</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cookics_bot_TEST</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jkraybill_bot</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twsummerbot</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MWG</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProfessorSP</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreeneiBot2</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajf-bot</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acm_bot</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot_Pepa</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-o1</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-perplexity</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laylaps</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wunderplumb</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manticAI</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-deepseek-r1</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-Gemini-Exp-1206</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NextWorldLab</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bot_median</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minefrac1</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-claude-3-5-sonnet-20240620</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmBot</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-grok-2-1212</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgodzinai</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VeritasAI</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-claude-3-5-sonnet-latest</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-Llama-3.1</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-exa</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InstitutPelFutur</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-gpt-4o</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  2.5% CI  10% CI  Median  90% CI  97.5% CI\n",
       "cobyj-bot                             0.0     0.0     0.0     0.0       0.0\n",
       "andrewsiah                            0.0     0.0     0.0     0.0       0.0\n",
       "X_bot                                -0.0    -0.0    -0.0     0.0       0.0\n",
       "jonahsingerbot                       -0.0    -0.0    -0.0    -0.0      -0.0\n",
       "bean_bot                             -0.0    -0.0    -0.0    -0.0      -0.0\n",
       "RPM_bot                              -0.1    -0.0    -0.0     0.0       0.0\n",
       "CumulativeBot                        -0.0    -0.0    -0.0    -0.0       0.0\n",
       "swingswish                           -0.0    -0.0    -0.0    -0.0      -0.0\n",
       "KevinTestBot                         -0.1    -0.0    -0.0     0.0       0.0\n",
       "SynapseSeer                          -0.1    -0.0    -0.0     0.0       0.0\n",
       "Grizeu_Bot                           -0.2    -0.1    -0.0     0.1       0.2\n",
       "pianobot                             -0.1    -0.1    -0.0    -0.0       0.0\n",
       "CatrachoCaster                       -0.1    -0.1    -0.0    -0.0       0.0\n",
       "krm-bot                              -0.1    -0.1    -0.1    -0.0      -0.0\n",
       "4Shadower                            -0.1    -0.1    -0.1    -0.0      -0.0\n",
       "annabot                              -0.1    -0.1    -0.1    -0.0      -0.0\n",
       "cookics_bot_TEST                     -0.2    -0.1    -0.1    -0.0       0.0\n",
       "jkraybill_bot                        -0.2    -0.1    -0.1    -0.0      -0.0\n",
       "twsummerbot                          -0.2    -0.2    -0.1    -0.0       0.0\n",
       "MWG                                  -0.2    -0.2    -0.1    -0.0      -0.0\n",
       "ProfessorSP                          -0.2    -0.2    -0.1    -0.1      -0.0\n",
       "GreeneiBot2                          -0.2    -0.2    -0.1    -0.0       0.0\n",
       "ajf-bot                              -0.3    -0.2    -0.1    -0.0       0.0\n",
       "acm_bot                              -0.3    -0.2    -0.1     0.0       0.1\n",
       "Bot_Pepa                             -0.2    -0.2    -0.1    -0.1      -0.0\n",
       "metac-o1                             -0.3    -0.2    -0.1    -0.0       0.1\n",
       "metac-perplexity                     -0.3    -0.2    -0.1     0.0       0.1\n",
       "laylaps                              -0.2    -0.2    -0.1    -0.1      -0.0\n",
       "wunderplumb                          -0.3    -0.2    -0.1    -0.1      -0.0\n",
       "manticAI                             -0.3    -0.2    -0.2    -0.1      -0.0\n",
       "metac-deepseek-r1                    -0.3    -0.2    -0.2    -0.1      -0.0\n",
       "metac-Gemini-Exp-1206                -0.3    -0.3    -0.2    -0.0       0.0\n",
       "NextWorldLab                         -0.3    -0.3    -0.2    -0.1      -0.0\n",
       "bot_median                           -0.4    -0.3    -0.2    -0.1       0.0\n",
       "minefrac1                            -0.3    -0.3    -0.2    -0.1      -0.1\n",
       "metac-claude-3-5-sonnet-20240620     -0.4    -0.3    -0.2    -0.1       0.0\n",
       "mmBot                                -0.4    -0.3    -0.2    -0.1      -0.1\n",
       "metac-grok-2-1212                    -0.4    -0.4    -0.2    -0.1      -0.0\n",
       "pgodzinai                            -0.4    -0.4    -0.2    -0.1      -0.1\n",
       "VeritasAI                            -0.4    -0.3    -0.3    -0.2      -0.1\n",
       "metac-claude-3-5-sonnet-latest       -0.4    -0.4    -0.3    -0.2      -0.1\n",
       "metac-Llama-3.1                      -0.5    -0.4    -0.3    -0.1      -0.1\n",
       "metac-exa                            -0.5    -0.4    -0.3    -0.2      -0.1\n",
       "InstitutPelFutur                     -0.5    -0.4    -0.3    -0.2      -0.1\n",
       "metac-o1-preview                     -0.5    -0.4    -0.3    -0.2      -0.1\n",
       "metac-gpt-4o                         -0.5    -0.4    -0.3    -0.2      -0.1"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM = round(df_bot_vs_pro_peer['question_weight'].sum())\n",
    "ITER = 1000\n",
    "\n",
    "result_df = weighted_bootstrap_analysis(df_bot_vs_pro_peer, all_bots, NUM, ITER)\n",
    "average_df = result_df / NUM\n",
    "\n",
    "print(f'\\n\\n\\nHEAD-TO-HEAD LEADERBOARD\\n\\n')\n",
    "#df_rounded = result_df.round(0).astype(int)\n",
    "df_rounded = average_df.round(1)\n",
    "\n",
    "df_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write df_rounded (bootstrapping h2h) to csv\n",
    "df_rounded.to_csv('notebook_outputs/bootstrapped_h2h_bot_vs_pros.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted score for annabot: -190.5513637093994\n",
      "Total score for annabot: 21.125669919166132\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Check specific bot records\n",
    "\n",
    "bot_name = 'annabot'\n",
    "\n",
    "df_bot = df_bot_peer_wide[['bot_question_id', 'question_weight', bot_name]]\n",
    "df_bot = df_bot.dropna()\n",
    "df_bot = df_bot.reset_index(drop=True)\n",
    "\n",
    "df_bot['weighted_score'] = df_bot[bot_name] * df_bot['question_weight']\n",
    "\n",
    "weighted_score = df_bot['weighted_score'].sum()\n",
    "\n",
    "print(f\"Weighted score for {bot_name}: {weighted_score}\")\n",
    "\n",
    "total_score = df_bot[bot_name].sum()\n",
    "\n",
    "print(f\"Total score for {bot_name}: {total_score}\\n\")\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size (optional)\n",
    "plt.hist(df_bot[bot_name], bins=10, edgecolor='black')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(f'Histogram of Scores for {bot_name}')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Add grid lines (optional)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7W8JXutv2ks",
    "outputId": "5e7053d3-2124-42b7-bd53-48a40a53caf2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_ave</th>\n",
       "      <th>W_count</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <td>12.2</td>\n",
       "      <td>276.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-o1</th>\n",
       "      <td>8.4</td>\n",
       "      <td>283.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgodzinai</th>\n",
       "      <td>8.7</td>\n",
       "      <td>248.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.025267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GreeneiBot2</th>\n",
       "      <td>9.2</td>\n",
       "      <td>204.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.026930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manticAI</th>\n",
       "      <td>7.7</td>\n",
       "      <td>245.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.035671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acm_bot</th>\n",
       "      <td>5.4</td>\n",
       "      <td>263.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.058135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-Gemini-Exp-1206</th>\n",
       "      <td>5.3</td>\n",
       "      <td>269.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.062806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SynapseSeer</th>\n",
       "      <td>6.0</td>\n",
       "      <td>125.9</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.068737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-claude-3-5-sonnet-latest</th>\n",
       "      <td>3.6</td>\n",
       "      <td>278.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.116899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twsummerbot</th>\n",
       "      <td>4.9</td>\n",
       "      <td>181.9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.152393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cookics_bot_TEST</th>\n",
       "      <td>5.8</td>\n",
       "      <td>135.2</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.132509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CumulativeBot</th>\n",
       "      <td>8.0</td>\n",
       "      <td>94.2</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0.153662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-deepseek-r1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>225.8</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.763142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MWG</th>\n",
       "      <td>3.6</td>\n",
       "      <td>84.8</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.365354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-perplexity</th>\n",
       "      <td>2.8</td>\n",
       "      <td>264.3</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.470416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-grok-2-1212</th>\n",
       "      <td>0.1</td>\n",
       "      <td>281.2</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.961620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-exa</th>\n",
       "      <td>1.7</td>\n",
       "      <td>275.2</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.654608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmBot</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>279.9</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.887163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InstitutPelFutur</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>264.9</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.988352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-Llama-3.1</th>\n",
       "      <td>-3.7</td>\n",
       "      <td>280.5</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.117806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-claude-3-5-sonnet-20240620</th>\n",
       "      <td>-3.3</td>\n",
       "      <td>282.2</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.224671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VeritasAI</th>\n",
       "      <td>-4.5</td>\n",
       "      <td>251.9</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.072948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jkraybill_bot</th>\n",
       "      <td>1.4</td>\n",
       "      <td>162.4</td>\n",
       "      <td>-9.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.808839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatrachoCaster</th>\n",
       "      <td>-2.7</td>\n",
       "      <td>61.9</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.493061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metac-gpt-4o</th>\n",
       "      <td>-5.2</td>\n",
       "      <td>281.2</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.054453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NextWorldLab</th>\n",
       "      <td>-4.6</td>\n",
       "      <td>256.3</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.156859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wunderplumb</th>\n",
       "      <td>-5.4</td>\n",
       "      <td>148.4</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.184061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4Shadower</th>\n",
       "      <td>-3.7</td>\n",
       "      <td>101.5</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.463979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minefrac1</th>\n",
       "      <td>-7.3</td>\n",
       "      <td>136.2</td>\n",
       "      <td>-14.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.043444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrewsiah</th>\n",
       "      <td>0.1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>-14.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.988409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krm-bot</th>\n",
       "      <td>-4.4</td>\n",
       "      <td>94.5</td>\n",
       "      <td>-14.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.399741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProfessorSP</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-14.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.464316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laylaps</th>\n",
       "      <td>-7.2</td>\n",
       "      <td>257.0</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.082564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pianobot</th>\n",
       "      <td>6.8</td>\n",
       "      <td>14.8</td>\n",
       "      <td>-16.2</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0.535822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cobyj-bot</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>31.5</td>\n",
       "      <td>-17.8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.964365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KevinTestBot</th>\n",
       "      <td>-2.7</td>\n",
       "      <td>81.1</td>\n",
       "      <td>-17.9</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.730388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonahsingerbot</th>\n",
       "      <td>-6.5</td>\n",
       "      <td>60.1</td>\n",
       "      <td>-19.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.309592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bean_bot</th>\n",
       "      <td>-4.1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>-19.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.600896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot_Pepa</th>\n",
       "      <td>-12.3</td>\n",
       "      <td>124.4</td>\n",
       "      <td>-20.6</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>0.003751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annabot</th>\n",
       "      <td>-6.3</td>\n",
       "      <td>54.5</td>\n",
       "      <td>-23.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.470037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grizeu_Bot</th>\n",
       "      <td>-16.5</td>\n",
       "      <td>140.9</td>\n",
       "      <td>-25.8</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajf-bot</th>\n",
       "      <td>-16.0</td>\n",
       "      <td>193.9</td>\n",
       "      <td>-28.2</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>0.011119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swingswish</th>\n",
       "      <td>-16.7</td>\n",
       "      <td>57.1</td>\n",
       "      <td>-36.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.103364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPM_bot</th>\n",
       "      <td>-44.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>-101.4</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.126191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  W_ave  W_count  lower_bound  upper_bound  \\\n",
       "metac-o1-preview                   12.2    276.6          7.1         17.3   \n",
       "metac-o1                            8.4    283.2          4.0         12.7   \n",
       "pgodzinai                           8.7    248.0          1.1         16.3   \n",
       "GreeneiBot2                         9.2    204.8          1.1         17.3   \n",
       "manticAI                            7.7    245.2          0.5         14.9   \n",
       "acm_bot                             5.4    263.5         -0.2         11.0   \n",
       "metac-Gemini-Exp-1206               5.3    269.6         -0.3         10.8   \n",
       "SynapseSeer                         6.0    125.9         -0.5         12.5   \n",
       "metac-claude-3-5-sonnet-latest      3.6    278.2         -0.9          8.2   \n",
       "twsummerbot                         4.9    181.9         -1.8         11.6   \n",
       "cookics_bot_TEST                    5.8    135.2         -1.8         13.4   \n",
       "CumulativeBot                       8.0     94.2         -3.0         18.9   \n",
       "metac-deepseek-r1                   0.8    225.8         -4.2          5.8   \n",
       "MWG                                 3.6     84.8         -4.3         11.5   \n",
       "metac-perplexity                    2.8    264.3         -4.8         10.3   \n",
       "metac-grok-2-1212                   0.1    281.2         -5.7          6.0   \n",
       "metac-exa                           1.7    275.2         -5.8          9.2   \n",
       "mmBot                              -0.5    279.9         -7.5          6.5   \n",
       "InstitutPelFutur                   -0.1    264.9         -8.1          8.0   \n",
       "metac-Llama-3.1                    -3.7    280.5         -8.3          0.9   \n",
       "metac-claude-3-5-sonnet-20240620   -3.3    282.2         -8.5          2.0   \n",
       "VeritasAI                          -4.5    251.9         -9.4          0.4   \n",
       "jkraybill_bot                       1.4    162.4         -9.7         12.4   \n",
       "CatrachoCaster                     -2.7     61.9        -10.6          5.2   \n",
       "metac-gpt-4o                       -5.2    281.2        -10.6          0.1   \n",
       "NextWorldLab                       -4.6    256.3        -10.9          1.8   \n",
       "wunderplumb                        -5.4    148.4        -13.5          2.6   \n",
       "4Shadower                          -3.7    101.5        -13.9          6.4   \n",
       "minefrac1                          -7.3    136.2        -14.4         -0.2   \n",
       "andrewsiah                          0.1     25.1        -14.6         14.8   \n",
       "krm-bot                            -4.4     94.5        -14.7          5.9   \n",
       "ProfessorSP                        -4.0    110.0        -14.8          6.8   \n",
       "laylaps                            -7.2    257.0        -15.4          0.9   \n",
       "pianobot                            6.8     14.8        -16.2         29.8   \n",
       "cobyj-bot                          -0.4     31.5        -17.8         17.1   \n",
       "KevinTestBot                       -2.7     81.1        -17.9         12.6   \n",
       "jonahsingerbot                     -6.5     60.1        -19.2          6.2   \n",
       "bean_bot                           -4.1     63.1        -19.6         11.4   \n",
       "Bot_Pepa                          -12.3    124.4        -20.6         -4.1   \n",
       "annabot                            -6.3     54.5        -23.7         11.1   \n",
       "Grizeu_Bot                        -16.5    140.9        -25.8         -7.1   \n",
       "ajf-bot                           -16.0    193.9        -28.2         -3.7   \n",
       "swingswish                        -16.7     57.1        -36.9          3.5   \n",
       "RPM_bot                           -44.0     15.8       -101.4         13.4   \n",
       "\n",
       "                                   p_value  \n",
       "metac-o1-preview                  0.000004  \n",
       "metac-o1                          0.000179  \n",
       "pgodzinai                         0.025267  \n",
       "GreeneiBot2                       0.026930  \n",
       "manticAI                          0.035671  \n",
       "acm_bot                           0.058135  \n",
       "metac-Gemini-Exp-1206             0.062806  \n",
       "SynapseSeer                       0.068737  \n",
       "metac-claude-3-5-sonnet-latest    0.116899  \n",
       "twsummerbot                       0.152393  \n",
       "cookics_bot_TEST                  0.132509  \n",
       "CumulativeBot                     0.153662  \n",
       "metac-deepseek-r1                 0.763142  \n",
       "MWG                               0.365354  \n",
       "metac-perplexity                  0.470416  \n",
       "metac-grok-2-1212                 0.961620  \n",
       "metac-exa                         0.654608  \n",
       "mmBot                             0.887163  \n",
       "InstitutPelFutur                  0.988352  \n",
       "metac-Llama-3.1                   0.117806  \n",
       "metac-claude-3-5-sonnet-20240620  0.224671  \n",
       "VeritasAI                         0.072948  \n",
       "jkraybill_bot                     0.808839  \n",
       "CatrachoCaster                    0.493061  \n",
       "metac-gpt-4o                      0.054453  \n",
       "NextWorldLab                      0.156859  \n",
       "wunderplumb                       0.184061  \n",
       "4Shadower                         0.463979  \n",
       "minefrac1                         0.043444  \n",
       "andrewsiah                        0.988409  \n",
       "krm-bot                           0.399741  \n",
       "ProfessorSP                       0.464316  \n",
       "laylaps                           0.082564  \n",
       "pianobot                          0.535822  \n",
       "cobyj-bot                         0.964365  \n",
       "KevinTestBot                      0.730388  \n",
       "jonahsingerbot                    0.309592  \n",
       "bean_bot                          0.600896  \n",
       "Bot_Pepa                          0.003751  \n",
       "annabot                           0.470037  \n",
       "Grizeu_Bot                        0.000639  \n",
       "ajf-bot                           0.011119  \n",
       "swingswish                        0.103364  \n",
       "RPM_bot                           0.126191  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Weighted Bot Only Peer, T test\n",
    "\n",
    "# To choose our top bot team, we only use the questions for which there is no Pro benchmark. (in Q4, there were some bots who ONLY forecasted on questions with Pro benchmark)\n",
    "no_pro_benchmark = df_pro_bot_resolved_questions[df_pro_bot_resolved_questions['pro_question_id'].isna()]['bot_question_id']\n",
    "\n",
    "df_bot_only_peer = df_bot_peer[df_bot_peer['bot_question_id'].isin(no_pro_benchmark)]\n",
    "df_bot_only_peer_wide = make_wide(df_bot_only_peer, df_pro_bot_resolved_questions)\n",
    "\n",
    "df_W_bot_only_peer_leaderboard = calculate_t_test(df_bot_only_peer_wide, df_bot_only_peer['forecaster'].unique())\n",
    "\n",
    "df_W_bot_only_peer_leaderboard[['W_ave', 'W_count', 'lower_bound', 'upper_bound', 'p_value']].sort_values(by='lower_bound', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_W_bot_only_peer_leaderboard.to_csv('notebook_outputs/weighted_bot_ONLY_peer_leaderboard_t_test.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 bots:\n",
      "1. metac-o1-preview\n",
      "2. metac-o1\n",
      "3. pgodzinai\n",
      "4. GreeneiBot2\n",
      "5. manticAI\n",
      "6. acm_bot\n",
      "7. metac-Gemini-Exp-1206\n",
      "8. SynapseSeer\n",
      "9. metac-claude-3-5-sonnet-latest\n",
      "10. twsummerbot\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by the lower_bound column in descending order\n",
    "sorted_df = df_W_bot_only_peer_leaderboard.sort_values(by='lower_bound', ascending=False)\n",
    "\n",
    "# exclude bot median for purposes of bot teaming\n",
    "sorted_df = sorted_df.drop('bot_median', errors='ignore')\n",
    "\n",
    "# Get the top 10 bot names\n",
    "top_10_bots = sorted_df.index[:10].tolist()\n",
    "\n",
    "# Print the list of top 10 bots\n",
    "print(\"Top 10 bots:\")\n",
    "for i, bot in enumerate(top_10_bots, 1):\n",
    "    print(f\"{i}. {bot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "cellView": "form",
    "id": "x6e1kZl12qFZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >>> Collected 1 forecasts: [0.1]\n",
      "   >>> Collected 1 forecasts: [0.35]\n",
      "   >>> Collected 1 forecasts: [0.9]\n",
      "   >>> Collected 1 forecasts: [0.75]\n",
      "   >>> Collected 1 forecasts: [0.05]\n",
      "   >>> Collected 1 forecasts: [0.7]\n",
      "   >>> Collected 1 forecasts: [0.85]\n",
      "   >>> Collected 1 forecasts: [0.05]\n",
      "   >>> Collected 1 forecasts: [0.15]\n",
      "   >>> Collected 1 forecasts: [0.2]\n",
      "   >>> Collected 1 forecasts: [0.2]\n",
      "   >>> Collected 1 forecasts: [0.7]\n",
      "   >>> Collected 1 forecasts: [0.15]\n",
      "   >>> Collected 1 forecasts: [0.25]\n",
      "   >>> Collected 1 forecasts: [0.05]\n",
      "   >>> Collected 1 forecasts: [0.15]\n",
      "   >>> Collected 1 forecasts: [0.95]\n",
      "   >>> Collected 1 forecasts: [0.1]\n",
      "   >>> Collected 1 forecasts: [0.05]\n",
      "   >>> Collected 1 forecasts: [0.05]\n",
      "   >>> Collected 1 forecasts: [0.15]\n",
      "   >>> Collected 1 forecasts: [0.6]\n",
      "   >>> Collected 1 forecasts: [0.2]\n",
      "   >>> Collected 1 forecasts: [0.97]\n",
      "   >>> Collected 1 forecasts: [0.4]\n",
      "   >>> Collected 1 forecasts: [0.4]\n",
      "   >>> Collected 1 forecasts: [0.35]\n",
      "   >>> Collected 1 forecasts: [0.1]\n",
      "   >>> Collected 1 forecasts: [0.6]\n",
      "   >>> Collected 1 forecasts: [0.99]\n",
      "   >>> Collected 1 forecasts: [0.97]\n",
      "   >>> Collected 1 forecasts: [0.99]\n",
      "   >>> Collected 1 forecasts: [0.9]\n",
      "   >>> Collected 1 forecasts: [0.9]\n",
      "   >>> Collected 1 forecasts: [0.7]\n",
      "   >>> Collected 1 forecasts: [0.9]\n",
      "   >>> Collected 1 forecasts: [0.05]\n",
      "   >>> Collected 1 forecasts: [0.2]\n",
      "   >>> Collected 1 forecasts: [0.6]\n",
      "   >>> Collected 1 forecasts: [0.2]\n",
      "   >>> Collected 1 forecasts: [0.25]\n",
      "   >>> Collected 1 forecasts: [0.05]\n",
      "   >>> Collected 1 forecasts: [0.2]\n",
      "   >>> Collected 1 forecasts: [0.15]\n",
      "   >>> Collected 1 forecasts: [0.85]\n",
      "   >>> Collected 1 forecasts: [0.9]\n",
      "   >>> Collected 1 forecasts: [0.9]\n",
      "   >>> Collected 1 forecasts: [0.9]\n",
      "   >>> Collected 1 forecasts: [0.85]\n",
      "   >>> Collected 1 forecasts: [0.05]\n",
      "   >>> Collected 2 forecasts: [0.1, 0.1]\n",
      "   >>> Collected 2 forecasts: [0.35, 0.6]\n",
      "   >>> Collected 2 forecasts: [0.9, 0.85]\n",
      "   >>> Collected 2 forecasts: [0.75, 0.85]\n",
      "   >>> Collected 2 forecasts: [0.05, 0.05]\n",
      "   >>> Collected 2 forecasts: [0.7, 0.4]\n",
      "   >>> Collected 2 forecasts: [0.85, 0.6]\n",
      "   >>> Collected 2 forecasts: [0.05, 0.05]\n",
      "   >>> Collected 2 forecasts: [0.15, 0.05]\n",
      "   >>> Collected 2 forecasts: [0.2, 0.2]\n",
      "   >>> Collected 2 forecasts: [0.2, 0.1]\n",
      "   >>> Collected 2 forecasts: [0.7, 0.85]\n",
      "   >>> Collected 2 forecasts: [0.15, 0.35]\n",
      "   >>> Collected 2 forecasts: [0.25, 0.25]\n",
      "   >>> Collected 2 forecasts: [0.05, 0.1]\n",
      "   >>> Collected 2 forecasts: [0.15, 0.4]\n",
      "   >>> Collected 2 forecasts: [0.95, 0.9]\n",
      "   >>> Collected 2 forecasts: [0.1, 0.2]\n",
      "   >>> Collected 2 forecasts: [0.05, 0.05]\n",
      "   >>> Collected 2 forecasts: [0.05, 0.02]\n",
      "   >>> Collected 2 forecasts: [0.15, 0.4]\n",
      "   >>> Collected 2 forecasts: [0.6, 0.3]\n",
      "   >>> Collected 2 forecasts: [0.2, 0.2]\n",
      "   >>> Collected 2 forecasts: [0.97, 0.98]\n",
      "   >>> Collected 2 forecasts: [0.4, 0.3]\n",
      "   >>> Collected 2 forecasts: [0.4, 0.4]\n",
      "   >>> Collected 2 forecasts: [0.35, 0.45]\n",
      "   >>> Collected 2 forecasts: [0.1, 0.02]\n",
      "   >>> Collected 2 forecasts: [0.6, 0.8]\n",
      "   >>> Collected 2 forecasts: [0.99, 0.9]\n",
      "   >>> Collected 2 forecasts: [0.97, 0.98]\n",
      "   >>> Collected 2 forecasts: [0.99, 0.25]\n",
      "   >>> Collected 2 forecasts: [0.9, 0.85]\n",
      "   >>> Collected 2 forecasts: [0.9, 0.8]\n",
      "   >>> Collected 2 forecasts: [0.7, 0.6]\n",
      "   >>> Collected 2 forecasts: [0.9, 0.85]\n",
      "   >>> Collected 2 forecasts: [0.05, 0.1]\n",
      "   >>> Collected 2 forecasts: [0.2, 0.2]\n",
      "   >>> Collected 2 forecasts: [0.6, 0.8]\n",
      "   >>> Collected 2 forecasts: [0.2, 0.15]\n",
      "   >>> Collected 2 forecasts: [0.25, 0.25]\n",
      "   >>> Collected 2 forecasts: [0.05, 0.1]\n",
      "   >>> Collected 2 forecasts: [0.2, 0.15]\n",
      "   >>> Collected 2 forecasts: [0.15, 0.05]\n",
      "   >>> Collected 2 forecasts: [0.85, 0.9]\n",
      "   >>> Collected 2 forecasts: [0.9, 0.9]\n",
      "   >>> Collected 2 forecasts: [0.9, 0.65]\n",
      "   >>> Collected 2 forecasts: [0.9, 0.85]\n",
      "   >>> Collected 2 forecasts: [0.85, 0.8]\n",
      "   >>> Collected 2 forecasts: [0.05, 0.02]\n",
      "   >>> Collected 3 forecasts: [0.1, 0.1, 0.07]\n",
      "   >>> Collected 3 forecasts: [0.35, 0.6, 0.62]\n",
      "   >>> Collected 3 forecasts: [0.9, 0.85, 0.82]\n",
      "   >>> Collected 3 forecasts: [0.75, 0.85, 0.85]\n",
      "   >>> Collected 3 forecasts: [0.05, 0.05, nan]\n",
      "   >>> Collected 3 forecasts: [0.7, 0.4, nan]\n",
      "   >>> Collected 3 forecasts: [0.85, 0.6, nan]\n",
      "   >>> Collected 3 forecasts: [0.05, 0.05, nan]\n",
      "   >>> Collected 3 forecasts: [0.15, 0.05, nan]\n",
      "   >>> Collected 3 forecasts: [0.2, 0.2, 0.25]\n",
      "   >>> Collected 3 forecasts: [0.2, 0.1, nan]\n",
      "   >>> Collected 3 forecasts: [0.7, 0.85, nan]\n",
      "   >>> Collected 3 forecasts: [0.15, 0.35, 0.108]\n",
      "   >>> Collected 3 forecasts: [0.25, 0.25, 0.16]\n",
      "   >>> Collected 3 forecasts: [0.05, 0.1, 0.95]\n",
      "   >>> Collected 3 forecasts: [0.15, 0.4, 0.15]\n",
      "   >>> Collected 3 forecasts: [0.95, 0.9, 0.05]\n",
      "   >>> Collected 3 forecasts: [0.1, 0.2, 0.125]\n",
      "   >>> Collected 3 forecasts: [0.05, 0.05, 0.034]\n",
      "   >>> Collected 3 forecasts: [0.05, 0.02, 0.03]\n",
      "   >>> Collected 3 forecasts: [0.15, 0.4, 0.35]\n",
      "   >>> Collected 3 forecasts: [0.6, 0.3, 0.35]\n",
      "   >>> Collected 3 forecasts: [0.2, 0.2, 0.115]\n",
      "   >>> Collected 3 forecasts: [0.97, 0.98, 0.97]\n",
      "   >>> Collected 3 forecasts: [0.4, 0.3, 0.285]\n",
      "   >>> Collected 3 forecasts: [0.4, 0.4, 0.3833333333333333]\n",
      "   >>> Collected 3 forecasts: [0.35, 0.45, 0.17]\n",
      "   >>> Collected 3 forecasts: [0.1, 0.02, 0.12]\n",
      "   >>> Collected 3 forecasts: [0.6, 0.8, 0.875]\n",
      "   >>> Collected 3 forecasts: [0.99, 0.9, 0.99]\n",
      "   >>> Collected 3 forecasts: [0.97, 0.98, 0.9233333333333332]\n",
      "   >>> Collected 3 forecasts: [0.99, 0.25, 0.14]\n",
      "   >>> Collected 3 forecasts: [0.9, 0.85, 0.8340000000000001]\n",
      "   >>> Collected 3 forecasts: [0.9, 0.8, 0.7666666666666667]\n",
      "   >>> Collected 3 forecasts: [0.7, 0.6, 0.875]\n",
      "   >>> Collected 3 forecasts: [0.9, 0.85, 0.84]\n",
      "   >>> Collected 3 forecasts: [0.05, 0.1, 0.026]\n",
      "   >>> Collected 3 forecasts: [0.2, 0.2, 0.16]\n",
      "   >>> Collected 3 forecasts: [0.6, 0.8, 0.67]\n",
      "   >>> Collected 3 forecasts: [0.2, 0.15, nan]\n",
      "   >>> Collected 3 forecasts: [0.25, 0.25, 0.3925]\n",
      "   >>> Collected 3 forecasts: [0.05, 0.1, 0.086]\n",
      "   >>> Collected 3 forecasts: [0.2, 0.15, 0.285]\n",
      "   >>> Collected 3 forecasts: [0.15, 0.05, 0.02]\n",
      "   >>> Collected 3 forecasts: [0.85, 0.9, nan]\n",
      "   >>> Collected 3 forecasts: [0.9, 0.9, 0.95]\n",
      "   >>> Collected 3 forecasts: [0.9, 0.65, nan]\n",
      "   >>> Collected 3 forecasts: [0.9, 0.85, nan]\n",
      "   >>> Collected 3 forecasts: [0.85, 0.8, 0.85]\n",
      "   >>> Collected 3 forecasts: [0.05, 0.02, 0.05]\n",
      "   >>> Collected 4 forecasts: [0.1, 0.1, 0.07, 0.0559999999999999]\n",
      "   >>> Collected 4 forecasts: [0.35, 0.6, 0.62, 0.7]\n",
      "   >>> Collected 4 forecasts: [0.9, 0.85, 0.82, 0.794]\n",
      "   >>> Collected 4 forecasts: [0.75, 0.85, 0.85, 0.884]\n",
      "   >>> Collected 4 forecasts: [0.05, 0.05, nan, nan]\n",
      "   >>> Collected 4 forecasts: [0.7, 0.4, nan, nan]\n",
      "   >>> Collected 4 forecasts: [0.85, 0.6, nan, nan]\n",
      "   >>> Collected 4 forecasts: [0.05, 0.05, nan, nan]\n",
      "   >>> Collected 4 forecasts: [0.15, 0.05, nan, nan]\n",
      "   >>> Collected 4 forecasts: [0.2, 0.2, 0.25, nan]\n",
      "   >>> Collected 4 forecasts: [0.2, 0.1, nan, 0.242]\n",
      "   >>> Collected 4 forecasts: [0.7, 0.85, nan, 0.936]\n",
      "   >>> Collected 4 forecasts: [0.15, 0.35, 0.108, 0.264]\n",
      "   >>> Collected 4 forecasts: [0.25, 0.25, 0.16, 0.652]\n",
      "   >>> Collected 4 forecasts: [0.05, 0.1, 0.95, 0.052]\n",
      "   >>> Collected 4 forecasts: [0.15, 0.4, 0.15, 0.12]\n",
      "   >>> Collected 4 forecasts: [0.95, 0.9, 0.05, 0.866]\n",
      "   >>> Collected 4 forecasts: [0.1, 0.2, 0.125, 0.212]\n",
      "   >>> Collected 4 forecasts: [0.05, 0.05, 0.034, nan]\n",
      "   >>> Collected 4 forecasts: [0.05, 0.02, 0.03, 0.072]\n",
      "   >>> Collected 4 forecasts: [0.15, 0.4, 0.35, 0.3339999999999999]\n",
      "   >>> Collected 4 forecasts: [0.6, 0.3, 0.35, 0.5]\n",
      "   >>> Collected 4 forecasts: [0.2, 0.2, 0.115, 0.102]\n",
      "   >>> Collected 4 forecasts: [0.97, 0.98, 0.97, 0.932]\n",
      "   >>> Collected 4 forecasts: [0.4, 0.3, 0.285, 0.34]\n",
      "   >>> Collected 4 forecasts: [0.4, 0.4, 0.3833333333333333, 0.42]\n",
      "   >>> Collected 4 forecasts: [0.35, 0.45, 0.17, 0.236]\n",
      "   >>> Collected 4 forecasts: [0.1, 0.02, 0.12, 0.29]\n",
      "   >>> Collected 4 forecasts: [0.6, 0.8, 0.875, 0.92]\n",
      "   >>> Collected 4 forecasts: [0.99, 0.9, 0.99, 0.99]\n",
      "   >>> Collected 4 forecasts: [0.97, 0.98, 0.9233333333333332, 0.954]\n",
      "   >>> Collected 4 forecasts: [0.99, 0.25, 0.14, 0.2]\n",
      "   >>> Collected 4 forecasts: [0.9, 0.85, 0.8340000000000001, nan]\n",
      "   >>> Collected 4 forecasts: [0.9, 0.8, 0.7666666666666667, nan]\n",
      "   >>> Collected 4 forecasts: [0.7, 0.6, 0.875, 0.7759999999999999]\n",
      "   >>> Collected 4 forecasts: [0.9, 0.85, 0.84, 0.86]\n",
      "   >>> Collected 4 forecasts: [0.05, 0.1, 0.026, 0.0559999999999999]\n",
      "   >>> Collected 4 forecasts: [0.2, 0.2, 0.16, nan]\n",
      "   >>> Collected 4 forecasts: [0.6, 0.8, 0.67, nan]\n",
      "   >>> Collected 4 forecasts: [0.2, 0.15, nan, nan]\n",
      "   >>> Collected 4 forecasts: [0.25, 0.25, 0.3925, nan]\n",
      "   >>> Collected 4 forecasts: [0.05, 0.1, 0.086, nan]\n",
      "   >>> Collected 4 forecasts: [0.2, 0.15, 0.285, nan]\n",
      "   >>> Collected 4 forecasts: [0.15, 0.05, 0.02, nan]\n",
      "   >>> Collected 4 forecasts: [0.85, 0.9, nan, nan]\n",
      "   >>> Collected 4 forecasts: [0.9, 0.9, 0.95, 0.905]\n",
      "   >>> Collected 4 forecasts: [0.9, 0.65, nan, nan]\n",
      "   >>> Collected 4 forecasts: [0.9, 0.85, nan, nan]\n",
      "   >>> Collected 4 forecasts: [0.85, 0.8, 0.85, 0.71]\n",
      "   >>> Collected 4 forecasts: [0.05, 0.02, 0.05, 0.02]\n",
      "   >>> Collected 5 forecasts: [0.1, 0.1, 0.07, 0.0559999999999999, nan]\n",
      "   >>> Collected 5 forecasts: [0.35, 0.6, 0.62, 0.7, 0.324676]\n",
      "   >>> Collected 5 forecasts: [0.9, 0.85, 0.82, 0.794, nan]\n",
      "   >>> Collected 5 forecasts: [0.75, 0.85, 0.85, 0.884, 0.76]\n",
      "   >>> Collected 5 forecasts: [0.05, 0.05, nan, nan, nan]\n",
      "   >>> Collected 5 forecasts: [0.7, 0.4, nan, nan, nan]\n",
      "   >>> Collected 5 forecasts: [0.85, 0.6, nan, nan, nan]\n",
      "   >>> Collected 5 forecasts: [0.05, 0.05, nan, nan, nan]\n",
      "   >>> Collected 5 forecasts: [0.15, 0.05, nan, nan, nan]\n",
      "   >>> Collected 5 forecasts: [0.2, 0.2, 0.25, nan, nan]\n",
      "   >>> Collected 5 forecasts: [0.2, 0.1, nan, 0.242, nan]\n",
      "   >>> Collected 5 forecasts: [0.7, 0.85, nan, 0.936, nan]\n",
      "   >>> Collected 5 forecasts: [0.15, 0.35, 0.108, 0.264, nan]\n",
      "   >>> Collected 5 forecasts: [0.25, 0.25, 0.16, 0.652, nan]\n",
      "   >>> Collected 5 forecasts: [0.05, 0.1, 0.95, 0.052, 0.0699999999999999]\n",
      "   >>> Collected 5 forecasts: [0.15, 0.4, 0.15, 0.12, 0.05]\n",
      "   >>> Collected 5 forecasts: [0.95, 0.9, 0.05, 0.866, 0.8925]\n",
      "   >>> Collected 5 forecasts: [0.1, 0.2, 0.125, 0.212, 0.085]\n",
      "   >>> Collected 5 forecasts: [0.05, 0.05, 0.034, nan, 0.0925]\n",
      "   >>> Collected 5 forecasts: [0.05, 0.02, 0.03, 0.072, 0.1]\n",
      "   >>> Collected 5 forecasts: [0.15, 0.4, 0.35, 0.3339999999999999, 0.1149999999999999]\n",
      "   >>> Collected 5 forecasts: [0.6, 0.3, 0.35, 0.5, 0.1375]\n",
      "   >>> Collected 5 forecasts: [0.2, 0.2, 0.115, 0.102, 0.1425]\n",
      "   >>> Collected 5 forecasts: [0.97, 0.98, 0.97, 0.932, 0.9475]\n",
      "   >>> Collected 5 forecasts: [0.4, 0.3, 0.285, 0.34, 0.2]\n",
      "   >>> Collected 5 forecasts: [0.4, 0.4, 0.3833333333333333, 0.42, 0.4]\n",
      "   >>> Collected 5 forecasts: [0.35, 0.45, 0.17, 0.236, nan]\n",
      "   >>> Collected 5 forecasts: [0.1, 0.02, 0.12, 0.29, 0.06]\n",
      "   >>> Collected 5 forecasts: [0.6, 0.8, 0.875, 0.92, 0.6599999999999999]\n",
      "   >>> Collected 5 forecasts: [0.99, 0.9, 0.99, 0.99, 0.95]\n",
      "   >>> Collected 5 forecasts: [0.97, 0.98, 0.9233333333333332, 0.954, 0.9280000000000002]\n",
      "   >>> Collected 5 forecasts: [0.99, 0.25, 0.14, 0.2, 0.336]\n",
      "   >>> Collected 5 forecasts: [0.9, 0.85, 0.8340000000000001, nan, nan]\n",
      "   >>> Collected 5 forecasts: [0.9, 0.8, 0.7666666666666667, nan, nan]\n",
      "   >>> Collected 5 forecasts: [0.7, 0.6, 0.875, 0.7759999999999999, 0.2299999999999999]\n",
      "   >>> Collected 5 forecasts: [0.9, 0.85, 0.84, 0.86, 0.8019999999999999]\n",
      "   >>> Collected 5 forecasts: [0.05, 0.1, 0.026, 0.0559999999999999, 0.05]\n",
      "   >>> Collected 5 forecasts: [0.2, 0.2, 0.16, nan, 0.05]\n",
      "   >>> Collected 5 forecasts: [0.6, 0.8, 0.67, nan, 0.76]\n",
      "   >>> Collected 5 forecasts: [0.2, 0.15, nan, nan, 0.2]\n",
      "   >>> Collected 5 forecasts: [0.25, 0.25, 0.3925, nan, 0.38]\n",
      "   >>> Collected 5 forecasts: [0.05, 0.1, 0.086, nan, 0.12]\n",
      "   >>> Collected 5 forecasts: [0.2, 0.15, 0.285, nan, 0.096]\n",
      "   >>> Collected 5 forecasts: [0.15, 0.05, 0.02, nan, 0.098]\n",
      "   >>> Collected 5 forecasts: [0.85, 0.9, nan, nan, 0.5599999999999999]\n",
      "   >>> Collected 5 forecasts: [0.9, 0.9, 0.95, 0.905, 0.78]\n",
      "   >>> Collected 5 forecasts: [0.9, 0.65, nan, nan, 0.05]\n",
      "   >>> Collected 5 forecasts: [0.9, 0.85, nan, nan, 0.744]\n",
      "   >>> Collected 5 forecasts: [0.85, 0.8, 0.85, 0.71, 0.55]\n",
      "   >>> Collected 5 forecasts: [0.05, 0.02, 0.05, 0.02, 0.052]\n",
      "   >>> Collected 6 forecasts: [0.1, 0.1, 0.07, 0.0559999999999999, nan, 0.175]\n",
      "   >>> Collected 6 forecasts: [0.35, 0.6, 0.62, 0.7, 0.324676, 0.5]\n",
      "   >>> Collected 6 forecasts: [0.9, 0.85, 0.82, 0.794, nan, 0.75]\n",
      "   >>> Collected 6 forecasts: [0.75, 0.85, 0.85, 0.884, 0.76, 0.85]\n",
      "   >>> Collected 6 forecasts: [0.05, 0.05, nan, nan, nan, 0.15]\n",
      "   >>> Collected 6 forecasts: [0.7, 0.4, nan, nan, nan, 0.7]\n",
      "   >>> Collected 6 forecasts: [0.85, 0.6, nan, nan, nan, 0.65]\n",
      "   >>> Collected 6 forecasts: [0.05, 0.05, nan, nan, nan, 0.15]\n",
      "   >>> Collected 6 forecasts: [0.15, 0.05, nan, nan, nan, 0.15]\n",
      "   >>> Collected 6 forecasts: [0.2, 0.2, 0.25, nan, nan, 0.225]\n",
      "   >>> Collected 6 forecasts: [0.2, 0.1, nan, 0.242, nan, 0.275]\n",
      "   >>> Collected 6 forecasts: [0.7, 0.85, nan, 0.936, nan, 0.85]\n",
      "   >>> Collected 6 forecasts: [0.15, 0.35, 0.108, 0.264, nan, 0.2]\n",
      "   >>> Collected 6 forecasts: [0.25, 0.25, 0.16, 0.652, nan, 0.275]\n",
      "   >>> Collected 6 forecasts: [0.05, 0.1, 0.95, 0.052, 0.0699999999999999, 0.125]\n",
      "   >>> Collected 6 forecasts: [0.15, 0.4, 0.15, 0.12, 0.05, 0.15]\n",
      "   >>> Collected 6 forecasts: [0.95, 0.9, 0.05, 0.866, 0.8925, 0.85]\n",
      "   >>> Collected 6 forecasts: [0.1, 0.2, 0.125, 0.212, 0.085, 0.725]\n",
      "   >>> Collected 6 forecasts: [0.05, 0.05, 0.034, nan, 0.0925, 0.125]\n",
      "   >>> Collected 6 forecasts: [0.05, 0.02, 0.03, 0.072, 0.1, 0.075]\n",
      "   >>> Collected 6 forecasts: [0.15, 0.4, 0.35, 0.3339999999999999, 0.1149999999999999, 0.275]\n",
      "   >>> Collected 6 forecasts: [0.6, 0.3, 0.35, 0.5, 0.1375, 0.35]\n",
      "   >>> Collected 6 forecasts: [0.2, 0.2, 0.115, 0.102, 0.1425, 0.275]\n",
      "   >>> Collected 6 forecasts: [0.97, 0.98, 0.97, 0.932, 0.9475, 0.5]\n",
      "   >>> Collected 6 forecasts: [0.4, 0.3, 0.285, 0.34, 0.2, 0.35]\n",
      "   >>> Collected 6 forecasts: [0.4, 0.4, 0.3833333333333333, 0.42, 0.4, 0.35]\n",
      "   >>> Collected 6 forecasts: [0.35, 0.45, 0.17, 0.236, nan, 0.3]\n",
      "   >>> Collected 6 forecasts: [0.1, 0.02, 0.12, 0.29, 0.06, 0.05]\n",
      "   >>> Collected 6 forecasts: [0.6, 0.8, 0.875, 0.92, 0.6599999999999999, 0.75]\n",
      "   >>> Collected 6 forecasts: [0.99, 0.9, 0.99, 0.99, 0.95, 0.5]\n",
      "   >>> Collected 6 forecasts: [0.97, 0.98, 0.9233333333333332, 0.954, 0.9280000000000002, 0.5]\n",
      "   >>> Collected 6 forecasts: [0.99, 0.25, 0.14, 0.2, 0.336, 0.325]\n",
      "   >>> Collected 6 forecasts: [0.9, 0.85, 0.8340000000000001, nan, nan, nan]\n",
      "   >>> Collected 6 forecasts: [0.9, 0.8, 0.7666666666666667, nan, nan, nan]\n",
      "   >>> Collected 6 forecasts: [0.7, 0.6, 0.875, 0.7759999999999999, 0.2299999999999999, 0.75]\n",
      "   >>> Collected 6 forecasts: [0.9, 0.85, 0.84, 0.86, 0.8019999999999999, 0.75]\n",
      "   >>> Collected 6 forecasts: [0.05, 0.1, 0.026, 0.0559999999999999, 0.05, 0.085]\n",
      "   >>> Collected 6 forecasts: [0.2, 0.2, 0.16, nan, 0.05, 0.225]\n",
      "   >>> Collected 6 forecasts: [0.6, 0.8, 0.67, nan, 0.76, 0.725]\n",
      "   >>> Collected 6 forecasts: [0.2, 0.15, nan, nan, 0.2, 0.2]\n",
      "   >>> Collected 6 forecasts: [0.25, 0.25, 0.3925, nan, 0.38, 0.675]\n",
      "   >>> Collected 6 forecasts: [0.05, 0.1, 0.086, nan, 0.12, 0.1]\n",
      "   >>> Collected 6 forecasts: [0.2, 0.15, 0.285, nan, 0.096, 0.15]\n",
      "   >>> Collected 6 forecasts: [0.15, 0.05, 0.02, nan, 0.098, 0.05]\n",
      "   >>> Collected 6 forecasts: [0.85, 0.9, nan, nan, 0.5599999999999999, 0.935]\n",
      "   >>> Collected 6 forecasts: [0.9, 0.9, 0.95, 0.905, 0.78, 0.935]\n",
      "   >>> Collected 6 forecasts: [0.9, 0.65, nan, nan, 0.05, 0.055]\n",
      "   >>> Collected 6 forecasts: [0.9, 0.85, nan, nan, 0.744, 0.8]\n",
      "   >>> Collected 6 forecasts: [0.85, 0.8, 0.85, 0.71, 0.55, 0.475]\n",
      "   >>> Collected 6 forecasts: [0.05, 0.02, 0.05, 0.02, 0.052, 0.04]\n",
      "   >>> Collected 7 forecasts: [0.1, 0.1, 0.07, 0.0559999999999999, nan, 0.175, 0.28]\n",
      "   >>> Collected 7 forecasts: [0.35, 0.6, 0.62, 0.7, 0.324676, 0.5, 0.35]\n",
      "   >>> Collected 7 forecasts: [0.9, 0.85, 0.82, 0.794, nan, 0.75, 0.88]\n",
      "   >>> Collected 7 forecasts: [0.75, 0.85, 0.85, 0.884, 0.76, 0.85, 0.75]\n",
      "   >>> Collected 7 forecasts: [0.05, 0.05, nan, nan, nan, 0.15, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.7, 0.4, nan, nan, nan, 0.7, 0.75]\n",
      "   >>> Collected 7 forecasts: [0.85, 0.6, nan, nan, nan, 0.65, 0.78]\n",
      "   >>> Collected 7 forecasts: [0.05, 0.05, nan, nan, nan, 0.15, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.15, 0.05, nan, nan, nan, 0.15, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.2, 0.2, 0.25, nan, nan, 0.225, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.2, 0.1, nan, 0.242, nan, 0.275, 0.85]\n",
      "   >>> Collected 7 forecasts: [0.7, 0.85, nan, 0.936, nan, 0.85, nan]\n",
      "   >>> Collected 7 forecasts: [0.15, 0.35, 0.108, 0.264, nan, 0.2, 0.3]\n",
      "   >>> Collected 7 forecasts: [0.25, 0.25, 0.16, 0.652, nan, 0.275, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.05, 0.1, 0.95, 0.052, 0.0699999999999999, 0.125, 0.05]\n",
      "   >>> Collected 7 forecasts: [0.15, 0.4, 0.15, 0.12, 0.05, 0.15, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.95, 0.9, 0.05, 0.866, 0.8925, 0.85, 0.9]\n",
      "   >>> Collected 7 forecasts: [0.1, 0.2, 0.125, 0.212, 0.085, 0.725, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.05, 0.05, 0.034, nan, 0.0925, 0.125, nan]\n",
      "   >>> Collected 7 forecasts: [0.05, 0.02, 0.03, 0.072, 0.1, 0.075, 0.05]\n",
      "   >>> Collected 7 forecasts: [0.15, 0.4, 0.35, 0.3339999999999999, 0.1149999999999999, 0.275, 0.27]\n",
      "   >>> Collected 7 forecasts: [0.6, 0.3, 0.35, 0.5, 0.1375, 0.35, 0.35]\n",
      "   >>> Collected 7 forecasts: [0.2, 0.2, 0.115, 0.102, 0.1425, 0.275, nan]\n",
      "   >>> Collected 7 forecasts: [0.97, 0.98, 0.97, 0.932, 0.9475, 0.5, nan]\n",
      "   >>> Collected 7 forecasts: [0.4, 0.3, 0.285, 0.34, 0.2, 0.35, nan]\n",
      "   >>> Collected 7 forecasts: [0.4, 0.4, 0.3833333333333333, 0.42, 0.4, 0.35, 0.27]\n",
      "   >>> Collected 7 forecasts: [0.35, 0.45, 0.17, 0.236, nan, 0.3, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.1, 0.02, 0.12, 0.29, 0.06, 0.05, nan]\n",
      "   >>> Collected 7 forecasts: [0.6, 0.8, 0.875, 0.92, 0.6599999999999999, 0.75, 0.65]\n",
      "   >>> Collected 7 forecasts: [0.99, 0.9, 0.99, 0.99, 0.95, 0.5, 0.99]\n",
      "   >>> Collected 7 forecasts: [0.97, 0.98, 0.9233333333333332, 0.954, 0.9280000000000002, 0.5, 0.98]\n",
      "   >>> Collected 7 forecasts: [0.99, 0.25, 0.14, 0.2, 0.336, 0.325, 0.2]\n",
      "   >>> Collected 7 forecasts: [0.9, 0.85, 0.8340000000000001, nan, nan, nan, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.9, 0.8, 0.7666666666666667, nan, nan, nan, 0.85]\n",
      "   >>> Collected 7 forecasts: [0.7, 0.6, 0.875, 0.7759999999999999, 0.2299999999999999, 0.75, 0.6]\n",
      "   >>> Collected 7 forecasts: [0.9, 0.85, 0.84, 0.86, 0.8019999999999999, 0.75, 0.75]\n",
      "   >>> Collected 7 forecasts: [0.05, 0.1, 0.026, 0.0559999999999999, 0.05, 0.085, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.2, 0.2, 0.16, nan, 0.05, 0.225, 0.35]\n",
      "   >>> Collected 7 forecasts: [0.6, 0.8, 0.67, nan, 0.76, 0.725, 0.75]\n",
      "   >>> Collected 7 forecasts: [0.2, 0.15, nan, nan, 0.2, 0.2, 0.2]\n",
      "   >>> Collected 7 forecasts: [0.25, 0.25, 0.3925, nan, 0.38, 0.675, 0.15]\n",
      "   >>> Collected 7 forecasts: [0.05, 0.1, 0.086, nan, 0.12, 0.1, 0.1]\n",
      "   >>> Collected 7 forecasts: [0.2, 0.15, 0.285, nan, 0.096, 0.15, 0.03]\n",
      "   >>> Collected 7 forecasts: [0.15, 0.05, 0.02, nan, 0.098, 0.05, 0.05]\n",
      "   >>> Collected 7 forecasts: [0.85, 0.9, nan, nan, 0.5599999999999999, 0.935, 0.75]\n",
      "   >>> Collected 7 forecasts: [0.9, 0.9, 0.95, 0.905, 0.78, 0.935, 0.95]\n",
      "   >>> Collected 7 forecasts: [0.9, 0.65, nan, nan, 0.05, 0.055, 0.65]\n",
      "   >>> Collected 7 forecasts: [0.9, 0.85, nan, nan, 0.744, 0.8, 0.75]\n",
      "   >>> Collected 7 forecasts: [0.85, 0.8, 0.85, 0.71, 0.55, 0.475, 0.85]\n",
      "   >>> Collected 7 forecasts: [0.05, 0.02, 0.05, 0.02, 0.052, 0.04, 0.02]\n",
      "   >>> Collected 8 forecasts: [0.1, 0.1, 0.07, 0.0559999999999999, nan, 0.175, 0.28, nan]\n",
      "   >>> Collected 8 forecasts: [0.35, 0.6, 0.62, 0.7, 0.324676, 0.5, 0.35, nan]\n",
      "   >>> Collected 8 forecasts: [0.9, 0.85, 0.82, 0.794, nan, 0.75, 0.88, nan]\n",
      "   >>> Collected 8 forecasts: [0.75, 0.85, 0.85, 0.884, 0.76, 0.85, 0.75, nan]\n",
      "   >>> Collected 8 forecasts: [0.05, 0.05, nan, nan, nan, 0.15, 0.15, nan]\n",
      "   >>> Collected 8 forecasts: [0.7, 0.4, nan, nan, nan, 0.7, 0.75, nan]\n",
      "   >>> Collected 8 forecasts: [0.85, 0.6, nan, nan, nan, 0.65, 0.78, nan]\n",
      "   >>> Collected 8 forecasts: [0.05, 0.05, nan, nan, nan, 0.15, 0.15, nan]\n",
      "   >>> Collected 8 forecasts: [0.15, 0.05, nan, nan, nan, 0.15, 0.15, nan]\n",
      "   >>> Collected 8 forecasts: [0.2, 0.2, 0.25, nan, nan, 0.225, 0.15, nan]\n",
      "   >>> Collected 8 forecasts: [0.2, 0.1, nan, 0.242, nan, 0.275, 0.85, nan]\n",
      "   >>> Collected 8 forecasts: [0.7, 0.85, nan, 0.936, nan, 0.85, nan, nan]\n",
      "   >>> Collected 8 forecasts: [0.15, 0.35, 0.108, 0.264, nan, 0.2, 0.3, nan]\n",
      "   >>> Collected 8 forecasts: [0.25, 0.25, 0.16, 0.652, nan, 0.275, 0.15, nan]\n",
      "   >>> Collected 8 forecasts: [0.05, 0.1, 0.95, 0.052, 0.0699999999999999, 0.125, 0.05, nan]\n",
      "   >>> Collected 8 forecasts: [0.15, 0.4, 0.15, 0.12, 0.05, 0.15, 0.15, nan]\n",
      "   >>> Collected 8 forecasts: [0.95, 0.9, 0.05, 0.866, 0.8925, 0.85, 0.9, nan]\n",
      "   >>> Collected 8 forecasts: [0.1, 0.2, 0.125, 0.212, 0.085, 0.725, 0.15, nan]\n",
      "   >>> Collected 8 forecasts: [0.05, 0.05, 0.034, nan, 0.0925, 0.125, nan, nan]\n",
      "   >>> Collected 8 forecasts: [0.05, 0.02, 0.03, 0.072, 0.1, 0.075, 0.05, 0.124]\n",
      "   >>> Collected 8 forecasts: [0.15, 0.4, 0.35, 0.3339999999999999, 0.1149999999999999, 0.275, 0.27, 0.6765]\n",
      "   >>> Collected 8 forecasts: [0.6, 0.3, 0.35, 0.5, 0.1375, 0.35, 0.35, 0.55]\n",
      "   >>> Collected 8 forecasts: [0.2, 0.2, 0.115, 0.102, 0.1425, 0.275, nan, 0.195]\n",
      "   >>> Collected 8 forecasts: [0.97, 0.98, 0.97, 0.932, 0.9475, 0.5, nan, 0.95]\n",
      "   >>> Collected 8 forecasts: [0.4, 0.3, 0.285, 0.34, 0.2, 0.35, nan, 0.4375]\n",
      "   >>> Collected 8 forecasts: [0.4, 0.4, 0.3833333333333333, 0.42, 0.4, 0.35, 0.27, 0.513]\n",
      "   >>> Collected 8 forecasts: [0.35, 0.45, 0.17, 0.236, nan, 0.3, 0.15, 0.6485000000000001]\n",
      "   >>> Collected 8 forecasts: [0.1, 0.02, 0.12, 0.29, 0.06, 0.05, nan, 0.345]\n",
      "   >>> Collected 8 forecasts: [0.6, 0.8, 0.875, 0.92, 0.6599999999999999, 0.75, 0.65, 0.85]\n",
      "   >>> Collected 8 forecasts: [0.99, 0.9, 0.99, 0.99, 0.95, 0.5, 0.99, nan]\n",
      "   >>> Collected 8 forecasts: [0.97, 0.98, 0.9233333333333332, 0.954, 0.9280000000000002, 0.5, 0.98, 0.95]\n",
      "   >>> Collected 8 forecasts: [0.99, 0.25, 0.14, 0.2, 0.336, 0.325, 0.2, 0.34]\n",
      "   >>> Collected 8 forecasts: [0.9, 0.85, 0.8340000000000001, nan, nan, nan, 0.15, nan]\n",
      "   >>> Collected 8 forecasts: [0.9, 0.8, 0.7666666666666667, nan, nan, nan, 0.85, nan]\n",
      "   >>> Collected 8 forecasts: [0.7, 0.6, 0.875, 0.7759999999999999, 0.2299999999999999, 0.75, 0.6, 0.847]\n",
      "   >>> Collected 8 forecasts: [0.9, 0.85, 0.84, 0.86, 0.8019999999999999, 0.75, 0.75, 0.8620000000000001]\n",
      "   >>> Collected 8 forecasts: [0.05, 0.1, 0.026, 0.0559999999999999, 0.05, 0.085, 0.15, 0.1615]\n",
      "   >>> Collected 8 forecasts: [0.2, 0.2, 0.16, nan, 0.05, 0.225, 0.35, 0.55]\n",
      "   >>> Collected 8 forecasts: [0.6, 0.8, 0.67, nan, 0.76, 0.725, 0.75, 0.85]\n",
      "   >>> Collected 8 forecasts: [0.2, 0.15, nan, nan, 0.2, 0.2, 0.2, 0.223]\n",
      "   >>> Collected 8 forecasts: [0.25, 0.25, 0.3925, nan, 0.38, 0.675, 0.15, 0.58]\n",
      "   >>> Collected 8 forecasts: [0.05, 0.1, 0.086, nan, 0.12, 0.1, 0.1, 0.1109999999999999]\n",
      "   >>> Collected 8 forecasts: [0.2, 0.15, 0.285, nan, 0.096, 0.15, 0.03, 0.125]\n",
      "   >>> Collected 8 forecasts: [0.15, 0.05, 0.02, nan, 0.098, 0.05, 0.05, 0.073]\n",
      "   >>> Collected 8 forecasts: [0.85, 0.9, nan, nan, 0.5599999999999999, 0.935, 0.75, 0.94]\n",
      "   >>> Collected 8 forecasts: [0.9, 0.9, 0.95, 0.905, 0.78, 0.935, 0.95, 0.785]\n",
      "   >>> Collected 8 forecasts: [0.9, 0.65, nan, nan, 0.05, 0.055, 0.65, 0.067]\n",
      "   >>> Collected 8 forecasts: [0.9, 0.85, nan, nan, 0.744, 0.8, 0.75, 0.7240000000000001]\n",
      "   >>> Collected 8 forecasts: [0.85, 0.8, 0.85, 0.71, 0.55, 0.475, 0.85, 0.708]\n",
      "   >>> Collected 8 forecasts: [0.05, 0.02, 0.05, 0.02, 0.052, 0.04, 0.02, 0.042]\n",
      "   >>> Collected 9 forecasts: [0.1, 0.1, 0.07, 0.0559999999999999, nan, 0.175, 0.28, nan, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.35, 0.6, 0.62, 0.7, 0.324676, 0.5, 0.35, nan, 0.7]\n",
      "   >>> Collected 9 forecasts: [0.9, 0.85, 0.82, 0.794, nan, 0.75, 0.88, nan, 0.8]\n",
      "   >>> Collected 9 forecasts: [0.75, 0.85, 0.85, 0.884, 0.76, 0.85, 0.75, nan, 0.85]\n",
      "   >>> Collected 9 forecasts: [0.05, 0.05, nan, nan, nan, 0.15, 0.15, nan, 0.05]\n",
      "   >>> Collected 9 forecasts: [0.7, 0.4, nan, nan, nan, 0.7, 0.75, nan, 0.35]\n",
      "   >>> Collected 9 forecasts: [0.85, 0.6, nan, nan, nan, 0.65, 0.78, nan, 0.75]\n",
      "   >>> Collected 9 forecasts: [0.05, 0.05, nan, nan, nan, 0.15, 0.15, nan, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.15, 0.05, nan, nan, nan, 0.15, 0.15, nan, 0.05]\n",
      "   >>> Collected 9 forecasts: [0.2, 0.2, 0.25, nan, nan, 0.225, 0.15, nan, 0.25]\n",
      "   >>> Collected 9 forecasts: [0.2, 0.1, nan, 0.242, nan, 0.275, 0.85, nan, 0.2]\n",
      "   >>> Collected 9 forecasts: [0.7, 0.85, nan, 0.936, nan, 0.85, nan, nan, 0.95]\n",
      "   >>> Collected 9 forecasts: [0.15, 0.35, 0.108, 0.264, nan, 0.2, 0.3, nan, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.25, 0.25, 0.16, 0.652, nan, 0.275, 0.15, nan, 0.25]\n",
      "   >>> Collected 9 forecasts: [0.05, 0.1, 0.95, 0.052, 0.0699999999999999, 0.125, 0.05, nan, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.15, 0.4, 0.15, 0.12, 0.05, 0.15, 0.15, nan, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.95, 0.9, 0.05, 0.866, 0.8925, 0.85, 0.9, nan, 0.85]\n",
      "   >>> Collected 9 forecasts: [0.1, 0.2, 0.125, 0.212, 0.085, 0.725, 0.15, nan, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.05, 0.05, 0.034, nan, 0.0925, 0.125, nan, nan, 0.05]\n",
      "   >>> Collected 9 forecasts: [0.05, 0.02, 0.03, 0.072, 0.1, 0.075, 0.05, 0.124, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.15, 0.4, 0.35, 0.3339999999999999, 0.1149999999999999, 0.275, 0.27, 0.6765, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.6, 0.3, 0.35, 0.5, 0.1375, 0.35, 0.35, 0.55, 0.35]\n",
      "   >>> Collected 9 forecasts: [0.2, 0.2, 0.115, 0.102, 0.1425, 0.275, nan, 0.195, 0.25]\n",
      "   >>> Collected 9 forecasts: [0.97, 0.98, 0.97, 0.932, 0.9475, 0.5, nan, 0.95, 0.85]\n",
      "   >>> Collected 9 forecasts: [0.4, 0.3, 0.285, 0.34, 0.2, 0.35, nan, 0.4375, 0.35]\n",
      "   >>> Collected 9 forecasts: [0.4, 0.4, 0.3833333333333333, 0.42, 0.4, 0.35, 0.27, 0.513, 0.65]\n",
      "   >>> Collected 9 forecasts: [0.35, 0.45, 0.17, 0.236, nan, 0.3, 0.15, 0.6485000000000001, 0.25]\n",
      "   >>> Collected 9 forecasts: [0.1, 0.02, 0.12, 0.29, 0.06, 0.05, nan, 0.345, 0.01]\n",
      "   >>> Collected 9 forecasts: [0.6, 0.8, 0.875, 0.92, 0.6599999999999999, 0.75, 0.65, 0.85, 0.85]\n",
      "   >>> Collected 9 forecasts: [0.99, 0.9, 0.99, 0.99, 0.95, 0.5, 0.99, nan, 0.99]\n",
      "   >>> Collected 9 forecasts: [0.97, 0.98, 0.9233333333333332, 0.954, 0.9280000000000002, 0.5, 0.98, 0.95, 0.98]\n",
      "   >>> Collected 9 forecasts: [0.99, 0.25, 0.14, 0.2, 0.336, 0.325, 0.2, 0.34, 0.25]\n",
      "   >>> Collected 9 forecasts: [0.9, 0.85, 0.8340000000000001, nan, nan, nan, 0.15, nan, 0.85]\n",
      "   >>> Collected 9 forecasts: [0.9, 0.8, 0.7666666666666667, nan, nan, nan, 0.85, nan, 0.75]\n",
      "   >>> Collected 9 forecasts: [0.7, 0.6, 0.875, 0.7759999999999999, 0.2299999999999999, 0.75, 0.6, 0.847, 0.35]\n",
      "   >>> Collected 9 forecasts: [0.9, 0.85, 0.84, 0.86, 0.8019999999999999, 0.75, 0.75, 0.8620000000000001, 0.85]\n",
      "   >>> Collected 9 forecasts: [0.05, 0.1, 0.026, 0.0559999999999999, 0.05, 0.085, 0.15, 0.1615, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.2, 0.2, 0.16, nan, 0.05, 0.225, 0.35, 0.55, 0.25]\n",
      "   >>> Collected 9 forecasts: [0.6, 0.8, 0.67, nan, 0.76, 0.725, 0.75, 0.85, 0.85]\n",
      "   >>> Collected 9 forecasts: [0.2, 0.15, nan, nan, 0.2, 0.2, 0.2, 0.223, 0.65]\n",
      "   >>> Collected 9 forecasts: [0.25, 0.25, 0.3925, nan, 0.38, 0.675, 0.15, 0.58, 0.25]\n",
      "   >>> Collected 9 forecasts: [0.05, 0.1, 0.086, nan, 0.12, 0.1, 0.1, 0.1109999999999999, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.2, 0.15, 0.285, nan, 0.096, 0.15, 0.03, 0.125, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.15, 0.05, 0.02, nan, 0.098, 0.05, 0.05, 0.073, 0.15]\n",
      "   >>> Collected 9 forecasts: [0.85, 0.9, nan, nan, 0.5599999999999999, 0.935, 0.75, 0.94, 0.85]\n",
      "   >>> Collected 9 forecasts: [0.9, 0.9, 0.95, 0.905, 0.78, 0.935, 0.95, 0.785, 0.9]\n",
      "   >>> Collected 9 forecasts: [0.9, 0.65, nan, nan, 0.05, 0.055, 0.65, 0.067, 0.75]\n",
      "   >>> Collected 9 forecasts: [0.9, 0.85, nan, nan, 0.744, 0.8, 0.75, 0.7240000000000001, 0.9]\n",
      "   >>> Collected 9 forecasts: [0.85, 0.8, 0.85, 0.71, 0.55, 0.475, 0.85, 0.708, 0.85]\n",
      "   >>> Collected 9 forecasts: [0.05, 0.02, 0.05, 0.02, 0.052, 0.04, 0.02, 0.042, 0.05]\n",
      "   >>> Collected 10 forecasts: [0.1, 0.1, 0.07, 0.0559999999999999, nan, 0.175, 0.28, nan, 0.15, nan]\n",
      "   >>> Collected 10 forecasts: [0.35, 0.6, 0.62, 0.7, 0.324676, 0.5, 0.35, nan, 0.7, nan]\n",
      "   >>> Collected 10 forecasts: [0.9, 0.85, 0.82, 0.794, nan, 0.75, 0.88, nan, 0.8, 0.638]\n",
      "   >>> Collected 10 forecasts: [0.75, 0.85, 0.85, 0.884, 0.76, 0.85, 0.75, nan, 0.85, 0.546]\n",
      "   >>> Collected 10 forecasts: [0.05, 0.05, nan, nan, nan, 0.15, 0.15, nan, 0.05, 0.127]\n",
      "   >>> Collected 10 forecasts: [0.7, 0.4, nan, nan, nan, 0.7, 0.75, nan, 0.35, 0.319]\n",
      "   >>> Collected 10 forecasts: [0.85, 0.6, nan, nan, nan, 0.65, 0.78, nan, 0.75, nan]\n",
      "   >>> Collected 10 forecasts: [0.05, 0.05, nan, nan, nan, 0.15, 0.15, nan, 0.15, nan]\n",
      "   >>> Collected 10 forecasts: [0.15, 0.05, nan, nan, nan, 0.15, 0.15, nan, 0.05, nan]\n",
      "   >>> Collected 10 forecasts: [0.2, 0.2, 0.25, nan, nan, 0.225, 0.15, nan, 0.25, 0.1939999999999999]\n",
      "   >>> Collected 10 forecasts: [0.2, 0.1, nan, 0.242, nan, 0.275, 0.85, nan, 0.2, 0.281]\n",
      "   >>> Collected 10 forecasts: [0.7, 0.85, nan, 0.936, nan, 0.85, nan, nan, 0.95, 0.946]\n",
      "   >>> Collected 10 forecasts: [0.15, 0.35, 0.108, 0.264, nan, 0.2, 0.3, nan, 0.15, nan]\n",
      "   >>> Collected 10 forecasts: [0.25, 0.25, 0.16, 0.652, nan, 0.275, 0.15, nan, 0.25, nan]\n",
      "   >>> Collected 10 forecasts: [0.05, 0.1, 0.95, 0.052, 0.0699999999999999, 0.125, 0.05, nan, 0.15, nan]\n",
      "   >>> Collected 10 forecasts: [0.15, 0.4, 0.15, 0.12, 0.05, 0.15, 0.15, nan, 0.15, 0.154]\n",
      "   >>> Collected 10 forecasts: [0.95, 0.9, 0.05, 0.866, 0.8925, 0.85, 0.9, nan, 0.85, 0.85]\n",
      "   >>> Collected 10 forecasts: [0.1, 0.2, 0.125, 0.212, 0.085, 0.725, 0.15, nan, 0.15, 0.408]\n",
      "   >>> Collected 10 forecasts: [0.05, 0.05, 0.034, nan, 0.0925, 0.125, nan, nan, 0.05, 0.132]\n",
      "   >>> Collected 10 forecasts: [0.05, 0.02, 0.03, 0.072, 0.1, 0.075, 0.05, 0.124, 0.15, 0.063]\n",
      "   >>> Collected 10 forecasts: [0.15, 0.4, 0.35, 0.3339999999999999, 0.1149999999999999, 0.275, 0.27, 0.6765, 0.15, 0.289]\n",
      "   >>> Collected 10 forecasts: [0.6, 0.3, 0.35, 0.5, 0.1375, 0.35, 0.35, 0.55, 0.35, 0.293]\n",
      "   >>> Collected 10 forecasts: [0.2, 0.2, 0.115, 0.102, 0.1425, 0.275, nan, 0.195, 0.25, 0.201]\n",
      "   >>> Collected 10 forecasts: [0.97, 0.98, 0.97, 0.932, 0.9475, 0.5, nan, 0.95, 0.85, 0.955]\n",
      "   >>> Collected 10 forecasts: [0.4, 0.3, 0.285, 0.34, 0.2, 0.35, nan, 0.4375, 0.35, 0.126]\n",
      "   >>> Collected 10 forecasts: [0.4, 0.4, 0.3833333333333333, 0.42, 0.4, 0.35, 0.27, 0.513, 0.65, 0.425]\n",
      "   >>> Collected 10 forecasts: [0.35, 0.45, 0.17, 0.236, nan, 0.3, 0.15, 0.6485000000000001, 0.25, 0.155]\n",
      "   >>> Collected 10 forecasts: [0.1, 0.02, 0.12, 0.29, 0.06, 0.05, nan, 0.345, 0.01, 0.161]\n",
      "   >>> Collected 10 forecasts: [0.6, 0.8, 0.875, 0.92, 0.6599999999999999, 0.75, 0.65, 0.85, 0.85, 0.6659999999999999]\n",
      "   >>> Collected 10 forecasts: [0.99, 0.9, 0.99, 0.99, 0.95, 0.5, 0.99, nan, 0.99, 0.959]\n",
      "   >>> Collected 10 forecasts: [0.97, 0.98, 0.9233333333333332, 0.954, 0.9280000000000002, 0.5, 0.98, 0.95, 0.98, 0.7759999999999999]\n",
      "   >>> Collected 10 forecasts: [0.99, 0.25, 0.14, 0.2, 0.336, 0.325, 0.2, 0.34, 0.25, 0.408]\n",
      "   >>> Collected 10 forecasts: [0.9, 0.85, 0.8340000000000001, nan, nan, nan, 0.15, nan, 0.85, nan]\n",
      "   >>> Collected 10 forecasts: [0.9, 0.8, 0.7666666666666667, nan, nan, nan, 0.85, nan, 0.75, nan]\n",
      "   >>> Collected 10 forecasts: [0.7, 0.6, 0.875, 0.7759999999999999, 0.2299999999999999, 0.75, 0.6, 0.847, 0.35, nan]\n",
      "   >>> Collected 10 forecasts: [0.9, 0.85, 0.84, 0.86, 0.8019999999999999, 0.75, 0.75, 0.8620000000000001, 0.85, nan]\n",
      "   >>> Collected 10 forecasts: [0.05, 0.1, 0.026, 0.0559999999999999, 0.05, 0.085, 0.15, 0.1615, 0.15, nan]\n",
      "   >>> Collected 10 forecasts: [0.2, 0.2, 0.16, nan, 0.05, 0.225, 0.35, 0.55, 0.25, nan]\n",
      "   >>> Collected 10 forecasts: [0.6, 0.8, 0.67, nan, 0.76, 0.725, 0.75, 0.85, 0.85, nan]\n",
      "   >>> Collected 10 forecasts: [0.2, 0.15, nan, nan, 0.2, 0.2, 0.2, 0.223, 0.65, 0.088]\n",
      "   >>> Collected 10 forecasts: [0.25, 0.25, 0.3925, nan, 0.38, 0.675, 0.15, 0.58, 0.25, 0.574]\n",
      "   >>> Collected 10 forecasts: [0.05, 0.1, 0.086, nan, 0.12, 0.1, 0.1, 0.1109999999999999, 0.15, nan]\n",
      "   >>> Collected 10 forecasts: [0.2, 0.15, 0.285, nan, 0.096, 0.15, 0.03, 0.125, 0.15, nan]\n",
      "   >>> Collected 10 forecasts: [0.15, 0.05, 0.02, nan, 0.098, 0.05, 0.05, 0.073, 0.15, 0.086]\n",
      "   >>> Collected 10 forecasts: [0.85, 0.9, nan, nan, 0.5599999999999999, 0.935, 0.75, 0.94, 0.85, 0.8220000000000001]\n",
      "   >>> Collected 10 forecasts: [0.9, 0.9, 0.95, 0.905, 0.78, 0.935, 0.95, 0.785, 0.9, 0.762]\n",
      "   >>> Collected 10 forecasts: [0.9, 0.65, nan, nan, 0.05, 0.055, 0.65, 0.067, 0.75, 0.126]\n",
      "   >>> Collected 10 forecasts: [0.9, 0.85, nan, nan, 0.744, 0.8, 0.75, 0.7240000000000001, 0.9, 0.828]\n",
      "   >>> Collected 10 forecasts: [0.85, 0.8, 0.85, 0.71, 0.55, 0.475, 0.85, 0.708, 0.85, 0.132]\n",
      "   >>> Collected 10 forecasts: [0.05, 0.02, 0.05, 0.02, 0.052, 0.04, 0.02, 0.042, 0.05, 0.27]\n"
     ]
    }
   ],
   "source": [
    "# @title Calculate df_bot_team_forecasts\n",
    "\n",
    "df_bot_team_forecasts = pd.merge(\n",
    "    df_bot_forecasts,\n",
    "    df_pro_bot_resolved_questions[['bot_question_id', 'pro_question_id', 'question_weight', 'resolution', 'type', 'options', 'range_min', 'range_max', 'open_lower_bound', 'open_upper_bound']],\n",
    "    on='bot_question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# KEEP ONLY ROWS WHERE PRO_QUESTION_ID IS NA\n",
    "df_bot_team_forecasts = df_bot_team_forecasts[~df_bot_team_forecasts['pro_question_id'].isna()]\n",
    "\n",
    "columns_to_keep = ['bot_question_id', 'question_weight', 'resolution', 'type', 'options', 'range_min', 'range_max', 'open_lower_bound', 'open_upper_bound'] + top_10_bots\n",
    "\n",
    "# Filter the DataFrame to keep only the specified columns\n",
    "df_bot_team_forecasts = df_bot_team_forecasts[columns_to_keep]\n",
    "\n",
    "df_bot_team_forecasts['options'] = df_bot_team_forecasts['options'].apply(parse_options_array)\n",
    "\n",
    "# Calculate and add median forecasts for 1 to 10 bots\n",
    "for i in range(1, 11):\n",
    "    bots_subset = top_10_bots[:i]\n",
    "    column_name = f'median_forecast_{i}_bots'\n",
    "    df_bot_team_forecasts[column_name] = df_bot_team_forecasts.apply(lambda row: get_median_forecast(row, bots=bots_subset), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut off output in dataframes when a CELL is too long\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>options</th>\n",
       "      <th>resolution</th>\n",
       "      <th>metac-o1-preview</th>\n",
       "      <th>median_forecast_5_bots</th>\n",
       "      <th>median_forecast_8_bots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[0, 1, 2-3, 4-6, &gt;6]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.014083333333333333,0.6016666666666668,0.178...</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>0.082463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.82</td>\n",
       "      <td>[0.05,0.0506666667,0.0513333333,0.052,0.052666...</td>\n",
       "      <td>[0.037750000000000006, 0.038250620225000004, 0...</td>\n",
       "      <td>[0.0402, 0.040750496180000005, 0.04130456232, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multiple_choice</td>\n",
       "      <td>[0-4, 5-9, &gt;9]</td>\n",
       "      <td>5-9</td>\n",
       "      <td>[0.7,0.25,0.05]</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>numeric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.2</td>\n",
       "      <td>[0.0,0.004,0.008,0.012,0.016,0.02,0.024,0.028,...</td>\n",
       "      <td>[0.0, 0.0019825503600000003, 0.003970557620000...</td>\n",
       "      <td>[0.0, 0.002036555585714286, 0.0040770089428571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.3585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>binary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                type               options resolution  \\\n",
       "0    multiple_choice  [0, 1, 2-3, 4-6, >6]          0   \n",
       "1            numeric                   NaN      86.82   \n",
       "2             binary                   NaN         no   \n",
       "3    multiple_choice        [0-4, 5-9, >9]        5-9   \n",
       "4            numeric                   NaN      119.2   \n",
       "..               ...                   ...        ...   \n",
       "342           binary                   NaN        yes   \n",
       "351           binary                   NaN         no   \n",
       "355           binary                   NaN        yes   \n",
       "361           binary                   NaN         no   \n",
       "364           binary                   NaN         no   \n",
       "\n",
       "                                      metac-o1-preview  \\\n",
       "0    [0.014083333333333333,0.6016666666666668,0.178...   \n",
       "1    [0.05,0.0506666667,0.0513333333,0.052,0.052666...   \n",
       "2                                                  0.1   \n",
       "3                                      [0.7,0.25,0.05]   \n",
       "4    [0.0,0.004,0.008,0.012,0.016,0.02,0.024,0.028,...   \n",
       "..                                                 ...   \n",
       "342                                                0.9   \n",
       "351                                                0.9   \n",
       "355                                                0.9   \n",
       "361                                               0.85   \n",
       "364                                               0.05   \n",
       "\n",
       "                                median_forecast_5_bots  \\\n",
       "0                                             0.014505   \n",
       "1    [0.037750000000000006, 0.038250620225000004, 0...   \n",
       "2                                                0.085   \n",
       "3                                               0.5125   \n",
       "4    [0.0, 0.0019825503600000003, 0.003970557620000...   \n",
       "..                                                 ...   \n",
       "342                                                0.9   \n",
       "351                                               0.65   \n",
       "355                                               0.85   \n",
       "361                                                0.8   \n",
       "364                                               0.05   \n",
       "\n",
       "                                median_forecast_8_bots  \n",
       "0                                             0.082463  \n",
       "1    [0.0402, 0.040750496180000005, 0.04130456232, ...  \n",
       "2                                                  0.1  \n",
       "3                                                  0.5  \n",
       "4    [0.0, 0.002036555585714286, 0.0040770089428571...  \n",
       "..                                                 ...  \n",
       "342                                             0.9025  \n",
       "351                                             0.3585  \n",
       "355                                              0.775  \n",
       "361                                              0.755  \n",
       "364                                              0.041  \n",
       "\n",
       "[99 rows x 6 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bot_team_forecasts[['type', 'options', 'resolution', 'metac-o1-preview', 'median_forecast_5_bots', 'median_forecast_8_bots']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of weights: 95.0, Number of questions: 99\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "a = df_bot_team_forecasts['question_weight'].sum()\n",
    "b = df_bot_team_forecasts.shape[0] # number of rows in df_bot_team_forecasts\n",
    "print(f'Sum of weights: {a}, Number of questions: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-FedHpWV_1v",
    "outputId": "7327c204-c501-4dfb-bdfb-176606c96dc4"
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Havent decided how to handle null forecasts or anulled resolutions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[241], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# @title Calculate the baseline scores for each team size\u001b[39;00m\n\u001b[1;32m      3\u001b[0m teams \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_forecast_1_bots\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_forecast_2_bots\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_forecast_3_bots\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_forecast_9_bots\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_forecast_10_bots\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m weighted_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_weighted_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_bot_team_forecasts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Print nicely - round to 2 decimal places and first column should be just an integer (bot team size)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m weighted_scores_print \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(weighted_scores)\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/Desktop/LogipediaStuff/aib-analysis/functions.py:448\u001b[0m, in \u001b[0;36mcalculate_weighted_scores\u001b[0;34m(df_bot_team_forecasts, teams)\u001b[0m\n\u001b[1;32m    445\u001b[0m forecast \u001b[38;5;241m=\u001b[39m row[team]\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 448\u001b[0m     weighted_score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_baseline_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforecast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrange_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrange_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquestion_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopen_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopen_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopen_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopen_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m     team_scores[team] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m weighted_score\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mIndexError\u001b[39;00m):\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# @Check: Does skipping introduce any problems?\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:61\u001b[0m, in \u001b[0;36mcalculate_baseline_score\u001b[0;34m(forecast, resolution, q_type, options, range_min, range_max, question_weight, open_upper_bound, open_lower_bound)\u001b[0m\n\u001b[1;32m     59\u001b[0m question_type \u001b[38;5;241m=\u001b[39m _determine_question_type(q_type, resolution)\n\u001b[1;32m     60\u001b[0m resolution \u001b[38;5;241m=\u001b[39m _normalize_resolution(question_type, resolution, range_min, range_max)\n\u001b[0;32m---> 61\u001b[0m prob_for_resolution \u001b[38;5;241m=\u001b[39m \u001b[43m_determine_probability_for_resolution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquestion_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrange_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrange_max\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m baseline_prob \u001b[38;5;241m=\u001b[39m _determine_baseline(\n\u001b[1;32m     65\u001b[0m     question_type, resolution, options, range_min, range_max, open_upper_bound, open_lower_bound\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m divisor \u001b[38;5;241m=\u001b[39m _determine_divisor_for_baseline_score(question_type, options)\n",
      "File \u001b[0;32m~/Desktop/LogipediaStuff/aib-analysis/refactored_notebook/scoring.py:153\u001b[0m, in \u001b[0;36m_determine_probability_for_resolution\u001b[0;34m(q_type, forecast, resolution, options, range_min, range_max)\u001b[0m\n\u001b[1;32m    150\u001b[0m resolution \u001b[38;5;241m=\u001b[39m _normalize_resolution(q_type, resolution, range_min, range_max)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m forecast \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m resolution \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHavent decided how to handle null forecasts or anulled resolutions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(forecast) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForecast is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Havent decided how to handle null forecasts or anulled resolutions"
     ]
    }
   ],
   "source": [
    "# @title Calculate the baseline scores for each team size\n",
    "\n",
    "teams = ['median_forecast_1_bots',\n",
    "         'median_forecast_2_bots',\n",
    "         'median_forecast_3_bots',\n",
    "         'median_forecast_4_bots',\n",
    "         'median_forecast_5_bots',\n",
    "         'median_forecast_6_bots',\n",
    "         'median_forecast_7_bots',\n",
    "         'median_forecast_8_bots',\n",
    "         'median_forecast_9_bots',\n",
    "         'median_forecast_10_bots']\n",
    "\n",
    "weighted_scores = calculate_weighted_scores(df_bot_team_forecasts, teams)\n",
    "\n",
    "# Print nicely - round to 2 decimal places and first column should be just an integer (bot team size)\n",
    "weighted_scores_print = pd.DataFrame(weighted_scores).reset_index()\n",
    "weighted_scores_print.columns = ['Bot_Team_Size', 'Weighted_Baseline_Score_for_Bot_Team_Median']\n",
    "weighted_scores_print['Weighted_Baseline_Score_for_Bot_Team_Median'] = weighted_scores_print['Weighted_Baseline_Score_for_Bot_Team_Median'].round(2)\n",
    "weighted_scores_print['Bot_Team_Size'] = weighted_scores_print['Bot_Team_Size'].apply(lambda x: int(x.split('_')[2].split('_')[0]))\n",
    "weighted_scores_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of top bot team from weighted_scores_print?\n",
    "winning_bot_team_size = weighted_scores_print.sort_values(by='Weighted_Baseline_Score_for_Bot_Team_Median', ascending=False).head(1)['Bot_Team_Size'].values[0]\n",
    "top_bot_team = top_10_bots[:winning_bot_team_size]\n",
    "top_bot_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot_forecasts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge bot_team_forecasts with df_top_bot_forecasts, just get type and options columns from bot_team_forecasts, merge on bot_question_id\n",
    "df_bot_forecasts = pd.merge(\n",
    "    df_bot_forecasts,\n",
    "    df_bot_team_forecasts[['bot_question_id', 'type', 'options', 'resolution']],\n",
    "    on='bot_question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# And make bot_question_id, type and options the first columns\n",
    "df_bot_forecasts = df_bot_forecasts[['bot_question_id', 'type', 'options', 'resolution'] + [col for col in df_bot_forecasts.columns if col not in ['bot_question_id', 'type', 'options']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot_team_forecasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3TTBVWoZVzU",
    "outputId": "0eb32f2c-09c6-4a15-e81a-bee353b1bccf"
   },
   "outputs": [],
   "source": [
    "# @title Weighted team-vs-pro\n",
    "\n",
    "# We have our top bot team members.\n",
    "# Calculate their median forecast on the pro_bot questions.\n",
    "# Create df with bot_question_id, forecasts, resolution, weights\n",
    "# Calculate the head-to-head score\n",
    "\n",
    "df_top_bot_forecasts = df_bot_team_forecasts[['bot_question_id', f'median_forecast_{len(top_bot_team)}_bots']]\n",
    "df_top_bot_forecasts = df_top_bot_forecasts.rename(columns={f'median_forecast_{len(top_bot_team)}_bots': 'bot_team_median'})\n",
    "\n",
    "df_pro_median = df_pro_forecasts[['pro_question_id', 'pro_median']]\n",
    "\n",
    "df_top_bot_pro_forecasts = pd.merge(\n",
    "    df_pro_bot_resolved_questions,\n",
    "    df_top_bot_forecasts[['bot_question_id', 'bot_team_median']],\n",
    "    on='bot_question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_top_bot_pro_forecasts = pd.merge(\n",
    "    df_top_bot_pro_forecasts,\n",
    "    df_pro_median,\n",
    "    on='pro_question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Copy with union (not just overlapping questions)\n",
    "df_top_bot_pro_forecasts_all = df_top_bot_pro_forecasts.copy()\n",
    "\n",
    "# Filter to only those rows where pro_median is not NA\n",
    "df_top_bot_pro_forecasts = df_top_bot_pro_forecasts.dropna(subset=['pro_median'])\n",
    "\n",
    "# Add the head_to_head column\n",
    "df_top_bot_pro_forecasts['head_to_head'] = df_top_bot_pro_forecasts.apply(calculate_head_to_head, args=('bot_team_median', 'pro_median'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_total_score = get_weighted_score(df_top_bot_pro_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "JlU9zyqn26Rl",
    "outputId": "ac54d636-670b-4a8f-aea9-402679efacf9"
   },
   "outputs": [],
   "source": [
    "plot_head_to_head_distribution(df_top_bot_pro_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1qC4m2VefLe",
    "outputId": "2f110b55-caf6-4ea8-9dfe-b746c3e4d892"
   },
   "outputs": [],
   "source": [
    "df_bot_team_h2h = calculate_t_test(df_top_bot_pro_forecasts, ['head_to_head'])\n",
    "\n",
    "df_bot_team_h2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0I0myCHpl7FT",
    "outputId": "bcc45b9a-f328-4f0c-ef98-a7620af7e358"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "df_sorted = df_top_bot_pro_forecasts.sort_values(by='head_to_head')\n",
    "df_sorted['head_to_head'] = df_sorted['head_to_head'].round(1)\n",
    "#df_sorted['resolution'] = df_sorted['resolution'].map({1: 'yes', 0: 'no'})\n",
    "\n",
    "df_top5 = df_sorted.head(5)\n",
    "df_bottom5 = df_sorted.tail(5)\n",
    "\n",
    "print(\"Top 5:\")\n",
    "\n",
    "df_top5[['title', 'bot_team_median', 'pro_median', 'resolution', 'head_to_head']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBottom 5:\")\n",
    "\n",
    "df_bottom5[['title', 'bot_team_median', 'pro_median', 'resolution', 'head_to_head']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast df_top_bot_pro_forecasts['resolution'] as string - idk why this is necessary but it is\n",
    "df_top_bot_pro_forecasts['resolution'] = df_top_bot_pro_forecasts['resolution'].astype(pd.StringDtype())\n",
    "df_top_bot_pro_forecasts['resolution'] = df_top_bot_pro_forecasts['resolution'].map({'yes': 1, 'no': 0})\n",
    "df_top_bot_pro_forecasts.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_bot_pro_forecasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make binary-only df_top_bot_pro_forecasts for calibration curves etc\n",
    "df_top_bot_pro_forecasts_binary = df_top_bot_pro_forecasts[df_top_bot_pro_forecasts['type'] == 'binary'].copy()\n",
    "\n",
    "df_top_bot_pro_forecasts_all_binary = df_top_bot_pro_forecasts_all[df_top_bot_pro_forecasts_all['type'] == 'binary'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "BjNQ4IND6Ct7",
    "outputId": "c0ec1316-ef4e-4bd1-875d-148b65ba0114"
   },
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly calibrated')\n",
    "\n",
    "# Plot calibration curves for bot_team_median and pro_median\n",
    "plot_calibration_curve(df_top_bot_pro_forecasts_binary, 'bot_team_median', 'Bot Team Median', 'blue')\n",
    "plot_calibration_curve(df_top_bot_pro_forecasts_binary, 'pro_median', 'Pro Median', 'red')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Assigned Probability', fontsize=12)\n",
    "plt.ylabel('Fraction that Resolved \\'Yes\\'', fontsize=12)\n",
    "plt.title(f'Calibration Curve: Bot Team Median vs Pro Median\\n(only overlap: {len(df_top_bot_pro_forecasts_binary)} questions)', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Set axis limits\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Number of pro forecasts: {len(df_top_bot_pro_forecasts_binary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map resolution to 0 and 1\n",
    "df_top_bot_pro_forecasts_all_binary['resolution'] = df_top_bot_pro_forecasts_all_binary['resolution'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_bot_pro_forecasts_all_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly calibrated')\n",
    "\n",
    "# Plot calibration curves for bot_team_median and pro_median\n",
    "plot_calibration_curve(df_top_bot_pro_forecasts_all_binary, 'bot_team_median', 'Bot Team Median', 'blue')\n",
    "plot_calibration_curve(df_top_bot_pro_forecasts_binary, 'pro_median', 'Pro Median', 'red')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Assigned Probability', fontsize=12)\n",
    "plt.ylabel('Fraction that Resolved \\'Yes\\'', fontsize=12)\n",
    "plt.title(f'Calibration Curve: Bot Team Median vs Pro Median\\n(all questions)', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Set axis limits\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Number of pro forecasts: {len(df_top_bot_pro_forecasts_binary)}\")\n",
    "print(f\"Number of bot forecasts: {len(df_top_bot_pro_forecasts_all_binary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPPgorXB7omi",
    "outputId": "24571b16-50b7-4e51-cd3d-420c15c7fe42"
   },
   "outputs": [],
   "source": [
    "# Calculate confidence scores for bot_team_median and pro_median\n",
    "display_head_and_tail(df_top_bot_pro_forecasts)\n",
    "bot_confidence = calculate_confidence(df_top_bot_pro_forecasts['bot_team_median'], df_top_bot_pro_forecasts['resolution'])\n",
    "pro_confidence = calculate_confidence(df_top_bot_pro_forecasts['pro_median'], df_top_bot_pro_forecasts['resolution'])\n",
    "\n",
    "print(f\"Bot team confidence score: {bot_confidence:.4f}\")\n",
    "print(f\"Pro team confidence score: {pro_confidence:.4f}\")\n",
    "\n",
    "print(f\"Bot team is {interpret_confidence(bot_confidence)}\")\n",
    "print(f\"Pro team is {interpret_confidence(pro_confidence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "N26JZjCV9_jc",
    "outputId": "eacb7626-54d0-47c7-8f21-48e95e709564"
   },
   "outputs": [],
   "source": [
    "# Call the function with your DataFrame and column names\n",
    "create_discrimination_histogram(df_top_bot_pro_forecasts,\n",
    "                                'bot_team_median',\n",
    "                                'pro_median',\n",
    "                                'resolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dkNBotk_4e3",
    "outputId": "d393a72e-997a-4025-ca7b-6f5328436286"
   },
   "outputs": [],
   "source": [
    "# Calculate average forecasts for resolved 1 and 0 for bots\n",
    "bot_avg_1 = df_top_bot_pro_forecasts[df_top_bot_pro_forecasts['resolution'] == 1]['bot_team_median'].mean()\n",
    "bot_avg_0 = df_top_bot_pro_forecasts[df_top_bot_pro_forecasts['resolution'] == 0]['bot_team_median'].mean()\n",
    "\n",
    "# Calculate average forecasts for resolved 1 and 0 for pros\n",
    "pro_avg_1 = df_top_bot_pro_forecasts[df_top_bot_pro_forecasts['resolution'] == 1]['pro_median'].mean()\n",
    "pro_avg_0 = df_top_bot_pro_forecasts[df_top_bot_pro_forecasts['resolution'] == 0]['pro_median'].mean()\n",
    "\n",
    "# Calculate the differences\n",
    "bot_difference = bot_avg_1 - bot_avg_0\n",
    "pro_difference = pro_avg_1 - pro_avg_0\n",
    "\n",
    "print(f\"Bot average forecast difference (1 - 0): {bot_difference:.4f}\")\n",
    "print(f\"Pro average forecast difference (1 - 0): {pro_difference:.4f}\")\n",
    "\n",
    "# Calculate the difference between pro and bot differences\n",
    "pro_bot_difference = pro_difference - bot_difference\n",
    "print(f\"Difference between pro and bot differences: {pro_bot_difference:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGnXswWOx_yw",
    "outputId": "35a0e2a8-5831-43cf-a006-f8e0262666ec"
   },
   "outputs": [],
   "source": [
    "# Calculate weighted number of 1 resolutions\n",
    "weighted_ones = np.sum(\n",
    "    df_top_bot_pro_forecasts['resolution'] *\n",
    "    df_top_bot_pro_forecasts['question_weight']\n",
    ")\n",
    "\n",
    "# Calculate weighted number of 0 resolutions\n",
    "weighted_zeros = np.sum(\n",
    "    (1 - df_top_bot_pro_forecasts['resolution']) *\n",
    "    df_top_bot_pro_forecasts['question_weight']\n",
    ")\n",
    "\n",
    "print(f\"Weighted number of 1 resolutions: {weighted_ones}\")\n",
    "print(f\"Weighted number of 0 resolutions: {weighted_zeros}\")\n",
    "\n",
    "print(f\"Average 1 resolutions: {weighted_ones / (weighted_zeros + weighted_ones)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CP COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CP COMPARISON\n",
    "\n",
    "cp = pd.read_csv('https://data.heroku.com/dataclips/xwbtczmsuszvlbrhdifhsilplfxf.csv')\n",
    "cp.rename(columns={'post_id': 'cp_post_id', 'question_id': 'cp_question_id'}, inplace=True)\n",
    "\n",
    "bot_cp_id = pd.read_csv('misc_data/bot_to_main_feed_ids.csv')\n",
    "\n",
    "# Merge these on cp_question_id\n",
    "df_bot_cp = pd.merge(bot_cp_id, cp, on='cp_post_id', how='right') # ahh?\n",
    "\n",
    "df_bot_cp = df_bot_cp[df_bot_cp['bot_question_id'].notnull()]\n",
    "df_bot_cp['bot_question_id'] = df_bot_cp['bot_question_id'].astype(int)\n",
    "\n",
    "# Evaluate cp_reveal_time, start_time, and end_time as datetime objects\n",
    "df_bot_cp['cp_reveal_time'] = pd.to_datetime(df_bot_cp['cp_reveal_time'])\n",
    "df_bot_cp['start_time'] = pd.to_datetime(df_bot_cp['start_time'])\n",
    "df_bot_cp['end_time'] = pd.to_datetime(df_bot_cp['end_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each group of (bot_question_id, question_title, cp_reveal_time), take only the row with the start_time closest to (BUT LESS THAN) cp_reveal_time\n",
    "df_bot_cp = df_bot_cp.sort_values(by=['bot_question_id', 'cp_reveal_time', 'start_time'])\n",
    "df_bot_cp = df_bot_cp[df_bot_cp['start_time'] < df_bot_cp['cp_reveal_time']]\n",
    "df_bot_cp = df_bot_cp.drop_duplicates(subset=['bot_question_id', 'cp_reveal_time', 'title'], keep='last')\n",
    "\n",
    "## Convert string representation of lists to actual lists\n",
    "df_bot_cp['forecast_values'] = df_bot_cp['forecast_values'].str.strip('[]').str.split(',').apply(lambda x: [float(i.strip()) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deal with influenza rows by filtering to rows where dates match.\n",
    "\n",
    "# First do the December/November replacements only on the relevant rows\n",
    "mask_29507 = df_bot_cp['cp_post_id'] == 29507\n",
    "df_bot_cp.loc[mask_29507, 'title'] = df_bot_cp.loc[mask_29507, 'title'].str.replace('December', 'Dec', regex=False)\n",
    "df_bot_cp.loc[mask_29507, 'title'] = df_bot_cp.loc[mask_29507, 'title'].str.replace('November', 'Nov', regex=False)\n",
    "\n",
    "# Then filter only those rows by the date matching condition\n",
    "matching_rows = df_bot_cp[mask_29507].apply(lambda row:\n",
    "    row['title'].find(re.search(r'(\\w+ \\d+)', row['question_title']).group(1)) != -1,\n",
    "    axis=1)\n",
    "\n",
    "# Update only the matching rows within the 29507 subset\n",
    "df_bot_cp = pd.concat([df_bot_cp[~mask_29507], df_bot_cp[mask_29507][matching_rows]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down by types - \"group\" (multiple choice; my bad), \"binary\" and \"numeric\"\n",
    "\n",
    "# Group questions are the ones that have NON-EMPTY lists in the options column\n",
    "groups = df_bot_cp[df_bot_cp['type'] == 'multiple_choice']\n",
    "groups['options'] = groups['options'].str.strip('[]').str.split(',').apply(lambda x: [i.strip().strip(\"'\") for i in x])\n",
    "\n",
    "binaries = df_bot_cp[df_bot_cp['type'] == 'binary']\n",
    "\n",
    "numerics = df_bot_cp[df_bot_cp['type'] == 'numeric']\n",
    "\n",
    "keep_cols = ['bot_question_id', 'question_title', 'title', 'cp_reveal_time', 'type', 'cp_question_id', 'cp_post_id', 'resolution', 'forecast_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and store problematic index\n",
    "problematic_idx = None\n",
    "for idx, row in groups.iterrows():\n",
    "   if len(row['forecast_values']) != len(row['options']):\n",
    "       problematic_idx = idx\n",
    "       break\n",
    "\n",
    "# Fix the specific row using stored index\n",
    "if problematic_idx is not None:\n",
    "   groups.at[problematic_idx, 'options'] = [\n",
    "       'Low',\n",
    "       'Moderate (or medium or equivalent)',\n",
    "       'High (or above such as Very High)'\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_exploded = groups.explode(['options', 'forecast_values'])\n",
    "groups_exploded['options'] = groups_exploded['options'].str.strip('\"')\n",
    "\n",
    "mask = groups_exploded['question_title'].str.contains('Will Joe Biden sign', case=False, na=False)\n",
    "groups_exploded.loc[mask, 'threshold'] = groups_exploded.loc[mask, 'question_title'].str.extract(r'(\\d+)')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each bot_question_id\n",
    "for bot_question_id in groups_exploded['bot_question_id'].unique():\n",
    "    # Get all rows for this bot_question_id\n",
    "    question_group = groups_exploded[groups_exploded['bot_question_id'] == bot_question_id]\n",
    "\n",
    "    # Get the question title\n",
    "    question_title = question_group['question_title'].iloc[0]\n",
    "\n",
    "    # Function to check if option matches question title\n",
    "    def option_matches(row):\n",
    "        option = row['options']\n",
    "        if option in question_title:\n",
    "            return True\n",
    "        # Handle \"X or Y\" vs \"X-Y\" format\n",
    "        if '-' in option:\n",
    "            start, end = option.split('-')\n",
    "            or_format = f\"{start} or {end}\"\n",
    "            return or_format in question_title\n",
    "        return False\n",
    "\n",
    "    # Find rows where the question title contains the option (with format handling)\n",
    "    matching_rows = question_group[question_group.apply(option_matches, axis=1)]\n",
    "\n",
    "    filtered_rows = []\n",
    "\n",
    "    # If we found a matching row, add the first one to our filtered rows, EXCEPT... Biden\n",
    "    if not matching_rows.empty and 'Biden' not in question_title:\n",
    "        filtered_rows.append(matching_rows.iloc[0])\n",
    "\n",
    "    # If Biden in question_title, we mustn't just take the first row - we must sum the rows that meet the threshold\n",
    "    if 'Biden' in question_title:\n",
    "        # Get first row for each unique option to avoid duplicates\n",
    "        first_rows = matching_rows.drop_duplicates(subset=['options'])\n",
    "\n",
    "        # Drop option='1' - we don't ask about 1 or more\n",
    "        first_rows = first_rows[first_rows['options'] != '1']\n",
    "        biden_interp = first_rows.copy()\n",
    "\n",
    "        # Now for each row in biden_interp\n",
    "        for idx, row in biden_interp.iterrows():\n",
    "            threshold = int(row['threshold'])\n",
    "            # Calculate cumulative probability based on that row's threshold\n",
    "            if threshold == 2:\n",
    "                forecast_value = first_rows[first_rows['options'].isin(['2', '3', '4 or more'])]['forecast_values'].sum()\n",
    "            elif threshold == 3:\n",
    "                forecast_value = first_rows[first_rows['options'].isin(['3', '4 or more'])]['forecast_values'].sum()\n",
    "            elif threshold == 4:\n",
    "                forecast_value = first_rows[first_rows['options'] == '4 or more']['forecast_values'].sum()\n",
    "\n",
    "            # Update this row's forecast value\n",
    "            biden_interp.at[idx, 'forecast_value'] = forecast_value\n",
    "\n",
    "        filtered_rows.append(biden_interp.iloc[0])\n",
    "\n",
    "# Combine all filtered rows into a DataFrame\n",
    "groups_filtered = pd.DataFrame(filtered_rows)\n",
    "\n",
    "# Print check\n",
    "print(f\"Original unique multiple-choice bot_question_ids: {len(groups_exploded['bot_question_id'].unique())}\")\n",
    "print(f\"Filtered unique multiple-choice bot_question_ids: {len(groups_filtered['bot_question_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show me Biden rows in groups_exploded\n",
    "groups_filtered[groups_filtered['title'].str.contains('Biden', case=False)][['question_title', 'title', 'options', 'forecast_values']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_filtered[['bot_question_id', 'question_title', 'title', 'options']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For BINARIES: Interpret forecast_values as lists and take the 'yes' element from each\n",
    "binaries['forecast_values'] = binaries['forecast_values'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMERICS ARE TRICKY\n",
    "\n",
    "# How long is each list in forecast_values?\n",
    "numerics['cdf_size'] = numerics['forecast_values'].apply(len)\n",
    "\n",
    "# Need to extract thresholds from binary versions of the numeric questions. TK: Could use another pair of eyes\n",
    "thresholds = {\n",
    "   29163: ('less', 2.0),        # COVID hospitalizations\n",
    "   29349: ('greater', 100),     # Brasilia rain\n",
    "   29350: ('greater', 150),     # Brasilia rain\n",
    "   29351: ('greater', 200),     # Brasilia rain\n",
    "   29353: ('greater', 20),      # Arms sales\n",
    "   29354: ('greater', 25),      # Arms sales\n",
    "   29362: ('greater', 3900),    # Emojis\n",
    "   29461: ('greater', 2000),    # Influenza hospitalizations\n",
    "   29462: ('greater', 2000),    # Influenza hospitalizations\n",
    "   29463: ('greater', 80),      # CDC influenza A\n",
    "   29566: ('less', 17.0),       # China unemployment Oct\n",
    "   29567: ('complicated', 0.0), # China unemployment Oct\n",
    "   29568: ('complicated', 0.0), # China unemployment Oct\n",
    "   29569: ('greater', 19.0),    # China unemployment Oct\n",
    "   29642: ('less', 0),        # Elon Musk net worth (less than or equal Bezos)\n",
    "   29643: ('complicated', 0.0), # Elon Musk net worth\n",
    "   29644: ('complicated', 0.0), # Elon Musk net worth\n",
    "   29645: ('complicated', 0.0), # Elon Musk net worth\n",
    "   29646: ('greater', 100),     # Elon Musk net worth (100+ more than Bezos)\n",
    "   29836: ('less', 17.0),       # China unemployment Nov\n",
    "   29837: ('complicated', 0.0), # China unemployment Nov\n",
    "   29838: ('complicated', 0.0), # China unemployment Nov\n",
    "   29839: ('greater', 19.0),    # China unemployment Nov\n",
    "   29836: ('greater', 375),     # NZ whooping cough\n",
    "   30578: ('complicated', 0.0), # NZ whooping cough\n",
    "   30579: ('less', 275),        # NZ whooping cough\n",
    "   30440: ('greater', -4),      # Trump favorability\n",
    "   30441: ('complicated', 0.0), # Trump favorability\n",
    "   30442: ('less', -6),         # Trump favorability\n",
    "   30583: ('greater', 7400),    # CAC 40\n",
    "   30584: ('complicated', 0.0), # CAC 40\n",
    "   30585: ('less', 7200),       # CAC 40\n",
    "   29462: ('complicated', 2000),    # Influenza hospitalizations\n",
    "   29462: ('complicated', 2000),     # Influenza hospitalizations\n",
    "   30791: ('greater', 19),      # Airline passengers\n",
    "   30792: ('complicated', 0.0),      # Airline passengers\n",
    "   30793: ('complicated', 0.0),         # Airline passengers\n",
    "   30794: ('less', 17),         # Airline passengers\n",
    "}\n",
    "\n",
    "# Apply that dictionary and make a 'binary_version_tuple' column\n",
    "numerics['binary_version_tuple'] = numerics['bot_question_id'].map(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values of binary_version_tuple\n",
    "unique_tuples = numerics['binary_version_tuple'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cdf's for the complicated ones (we will overwrite forecast_values)\n",
    "numerics['cdf'] = numerics['forecast_values']\n",
    "\n",
    "numerics = process_forecast_values(numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite the forecast_values for the influenza hospitalizations questions (grouped by week)\n",
    "numerics[numerics['bot_question_id'].isin([29461, 29462])]['cdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doing the \"between\" (\"complicated\") numerics one by one by bot_question_id\n",
    "\n",
    "# 29503: Waymo exactly 4, i.e. between 3.5 and 4.5 on continuous question\n",
    "row = numerics[numerics['bot_question_id'] == 29503].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 3.5, 4.5)\n",
    "\n",
    "# 29567: China youth unemployment > 17.0 and less than 18.0\n",
    "row = numerics[numerics['bot_question_id'] == 29567].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 17.0, 18.0)\n",
    "\n",
    "# 29568: China youth unemployment > 18.0 and less than 19.0\n",
    "row = numerics[numerics['bot_question_id'] == 29568].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 18.0, 19.0)\n",
    "\n",
    "# 29643: Elon Musk net worth > 240 and less than 280\n",
    "row = numerics[numerics['bot_question_id'] == 29643].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 0, 40)\n",
    "\n",
    "# 29644: Elon Musk net worth > 280 and less than 310\n",
    "row = numerics[numerics['bot_question_id'] == 29644].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 40, 70)\n",
    "\n",
    "# 29645: Elon Musk net worth > 310 and less than 340\n",
    "row = numerics[numerics['bot_question_id'] == 29645].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 70, 100)\n",
    "\n",
    "# 29837: China youth unemployment > 17.0 and less than 18.0\n",
    "row = numerics[numerics['bot_question_id'] == 29837].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 17.0, 18.0)\n",
    "\n",
    "# 29838: China youth unemployment > 18.0 and less than 19.0\n",
    "row = numerics[numerics['bot_question_id'] == 29838].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values']= cdf_between(row, row['cdf'], 18.0, 19.0)\n",
    "\n",
    "# 30281: Waymo exactly 4, i.e. between 3.5 and 4.5 on continuous question\n",
    "row = numerics[numerics['bot_question_id'] == 30281].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 3.5, 4.5)\n",
    "\n",
    "# 30437: New Zealand >375 whooping cough cases\n",
    "row = numerics[numerics['bot_question_id'] == 30437].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 375, 400)\n",
    "\n",
    "# 30438: New Zealand >275 and less than 375 whooping cough cases\n",
    "row = numerics[numerics['bot_question_id'] == 30438].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 275, 375)\n",
    "\n",
    "# 30439: New Zealand less than 275 whooping cough cases\n",
    "row = numerics[numerics['bot_question_id'] == 30439].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 250, 275)\n",
    "\n",
    "# 30441: Trump net favorabilty > -6 and less than -4\n",
    "row = numerics[numerics['bot_question_id'] == 30441].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], -6, -4)\n",
    "\n",
    "# 30584: CAC 40 > 7200 and less than 7400\n",
    "row = numerics[numerics['bot_question_id'] == 30584].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 7200, 7400)\n",
    "\n",
    "# 30792: Airline passengers > 18 and less than 19\n",
    "row = numerics[numerics['bot_question_id'] == 30792].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 18, 19)\n",
    "\n",
    "# 30793: Airline passengers > 17 and less than 18\n",
    "row = numerics[numerics['bot_question_id'] == 30793].iloc[0]\n",
    "numerics.loc[numerics['bot_question_id'] == row['bot_question_id'], 'forecast_values'] = cdf_between(row, row['cdf'], 17, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = numerics[keep_cols]\n",
    "binaries = binaries[keep_cols]\n",
    "groups_filtered = groups_filtered[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can merge all back together into.... df_bot_cp_exploded; keep only the relevant columns, i.e. 'bot_question_id', 'cp_question_id', 'cp_post_id', 'resolution', 'forecast_values'\n",
    "df_bot_cp_exploded = pd.concat([groups_filtered, binaries, numerics])\n",
    "print(f'Number of rows: {len(df_bot_cp_exploded)}')\n",
    "df_bot_cp_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract years from question_title and title\n",
    "df_bot_cp_exploded['bot_version_year'] = df_bot_cp_exploded['question_title'].apply(extract_year)\n",
    "df_bot_cp_exploded['cp_version_year'] = df_bot_cp_exploded['title'].apply(extract_year)\n",
    "\n",
    "cur_len = len(df_bot_cp_exploded)\n",
    "\n",
    "# Filter rows where the years do not match\n",
    "df_bot_cp_exploded = df_bot_cp_exploded[df_bot_cp_exploded['bot_version_year'] == df_bot_cp_exploded['cp_version_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract months from question_title and title\n",
    "df_bot_cp_exploded['bot_version_month'] = df_bot_cp_exploded['question_title'].apply(extract_month)\n",
    "df_bot_cp_exploded['cp_version_month'] = df_bot_cp_exploded['title'].apply(extract_month)\n",
    "\n",
    "if True:\n",
    "  # Filter rows where the months do not match\n",
    "  df_bot_cp_exploded = df_bot_cp_exploded[\n",
    "    (df_bot_cp_exploded['bot_version_month'] == df_bot_cp_exploded['cp_version_month']) |\n",
    "    (df_bot_cp_exploded['bot_version_month'].isnull())\n",
    "]\n",
    "\n",
    "  # How many rows were dropped?\n",
    "  print(f\"Number of rows dropped: {cur_len - len(df_bot_cp_exploded)}\")\n",
    "  print(f\"Remaining rows: {len(df_bot_cp_exploded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stragglers by hand\n",
    "bad_matches = [\n",
    "  30161, # Joe Biden no longer be president - CP version is \"before Jan 20\"\n",
    "  30723, # Doug Ford - CP version ends at the end of 2025\n",
    "  29463 # CDC flu - CP version asks about whole period thru April 2025\n",
    "]\n",
    "\n",
    "if 29356 in df_bot_cp_exploded['bot_question_id'].values:\n",
    "  df_bot_cp_exploded = df_bot_cp_exploded[~df_bot_cp_exploded['bot_question_id'].isin(bad_matches)]\n",
    "\n",
    "# And drop month and year columns out\n",
    "df_bot_cp_exploded = df_bot_cp_exploded[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to compute cp_baseline_score\n",
    "df_bot_cp_exploded['cp_baseline_score'] = df_bot_cp_exploded['forecast_values'].apply(compute_cp_baseline_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_bot_pro_cp_forecasts = df_top_bot_pro_forecasts.merge(df_bot_cp_exploded[['bot_question_id', 'cp_post_id', 'cp_question_id', 'cp_reveal_time', 'forecast_values', 'cp_baseline_score' ]], on='bot_question_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many forecast values are NA\n",
    "print(f\"Number of NA forecast values: {df_bot_cp_exploded['forecast_values'].isna().sum()}\")\n",
    "# Number of rows\n",
    "print(f\"Number of rows: {len(df_bot_cp_exploded)}\")\n",
    "# Number of each type based on type column\n",
    "print(df_bot_cp_exploded['type'].value_counts())\n",
    "\n",
    "# Show me the rows where forecast_values is NaN or 0\n",
    "df_bot_cp_exploded[df_bot_cp_exploded['forecast_values'].isna() | (df_bot_cp_exploded['forecast_values'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN in forecast_values\n",
    "df_top_bot_pro_cp_forecasts = df_top_bot_pro_cp_forecasts.dropna(subset=['forecast_values'])\n",
    "# Cast forecast_values as float\n",
    "df_top_bot_pro_cp_forecasts['forecast_values'] = df_top_bot_pro_cp_forecasts['forecast_values'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here begins the actual repeating of the bot-vs-pro analysis with bot-vs-CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique question ids? how many rows?\n",
    "print(f\"Number of unique question ids: {df_top_bot_pro_cp_forecasts['bot_question_id'].nunique()}\")\n",
    "print(f\"Number of rows: {len(df_top_bot_pro_cp_forecasts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly calibrated')\n",
    "\n",
    "# Plot calibration curves for bot_team_median and pro_median\n",
    "plot_calibration_curve(df_top_bot_pro_cp_forecasts, 'bot_team_median', 'Bot Team Median', 'blue')\n",
    "plot_calibration_curve(df_top_bot_pro_cp_forecasts, 'pro_median', 'Pro Median', 'red')\n",
    "plot_calibration_curve(df_top_bot_pro_cp_forecasts, 'forecast_values', 'Community Prediction', 'green')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Assigned Probability', fontsize=12)\n",
    "plt.ylabel('Fraction that Resolved \\'Yes\\'', fontsize=12)\n",
    "plt.title(f'Calibration Curve: Bot Team Median vs Pro Median vs Community Prediction\\n\\\n",
    "          (only overlap: {len(df_top_bot_pro_cp_forecasts)} questions)', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add diagonal line for perfect calibration\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', alpha=0.5)\n",
    "\n",
    "# Set axis limits\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly calibrated')\n",
    "\n",
    "# Plot calibration curves for bot_team_median and pro_median\n",
    "plot_calibration_curve(df_top_bot_pro_forecasts_all, 'bot_team_median', 'Bot Team Median', 'blue')\n",
    "plot_calibration_curve(df_top_bot_pro_forecasts, 'pro_median', 'Pro Median', 'red')\n",
    "plot_calibration_curve(df_top_bot_pro_cp_forecasts, 'forecast_values', 'Community Prediction', 'green')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Assigned Probability', fontsize=12)\n",
    "plt.ylabel('Fraction that Resolved \\'Yes\\'', fontsize=12)\n",
    "plt.title(f'Calibration Curve: Bot Team Median vs Pro Median vs Community Prediction\\n\\\n",
    "          all questions', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add diagonal line for perfect calibration\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', alpha=0.5)\n",
    "\n",
    "# Set axis limits\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make df_cp_baseline_wide and df_pro_bot_cp_resolved_questions\n",
    "df_cp_baseline_wide = df_top_bot_pro_cp_forecasts[['cp_post_id', 'bot_question_id', 'cp_baseline_score', 'forecast_values']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Create df_cp_bot_baseline_leaderboard, df_cp_bot_baseline_weighted_leaderboard\n",
    "\n",
    "# df_pro_bot_baseline_weights already has all the weights\n",
    "df_pro_bot_baseline_weights = df_pro_bot_baseline_weights.merge(df_cp_baseline_wide, on='bot_question_id', how='left')\n",
    "\n",
    "# Remove rows where cp_post_id is NaN (only want overlapping questions here)\n",
    "df_pro_bot_baseline_weights = df_pro_bot_baseline_weights.dropna(subset=['cp_post_id'])\n",
    "\n",
    "# Create a list of columns to keep\n",
    "forecaster_cols = ['cp_baseline_score', 'pro_median'] + [col for col in df_pro_bot_baseline_weights.columns if col in all_bots]\n",
    "df_filtered = df_pro_bot_baseline_weights[forecaster_cols]\n",
    "\n",
    "# Calculate the sum for each forecaster\n",
    "forecaster_scores = df_filtered.sum()\n",
    "forecaster_weighted_scores = df_filtered.mul(df_pro_bot_baseline_weights['question_weight'], axis=0).sum()\n",
    "\n",
    "question_counts = df_filtered.notna().sum()\n",
    "question_weighted_counts = df_filtered.notna().mul(df_pro_bot_baseline_weights['question_weight'], axis=0).sum()\n",
    "\n",
    "# Create a DataFrame for the leaderboard\n",
    "leaderboard = pd.DataFrame({\n",
    "    'Forecaster': forecaster_scores.index,\n",
    "    'Baseline': forecaster_scores.values,\n",
    "    'Count': question_counts.values\n",
    "})\n",
    "\n",
    "# Create a DataFrame for the leaderboard\n",
    "weighted_leaderboard = pd.DataFrame({\n",
    "    'Forecaster': forecaster_weighted_scores.index,\n",
    "    'Weighted_Baseline': forecaster_weighted_scores.values,\n",
    "    'Count': question_counts.values,\n",
    "    'Weighted Count': question_weighted_counts.values\n",
    "})\n",
    "\n",
    "# Sort the leaderboard by score in descending order\n",
    "leaderboard = leaderboard.sort_values('Baseline', ascending=False).reset_index(drop=True)\n",
    "weighted_leaderboard = weighted_leaderboard.sort_values('Weighted_Baseline', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Add a 'Rank' column\n",
    "leaderboard['Rank'] = leaderboard.index + 1\n",
    "weighted_leaderboard['Rank'] = weighted_leaderboard.index + 1\n",
    "\n",
    "# Reorder columns to have Rank first\n",
    "leaderboard = leaderboard[['Rank', 'Forecaster', 'Baseline', 'Count']]\n",
    "weighted_leaderboard = weighted_leaderboard[['Rank', 'Forecaster', 'Weighted_Baseline', 'Count', 'Weighted Count']]\n",
    "\n",
    "# Round to one decimal place\n",
    "leaderboard['Baseline'] = leaderboard['Baseline'].round(1)\n",
    "weighted_leaderboard['Weighted_Baseline'] = weighted_leaderboard['Weighted_Baseline'].round(1)\n",
    "weighted_leaderboard['Weighted Count'] = weighted_leaderboard['Weighted Count'].round(1)\n",
    "\n",
    "#leaderboard\n",
    "weighted_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Create df_cp_bot_forecasts, df_bot_vs_cp_peer\n",
    "\n",
    "df_cp_forecasts = df_cp_baseline_wide[['cp_post_id', 'bot_question_id', 'forecast_values']]\n",
    "\n",
    "want_cols = ['bot_question_id'] + [col for col in df_pro_bot_forecasts.columns if col in all_bots]\n",
    "\n",
    "df_cp_bot_forecasts = df_cp_forecasts.merge(df_pro_bot_forecasts[want_cols], on='bot_question_id', how='left')\n",
    "\n",
    "df_cp_bot_forecasts = df_cp_bot_forecasts.merge(df_top_bot_pro_forecasts[['bot_question_id', 'resolution', 'question_weight']], on='bot_question_id', how='left')\n",
    "\n",
    "# Create a new DataFrame to store peer scores\n",
    "df_bot_vs_cp_peer = df_cp_bot_forecasts.copy()\n",
    "df_bot_vs_cp_peer = df_bot_vs_cp_peer[['resolution', 'question_weight', 'bot_question_id']]\n",
    "\n",
    "# Calculate peer score for each bot\n",
    "for bot in all_bots:\n",
    "    # Calculate Head-to-head score based on the condition\n",
    "    peer_score = np.where(\n",
    "        df_cp_bot_forecasts['resolution'] == 'yes',\n",
    "        np.log(df_cp_bot_forecasts[bot] / df_cp_bot_forecasts['forecast_values']),\n",
    "        np.log((1 - df_cp_bot_forecasts[bot]) / (1 - df_cp_bot_forecasts['forecast_values']))\n",
    "    )\n",
    "\n",
    "    # Add the calculated peer score to the new DataFrame\n",
    "    df_bot_vs_cp_peer[bot] = 100 * peer_score\n",
    "\n",
    "# Calculate Head-to-head score for bot_team (TK: bot TEAM or median)\n",
    "peer_score = np.where(\n",
    "    df_cp_bot_forecasts['resolution'] == 'yes',\n",
    "    np.log(df_cp_bot_forecasts['bot_median'] / df_cp_bot_forecasts['forecast_values']),\n",
    "    np.log((1 - df_cp_bot_forecasts['bot_median']) / (1 - df_cp_bot_forecasts['forecast_values']))\n",
    ")\n",
    "\n",
    "# Add the calculated peer score to the new DataFrame\n",
    "df_bot_vs_cp_peer[\"bot_median\"] = 100 * peer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Weighted head-to-head, T test\n",
    "\n",
    "\"\"\"\n",
    "df_W_leaderboard: A leaderboard based on df_bot_vs_cp_peer with question\n",
    "weighting and the calculations for doing a weighted T test\n",
    "\"\"\"\n",
    "\n",
    "forecaster_weighted_scores = forecaster_weighted_scores.fillna(0)\n",
    "\n",
    "# Cast weights as numeric\n",
    "df_bot_vs_cp_peer['question_weight'] = pd.to_numeric(df_bot_vs_cp_peer['question_weight'], errors='coerce')\n",
    "\n",
    "df_W_leaderboard = calculate_t_test(df_bot_vs_cp_peer, all_bots)\n",
    "\n",
    "df_W_leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write both leaderboards to csv\n",
    "weighted_leaderboard.to_csv('notebook_outputs/weighted_baseline_bot_cp.csv', index=False)\n",
    "\n",
    "df_W_leaderboard.to_csv('notebook_outputs/weighted_t_test_h2h_bot_vs_cp.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique question ids in df_top_bot_pro_cp_forecasts\n",
    "print(f\"Number of unique question ids: {len(df_top_bot_pro_cp_forecasts['bot_question_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS JUST ON THE 43 THAT THEY ALL FORECASTED ON\n",
    "\n",
    "# Recommend paying attention to the bot team h2h scores vs CP graph (further down) rather than pgodzinai (he was selected as the bot \"team\" vs the PROS)\n",
    "\n",
    "df_top_bot_pro_cp_forecasts['head_to_head_bot_vs_cp'] = df_top_bot_pro_cp_forecasts.apply(calculate_head_to_head, args=('bot_team_median', 'forecast_values'), axis=1)\n",
    "df_top_bot_pro_cp_forecasts['head_to_head_cp_vs_pro'] = df_top_bot_pro_cp_forecasts.apply(calculate_head_to_head, args=('forecast_values', 'pro_median'), axis=1)\n",
    "df_top_bot_pro_cp_forecasts['head_to_head_bot_vs_pro'] = df_top_bot_pro_cp_forecasts.apply(calculate_head_to_head, args=('bot_team_median', 'pro_median'), axis=1)\n",
    "\n",
    "plot_head_to_head_distribution(df_top_bot_pro_cp_forecasts, 'head_to_head_bot_vs_cp', ('pgodzinai', 'CP'))\n",
    "plot_head_to_head_distribution(df_top_bot_pro_cp_forecasts, 'head_to_head_cp_vs_pro', ('CP', 'Pro median'))\n",
    "plot_head_to_head_distribution(df_top_bot_pro_cp_forecasts, 'head_to_head_bot_vs_pro', ('pgodzinai', 'Pro median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Weighted Bot Only Peer, T test (FOR CP COMPARISON)\n",
    "\n",
    "# To choose our top bot team, we only use the questions for which there is no CP benchmark\n",
    "yes_cp_benchmark = df_top_bot_pro_cp_forecasts[~df_top_bot_pro_cp_forecasts['cp_post_id'].isna()]['bot_question_id'].values\n",
    "\n",
    "df_bot_only_peer = df_bot_peer[~df_bot_peer['bot_question_id'].isin(yes_cp_benchmark)]\n",
    "df_bot_only_peer_wide = make_wide(df_bot_only_peer, df_pro_bot_resolved_questions)\n",
    "\n",
    "df_W_bot_only_peer_leaderboard = calculate_t_test(df_bot_only_peer_wide, df_bot_only_peer['forecaster'].unique())\n",
    "\n",
    "#df_W_bot_only_peer_leaderboard[['W_ave', 'W_count', 'lower_bound', 'upper_bound']].sort_values(by='lower_bound', ascending=False)\n",
    "\n",
    "# Sort the DataFrame by the lower_bound column in descending order\n",
    "sorted_df = df_W_bot_only_peer_leaderboard.sort_values(by='lower_bound', ascending=False)\n",
    "\n",
    "# exclude bot median for purposes of bot teaming\n",
    "sorted_df = sorted_df.drop('bot_median', errors='ignore')\n",
    "\n",
    "# Get the top 10 bot names\n",
    "top_10_bots = sorted_df.index[:10].tolist()\n",
    "\n",
    "# Print the list of top 10 bots\n",
    "print(\"Top 10 bots:\")\n",
    "for i, bot in enumerate(top_10_bots, 1):\n",
    "    print(f\"{i}. {bot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Calculate df_bot_team_forecasts\n",
    "\n",
    "df_bot_team_forecasts = pd.merge(\n",
    "    df_bot_forecasts,\n",
    "    df_pro_bot_resolved_questions[['bot_question_id', 'pro_question_id', 'question_weight', 'resolution']],\n",
    "    on='bot_question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Keep only rows where the there is no CP benchmark\n",
    "df_bot_team_forecasts = df_bot_team_forecasts[~df_bot_team_forecasts['bot_question_id'].isin(yes_cp_benchmark)]\n",
    "\n",
    "columns_to_keep = ['bot_question_id', 'question_weight', 'resolution'] + top_10_bots\n",
    "\n",
    "# Filter the DataFrame to keep only the specified columns\n",
    "df_bot_team_forecasts = df_bot_team_forecasts[columns_to_keep]\n",
    "\n",
    "# Function to calculate median forecast for a given number of bots\n",
    "def calculate_median_forecast(df, bots):\n",
    "    return df[bots].median(axis=1)\n",
    "\n",
    "# Calculate and add median forecasts for 2 to 10 bots\n",
    "for i in range(1, 11):\n",
    "    bots_subset = top_10_bots[:i]\n",
    "    column_name = f'median_forecast_{i}_bots'\n",
    "    df_bot_team_forecasts[column_name] = calculate_median_forecast(df_bot_team_forecasts, bots_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Calculate the baseline scores for each team size\n",
    "\n",
    "teams = ['median_forecast_1_bots',\n",
    "         'median_forecast_2_bots',\n",
    "         'median_forecast_3_bots',\n",
    "         'median_forecast_4_bots',\n",
    "         'median_forecast_5_bots',\n",
    "         'median_forecast_6_bots',\n",
    "         'median_forecast_7_bots',\n",
    "         'median_forecast_8_bots',\n",
    "         'median_forecast_9_bots',\n",
    "         'median_forecast_10_bots']\n",
    "\n",
    "weighted_scores = calculate_weighted_scores(df_bot_team_forecasts, teams)\n",
    "\n",
    "# Print nicely - round to 2 decimal places and first column should be just an integer (bot team size)\n",
    "weighted_scores_print = pd.DataFrame(weighted_scores).reset_index()\n",
    "weighted_scores_print.columns = ['Bot_Team_Size', 'Weighted_Baseline_Score_for_Bot_Team_Median']\n",
    "weighted_scores_print['Weighted_Baseline_Score_for_Bot_Team_Median'] = weighted_scores_print['Weighted_Baseline_Score_for_Bot_Team_Median'].round(2)\n",
    "weighted_scores_print['Bot_Team_Size'] = weighted_scores_print['Bot_Team_Size'].apply(lambda x: int(x.split('_')[2].split('_')[0]))\n",
    "weighted_scores_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of top bot team from weighted_scores_print?\n",
    "winning_bot_team_size = weighted_scores_print.sort_values(by='Weighted_Baseline_Score_for_Bot_Team_Median', ascending=False).head(1)['Bot_Team_Size'].values[0]\n",
    "top_bot_team = top_10_bots[:winning_bot_team_size]\n",
    "top_bot_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bot_forecasts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Weighted team-vs-cp\n",
    "\n",
    "# We have our top bot team members.\n",
    "# Create df with bot_question_id, forecasts, resolution, weights\n",
    "# Calculate the head-to-head scores\n",
    "\n",
    "df_top_bot_forecasts = df_bot_forecasts[['bot_question_id'] + top_bot_team]\n",
    "df_top_bot_forecasts['bot_team_median'] = df_top_bot_forecasts[top_bot_team].median(axis=1)\n",
    "\n",
    "df_cp = df_top_bot_pro_cp_forecasts[['cp_post_id', 'bot_question_id', 'forecast_values', 'resolution', 'question_weight']]\n",
    "\n",
    "df_top_bot_cp_forecasts = pd.merge(\n",
    "    df_top_bot_forecasts,\n",
    "    df_cp,\n",
    "    on='bot_question_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Filter to only those rows where CP is not NA\n",
    "df_top_bot_cp_forecasts = df_top_bot_cp_forecasts.dropna(subset=['forecast_values'])\n",
    "\n",
    "# Add the head_to_head column\n",
    "df_top_bot_cp_forecasts['head_to_head'] = df_top_bot_cp_forecasts.apply(calculate_head_to_head, args=('bot_team_median', 'forecast_values'), axis=1)\n",
    "\n",
    "display_head_and_tail(df_top_bot_cp_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge this bot_team_median with df_top_bot_pro_cp_forecasts. First, rename bot_team_median in df_top_bot_pro_cp_forecasts to pgodzinai\n",
    "df_top_bot_pro_cp_forecasts = df_top_bot_pro_cp_forecasts.rename(columns={'bot_team_median': 'pgodzinai'})\n",
    "df_top_bot_pro_cp_forecasts = df_top_bot_pro_cp_forecasts.merge(df_top_bot_cp_forecasts[['bot_question_id', 'bot_team_median']], on='bot_question_id', how='left')\n",
    "df_top_bot_pro_cp_forecasts = df_top_bot_pro_cp_forecasts.rename(columns={'forecast_values': 'community_prediction'})\n",
    "\n",
    "# Write df_top_bot_pro_cp_forecasts to csv, but only the columns bot question id, cp post id, cp question id, title, resolution, cp_reveal_time, forecast_values, bot_team_median, pro_median\n",
    "df_top_bot_pro_cp_forecasts[['bot_question_id', 'cp_post_id', 'cp_question_id', 'title', 'resolution', 'cp_reveal_time', 'community_prediction', 'bot_team_median', 'pgodzinai', 'pro_median']].to_csv('notebook_outputs/df_top_bot_pro_cp_forecasts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_total_score = get_weighted_score(df_top_bot_cp_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot head-to-head distribution\n",
    "plot_head_to_head_distribution(df_top_bot_cp_forecasts, 'head_to_head', ('Bot Team (pgodzinai, MWG, annabot)', 'CP'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
